{
  "res": [
    "Cache invalidation really is one of the hardest problems in computer science  If you donâ€™t have time for both, I recommend reading the original article: https://netflixtechblog.com/seeing-through-hardware-counters-a-journey-to-threefold-performance-increase-2721924a2822 The three hardest problems in CS  \n\\- cache invalidation\n\n\\- off by one errors\n\n\\- cache invalidation One question I have is why this supertype cache is shared between threads. It seems like an ideal candidate for something that should be made thread local. get rid of caches.  no cache, no cache invalidation, no problem. What's harder Cache invalidation or naming things? I wonder how much this problem could be mitigated by just having larger caches?\n\nI work at a higher level - one of my servers has an 800GB PCIe SSD drive as a cache for a slower (remote) block storage service where several terabytes of data is stored.\n\nI expect if we had a 100GB SSD, it would be really difficult to avoid cache misses. But because our cache is so large, we can err on the side of caching data that doesn't need to be cached and everything is quite easy to manage.\n\nI wonder why Intel CPU caches are so small? For example a Xeon commonly has 16KB of L2 cache per core. Apple's mobile phone CPUs have 16MB of L2 per core. As a software engineer developing a mobile app with an extensive server backend where basically the same tasks need to be completed on both... I'm often frustrated by how slow our most-expensive-money-can-buy server is compared to even a several year old smartphone at certain operations and I'm pretty sure it's the 1024x larger cache. Because everything else is *way* faster on the server. Hahahah! Yes, now try and explain it to non-tech, business folk like I have to ðŸ™ƒ Cache invalidation is not really to blame here. More concurrency and coherency requirements. > 1 / 8 = 12.5%, and thatâ€™s roughly the number of nodes that were observed in the low band in this scenario.\n\nYeah, this is cap. Structs have a \"_natural alignment_\". So the chance of false sharing is a bit more complex than this.\n\nThere fix is also a bit badly implemented as they just passed `jbyte[64]` when they should've padded with `jbyte[64-sizeof(Klass*)]` to ensure the following `Klass*` would start on the cache line. Itâ€™s very easy with redux toolkit query",
    "It's photoshopped, [this](https://files.catbox.moe/4ishz2.png) is the original photo. ",
    "Cartridge enthusiasts, if you don't make your own carts you are missing out. I'm about to turn all this GMO sugar wax into some amazing carts.  I can't recommend enough at least giving it a go. It's way easier than you think, more economical, and easier to find your favorite strains. If you are like me and love CBD, you can even add it to your oil. These 5 grams are gonna turn into 8 one gram carts at 1:1 (nightime) and 8 half gram carts at 1:3 (daytime) with added CBD distillate and isolate. Each one gram cart costs me about $20.\n\nEdit- \nHere you go folks, all done- [GMO Cookies 1:1 ]\n(https://i.imgur.com/BcfTOJX.jpg)\n\n\nThis is 10 grams. I'm gonna take 2 grams and further dilute it and use it for my daily carry that I puff on all day. \n\nThis is why dispensary carts are obsolete for me. Thinking of doing this next week. How do you decarb ? Iâ€™ve been exponentially more happy w my carts then dispo bought! ðŸ†ðŸ¥‚ This sounds cool and even maybe fun, any videos that show how that you suggest? Gotta be in a state that has affordable extracts lol. Lots of states are still illegal and even more have super expensive concentrates.\n\nIve made my own a couple times but I just don't have the access. Heck I'd be happy to just have the access to be able to buy prefilled carts... How much cheaper is it? Got some live rosin rn, if I load it into a heat safe jar and pop that bitch in my oven, how does 150 for a couple hours sound. Also, can I use a toaster oven Damn that looks fire too How to get started? How do you not waste a bunch of concentrates when making carts? Donâ€™t you get a lot sticking to the decarb vessel and syringe?",
    "Since a bunch of people have asked me about how to practise, I thought I'd just answer here.\n\nIn my opinion, the best thing to do is to try to really understand concepts, rather than trying to memorise a lot of different patterns/techniques. For example, I see a lot of people trying to memorise like 20 different DP problems, and then when they see a problem, they'll be like \"I wonder if I can force the coin change algorithm on this problem\". I think it's a lot better to have a general understanding of how to construct DP states and transitions - that way, you'll be able to formulate the correct DP recurrence on unfamiliar problems, perhaps with transitions and states you haven't seen before. I'm not discounting patterns entirely - sometimes, they can help in recognising which states to use. But you shouldn't rely on having seen almost the exact same pattern before. That being said, I haven't done any interviews before, so maybe the interview problems are simple enough that simple pattern recognition simply works... so maybe this strat works for interviews, but you certainly won't improve from it. (If anyone's confused by the terminology, the states are the variables that you memoise in your DP, and the transitions is how you use previous DP values to calculate your current DP value).  \nHence, there are perhaps two types of practice.\n\nThe first type of practice is general problem solving. This is where you build up a strong intuition of problem and develop general problem solving techniques (but not memorising a huge list of techniques). Of course, the only way to improve is to do lots of problems / contests. For those who are more interested in competitive programming, I really like [dmoj.ca](https://dmoj.ca) (they host contests there as well, sometimes I author some :) ).   \nThe second type is just learning new concepts or techniques. I can't comment on courses such as \"Grokking the Coding Interview\" because I simply haven't done them. What I have enjoyed, however, is the CSES handbook ([https://cses.fi/book/book.pdf](https://cses.fi/book/book.pdf)). The book is very well written, and there is an additional problemset to test the concepts you just learnt at [https://cses.fi/problemset/](https://cses.fi/problemset/). Some of the concepts taught in the book are a bit out of scope for interviews, but would be great for anyone interested in competitive programming. ",
    "Ask how long they'll spend in the house first of all. 4 hours is a decent amount but many companies push their inspectors to only spend 2, which is nowhere near enough time to do everything and properly document. Ask if they remove panel covers. They're usually not technically required to but if they don't, they're not really inspecting the panel and wiring for potential problems. Also ask if they use thermal imaging to inspect wiring and insulation. Good ones will always bring a thermal camera to look for hot wires and air gaps. There are other things to ask for as well but time spent, removing panels, and thermal imaging should give you a good idea of how thoroughly they'll actually inspect a house.\n\nEdit: as others have mentioned, time is subjective based on the size, age, and number of features that need inspection. Mainly I'd make sure they're not gonna rush through because of some arbitrary time constraint from the company or just to make their next appointment. Good inspections take time. ",
    "phily  join the discord https://discord.gg/kbVaKt3tpJ\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/SocietyLounge) if you have any questions or concerns.* Gritty This should not be as funny as it is u/savevideobot what is the song? Gritty is cracked the fuck out and I love it Mf got gotted ###[View link](https://redditsave.com/info?url=/r/SocietyLounge/comments/vb02qc/phily/)\n\n\n --- \n [**Info**](https://np.reddit.com/user/SaveVideo/comments/jv323v/info/)&#32;|&#32; [**Feedback**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Feedback for savevideo)&#32;|&#32;[**Donate**](https://ko-fi.com/getvideo) &#32;|&#32; [**DMCA**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Content removal request for savevideo&message=https://np.reddit.com//r/SocietyLounge/comments/vb02qc/phily/) Sweet dreams i know. but what remix is it?",
    "Man .... I miss pop smoke . This One of my favorite mash ups of all time  Pop wouldâ€™ve Been insane on some of the Top BX drill sampled beats ðŸ”¥ RIP to the Goat Nah this is dead fire ngl Shit hard ðŸ˜‚ðŸ”¥ Ong im going to be upset until I die for him not being able to finish the song that featured on the second half of his fire in the booth freestyle. â€œIM A TRAP FANATIC! I WALK IN THE SPOT LIKE I WANT IT ALLâ€ still speaking to my soul ILL BOOM YOUR CASA ðŸ˜­ðŸ˜­ðŸ˜­ðŸ¤£ðŸ¤£ðŸ¤£ Lmfao this is trash bro What song is that You miss him or u miss his music. And his energy? Still baffles me how niggas miss somebody they never met",
    "What are your most favorite LC problems ? What are the problems that you enjoyed most? Which problems did you find most useful to understand a given  topic ? The ones that I solved on my own Graph problems. Unlike string problems (many of which require tricks), most graph problems are intuitive to understand. Number of Islands or Pacific Atlantic Water Flow Reversing a Linked List, Linked List Cycle 2 in constant space, Inverting a Binary Tree and Kth smallest element in a BST I feel like all the graph problems could be solved with a version of bfs. I really enjoy dp problems Num islands, house robber Recipes!  I posted my solution in a screen shot on this forum. Something satisfying about implementing top sort. Counting Bitsâ€¦ so cool to see DP and the n & (n-1) bit trick together. Useful problems (understand the intuition/idea would be the best):\n\n* [https://leetcode.com/problems/longest-common-subsequence/](https://leetcode.com/problems/longest-common-subsequence/) \\- **SUPER CRUCIAL FOR STRING PROBLEMS!** When you know it they become much easier to breakdown through analysis.\n* [https://leetcode.com/problems/number-of-islands/](https://leetcode.com/problems/number-of-islands/) \\- **Very helpful to get started with Graph/Matrix problems.** It'll open your eyes as to how to deal with graph problems in general, such as how do you do the traversals, etc\n\nMy favourite problems:\n\n* [https://leetcode.com/problems/critical-connections-in-a-network/](https://leetcode.com/problems/critical-connections-in-a-network/) \\- Lots of ways to solve this, and relatable to real-world applications.\n* [https://leetcode.com/problems/the-skyline-problem/](https://leetcode.com/problems/the-skyline-problem/) \\- The most unique problem I've encountered\n* [https://leetcode.com/problems/wildcard-matching/](https://leetcode.com/problems/wildcard-matching/) \\- Absolute pain, but I loved the struggle I went through to solve it",
    "North County What are your go-to places to eat along the 78 corridor? Oceanside-Escondido. Donâ€™t say TJ Tacos. \n\nI work this area a lot and looking for new places to try. Any cuisine. Money pit for burgers, dogs, wraps and breakfast I would venture east about two minutes from the end of the 78 in Escondido to Rock n Jennyâ€™s Italian Subs Philly Frank's for cheesesteaks, Compadres grilled chicken. **Muay Thai Kitchen**... killer Thai food but beware of their spice scale, a five there is like a seven or eight everywhere else\n\n**Kung Fu Noodle**... their homemade noodles are superb, I'm addicted to their Dan Dan Mama Kat's for breakfasts Home Sweet Home for breakfast * The Yellow Deli (Vista)\n* Dija Mara (Oceanside)\n* Wrench and Rodent  Seabasstropub (Oceanside)\n* Flying Pig Pub & Kitchen (Oceanside)\n* Communal (Oceanside)\n* Beach Break Cafe (Oceanside)\n* Angelo's (Oceanside)\n* Al Toque Peruvian Kitchen (Vista)\n* Tip Top Meats (Carlsbad)\n* Lutchi and Mary (San Marcos) Check out Mirramar Fish Tacos in Oceanside right off of the 76 and Douglas.  Place has amazing reviews for a reason. They are mostly various seafood tacos. 1: Four Tunas in Escondido\n\n2: Churchill's Pub in San Marcos\n\n3: Ahi Sushi in San Marcos\n\n4: KM BBQ in O-side\n\n5: Felix's BBQ With Soul off Nordahl\n\n6: Fish House Vera Cruz in San Marcos\n\n7: Sayulitas Mexican Food off Nordahl\n\n8: Pizza Port in Bressi Ranch... (I like beer)\n\n9: Curry and More in San Marcos\n\n10: Board and Brew (Anywhere)\n\n11: Garcia's in Carlsbad\n\nand last, but not least...Mas Fina Cantina for some amazing food and a great time has by all. Bone apple tea! Off the 78 a little bit, but Guahan Grill in Oceanside is one of my favorites",
    "Fucking Algorithm - A gitbook that contains not just the solution code for a problem, but also WHY the solution works and HOW you too can figure it out  I haven't finished reading all the sections. I just went through first section so far i learnt so many new things i didn't know before. Very good find it will really help me for interview preperation. Thanks for sharing, I really appreciate it!!! I read â€œMy way of learning Algorithmsâ€ section of the book, and I guess the guy who translated it used Google Translate. Too many obvious mistakes. But great overall. This is interesting! Thanks for sharingâ€¦ Is there a github repo for this? Thanks bro Thanks for sharing the gem!!!!! Do they provide the content over youtube as well?? Ooh youâ€™re able to read and retain. Yeah: [https://github.com/labuladong/fucking-algorithm/tree/english](https://github.com/labuladong/fucking-algorithm/tree/english) Thank you",
    "Right moment  r \\\\JustUnsubbed members be like ah yes my favourite band, apolitical anger against a physical device I remember when Eminem publicly made fun of Donald Trump in like 2018 a lot of his fans got pissed\n\nThey somehow forgot Eminem [wrote multiple songs in the early 2000s about how much he hated Bush lol](https://www.lyrics.com/lyric/7359634/Eminem/Mosh) Rightists try to understand the least subtle art known to man challenge (IMPOSSIBLE) (10000%) FAIL Itâ€™s Rage Against the Machine isnâ€™t it? Me when rage against the machine starts talking about political stuff ðŸ˜® https://i.imgur.com/oeZdsrG.jpg Conservatives when they publicly deface â€œwhoâ€™s afraid of red blue and yellowâ€ and donâ€™t see the point of the art piece I find it so hilarious that when Bille Joe Armstrong posted some anti-racist stuff on instagram some literally said \"stick to music\" like... did you even hear American Idiot? There's some slightly gay/bi Green Day songs (Basket Case and Coming Clean for example) and then there's King for a Day. While, sure, some of these might be a but more subtle, American Idiot is in no fucking way subtle and it's one of their most popular songs. I'm just fucking dumbfounded by these fuckers. Neonazi Rammstein Fans:",
    "Grow your own Potatoes  i have built one of these based on the last meme cycle of this idea that i used for a few growing seasons. I found that the added work of building the box and maintaining the soil level was considerably more work than in ground potatoes, and the harvest was very disappointing both in size and quantity compared to in-ground. harvesting is a much bigger pain as well. [POTATO TOWERS DON'T WORK! ](https://www.cultivariable.com/potato-towers/)\n\nSorry its kinda exhausting seeing this Thing after four years again... Only problem is the wood for the boards is probably more expensive than the 100 pounds of potato My mom has tried a few above ground potato structures like this and they rarely work out. You can also buy bags for growing potatoes if you donâ€™t want to spend 100 dollars on wood do you have a way to grow 100 pounds of more expensive vegetables TFW the Martian. So how do one know when to start harvest the first layer or any subsequent one? From my experience, potatoes wonâ€™t put out new crops all the way up. Thereâ€™s just a foot or so of spud growth, the rest is all stems and greens.\n\nYou could maybe still take advantage of this system by growing different varieties in different layers. Plant slower growing in the bottom, and every foot add new seed stock as you cover as described. Itâ€™ll take a ton of watering to get big tubers, but thatâ€™s what Iâ€™m gonna try soon. I like potatoes.",
    "harry potter smokes weed  join the discord https://discord.gg/kbVaKt3tpJ\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/SocietyLounge) if you have any questions or concerns.* Can't wait for the next movie! Freak ass hoe mudblood If harry potter was good: this was the worst fucking shit I've ever watched why was it actually funny where part 2 fuck you i was gonna post this shit Cant believe I watched that whole thing u/savevideobot u/savevideo",
    "A Gram Per Line Keeps Me Feeling Fine ðŸ˜®â€ðŸ’¨ðŸ’¨  imagine this dude enters a job interview and they show him this videoðŸ’€ðŸ’€ Iâ€™ll say it once and Iâ€™ll say it again..YOU CAN ONLY GET SO HIGH..your body reaches a certain point and then you are looking at a heart attack or a stroke..and can be any age..slow down man enjoy the high..youâ€™re just tweaking here This is fucking hardcore, but i don't know if i should applaud. You can barely keep your fucking head still.\n\nYou should probably try doing less meth instead of more.\n\nWatching you people is like watching animals in a zoo. It's entertaining as fuck but you're glad it's them stuck in the cage and not you. In the darkest hours when the worst is inevitable with the walls upon which this civilization are starting to fall brick by brick. There is no hope for the future because there was nothing left as means for the future to be sustainable. As the last frantic response of self-preservation starts to give way to the start of acceptance of the end. With everything rapidly crashing around you the chaos fades away to peaceful silence. Then out of nowhere you see someone hot railing a g in one line. You realize there still is hope left with the best chance for the future. There's No Hope Like Dope Hope. Way to go young man!! Keep up the good fight!! Bro tweaked so hard he could barely hit it ðŸ’€ðŸ’€ðŸ’€ðŸ’€ I had 8 strokes watching this Not to be a buzz kill but if that was pure you'd be dead. Look up acetone washing and stop inhaling this shit. Just parachute it in small amounts after washing it to get way higher, be safer, and not look like your trying to impress tweakers. Regardless of all that, badass cloud happy tweaking Bro going so fast he died, reincarnated, made a new reddit account and is posting. This dude the final boss of methâ€¦ goodluck",
    "I just released the first six modules of my free Natural Language Processing course. If you're new to NLP, these first six modules will get you up and running with the basics.  \n\n\nWe'll cover:\n\n* what makes NLP challenging and what we'll learn in the course.\n* various ways to preprocess our text depending on our goals including tokenization, lemmatization, part-of-speech-tagging, and more.\n* how to turn our text into numbers with basic bag-of-words approaches and performing document search.\n* how to use spaCy and scikit-learn to do all of the above.  \n\n\nNo registration needed but you can sign up for updates. Check it out at [nlpdemystified.org](https://nlpdemystified.org) and let me know what you think! Looks very neat. I think I will be referring to this in future. I have not really gone through with it fully, but do you go teach the theoretical concepts showing the math behind it? [deleted] This is awesome, Iâ€™ve been fumbling my way through some applied NLP with no real background and itâ€™s fun but pretty improvised. This should be helpful, Iâ€™ll check it out! Which level of math would I need to know to take this course? Half way through the videos, nice work! They are very clear, good flow, great voice. Keep up the good work :) I watched the first two videos.  Very well done.   Iâ€™m on my phone so I didnâ€™t see any links to the notebooks.  Being able to run those would be helpful.  Iâ€™m an NLP hobbiest. I just want to know how it works as I think NLP along with â€œMLâ€ in general will be transformative over the next few years.  I bought a NLP cookbook recently that teaches the same concepts but the code was buggy and I was spending time fixing bugs rather than learning.  Have notebooks pre-setup would be super helpful. Whatâ€™s your process for tokenization and lemmatization? Yes, one of the goals of the course is to show the theoretical concepts in an accessible way. The math is light at the beginning (e.g. cosine similarity) and gets richer as we go into deep learning. You can subscribe for updates when new modules are released (no spam). I'm creating this for anyone who wants an accessible view of how NLP models work under the hood, and practical examples of applying that knowledge. My goal for the course is to enable others to understand theory and practice, and be able to read papers afterwards.   \n\n\nThis could be a software developer looking to get into ML, a linguist who knows some Python, an indie hacker who wants to create a product, a bright high school or undergrad student wanting to explore the area, or supplementary material for someone already into it. Their goal is up to them. At least for the uni undergrad/masters courses I've taken, they ask for practical projects as assignments, but very few of them actually teach you the practical side like using scikit learn or pandas. So that's why at least for me, I would personally benefit from online stuff covering the practical stuff. I'd use courses like this as supplementary material.",
    "Really struggling with machine learning interviews. What are the best ways to prepare for ML/Data Science interviews?? 3 months ago I quit my job as a software engineer to transition to a ML/data science role. I read (most of) the Bishop book (Pattern Recognition and Machine Learning), done the Andrew Ng course and been through a couple of ML roadmaps. I've sent off loads of application, had a couple of interviews and really struggled with them. The second was a hit to my confidence so really want to be better prepared next time... what are the best ways to prepare for interviews for ML/Data science roles?? Thanks :) >really struggled with them\n\nwhat were the main issues you struggled with? white-board coding like Leetcode style? technical questions like SQL/ML concepts? Chip has some good resources to use for ML interviews.\n\nhttps://huyenchip.com/archive/ ML and Data Science roles often differs.\n\nIf you've a software engineering background you may want to look at [https://aws.amazon.com/certification/certified-machine-learning-specialty](https://aws.amazon.com/certification/certified-machine-learning-specialty).\n\nIt will build you ML and data analytics skills assuming you'll be going to apply those skills.\n\nIt includes a strong mix of algorithms and technologies to design, build, and manage in production complex ML models in real-world applications.\n\nTry using Udemy courses from Sundog Education, they are very good. This will suffice for the certification and for building your confidence.\n\nMaybe use [https://www.deeplearningbook.org](https://www.deeplearningbook.org/) if you want also keep an eye on the theory.\n\nHave fun. Check out [Ace the DS Interview](https://www.acethedatascienceinterview.com/) â€” has chapters on ML interviews, Stats questions, and the typical open-ended DS/ML case study questions you'll also be asked. But I'm a tad biased, since I wrote the book! Projects. \n\nDid you do a project applying everything you learned? Not even a full fledged one, but just getting any dataset from kaggle or UCI and and doing complete EDA to model development on it? You can do a hundred courses but if you do not apply it on a project, you will never be confident about anything you've learned. The reason is that this is a highly applied field and there are nuances and multiple ways to approach any problem. Also, if you have a really good project relating to company domain, it will become a focal point of your interview.\n\nSource - Did a Time Series Analysis course a couple weeks back as I am looking to transition to Data Science soon but wasn't sure if I'm confident how much I actually learned in that course. Did a forecasting project for my current organization and it's turned out pretty good. But, doing that project on real world data was a real bitch. I had to refer so many things and learnt so many new things not included in the course or didn't feel important while doing the course. So, do a project. Pick a project correlated to something you are interested in. Frame it as something you would interview for in a smaller chunk. Grind. This will help your tech skills and confidence immensely. Purpose of the interviews is to ensure you have the skills to be successful in the job. One great way to showcase these skills is to participate in a ML competition and show that you can actually built a well performing model. Your model's performance in the competition will effectively communicate your ability to build models which is the core for data science work. You don't need to win one to get a job, but in case you do, there's also prize money involved :) Link: [https://mlcontests.com/](https://mlcontests.com/) You may want to, at least for now, focus on a more specific type of ML or data science. Do you want to play with databases/graphs, computer vision, 3d, etc.? If you read bishop's book and understand the material you should be fine; reading bishop's book is not enough. You got this bro",
    "You started a new job, what are the first tools you install on your machine? I'm curious to know what DevOps engineers do to setup their workspace when they are handed with a new laptop. What tools do you use daily to boost your productivity?\n\nFor example, oh my zsh, WSL for Windows, VS Code with X extensions, etc etc.\n\nI'm part of a DevOps IT team for R&D (I'm personally IT) and the engineers at my team always have wacky setups that help them to almost never use their mouse, or never completely type anything without some auto-completion. Basically wizards.\n\nThanks :) My goto:  \n\n\nSteam  \nWarhammer 3 Total War\n\nSpotify  \nNetflix login I usually just go with Ubuntu these days.\n\nMy main dot files, Oh-my-bash, tmux, pass, KeePass, git, vim + plug-ins, i3gaps, Compton, nmap-ncat, htop, systat, ansible, pipenv, dstat, httpie, curl, jq, pup, docker, puppet-debugger, clamav unless they have a specific policy. \n\nIt's all in a small script I usually run. There's probably a few more I'm missing [asdf version manager](https://asdf-vm.com/) Said before but I just *have* to say it again. \n\n```\nchezmoi init --apply $GITHUB_USERNAME\n```\n\nIt does the rest for me, regardless of OS and arch that I'm on. this is leaving off most of the obvious stuff, but here's the stuff i can't live without\n\n## homebrew casks\n\n- iterm2\n- visual-studio-code\n- tower (git client, commercial)\n- 1password (password manager, commercial)\n- alfred (productivity tool, commercial)\n- altair-graphql-client (graphql client)\n- docker-edge (latest docker for mac)\n- font-jetbrainsmono-nerd-font\n- gpg-suite (gpg for mac, commercial)\n- kaleidoscope (diff utility, commercial)\n- keybase\n- lepton (gist manager)\n- libreoffice (free ms office alternative)\n- little-snitch (firewall, commercial)\n- owasp-zap (owasp site scanner)\n- rcdefaultapp (control panel to set default apps for file extensions)\n- setapp (tons of great apps for $5/mo, commercial)\n- soundsource (advance mac audio controls, commercial)\n- steermouse (allows customization of mouse buttons, commercial)\n- syncthing (free alternative to dropbox, etc.)\n- transmit (the best ftp client, commercial)\n- virtualbox \n- xquartz (x11 for mac)\n\n## homebrew packages\n\n- autoraise (focus follows mouse for mac)\n- bat (alternative to cat)\n- bpytop (alternative to top)\n- browsh (text-based \"graphical\" web browser)\n- byobu (alternative to tmux)\n- chezmoi (sync dotfiles across machines)\n- fx (json viewer)\n- fzf (fuzzy finder, integrates with ohmyzsh)\n- gping (\"graphical\" ping)\n- howdoi (code snippet search)\n- jq (json query utility)\n- lsd (alternative to ls)\n- m-cli (cli for common mac functions)\n- mas (cli for mac app store)\n- micro (the most modern and user-friendly cli text editor)\n- mytop (mysql resource monitor)\n- percona-toolkit (various mysql utilities)\n- s3cmd (cli interface for amazon s3-compatible services)\n- safe-rm (safer alternative to rm command)\n- starship (the best cross-platform shell prompt)\n- terraform\n- thefuck (autocorrect for cli commands)\n- topgrade (autoupdate all the things)\n- xclip (add clipboard support to the cli, use over ssh with x11 forwarding)\n- xh (rust-based version of httpie)\n- zoxide (alternative to cd command with folder memory and quick jumping)\n\n## app store only\n\n- stts (live status updates on all your cloud services' availability)\n- gitify (github notifications in your menubar)\n- magnet (my preferred window manager for mac) As long as there is a half decent web browser and ssh/terminal client included, I'm good.  I don't keep anything local. Chezmoi Linux. My dot files are in a repo I clone\n\n* vim + vundle\n* tilix\n* git\n* pass\n* Hashicorp tools\n* various cloud provider tools (we use them all, including our own openstack one)\n* Flat remix gnome shell theme I grab a copy of my git repo and run the install script.\n\nBrew, and Macos defaults.",
    "This nigga scammed her for 10kðŸ’€  this nigga a real life leprechaun ongðŸ’€ Nigga hit the Jig for 10k ðŸ˜‚ðŸ˜‚ðŸ˜‚ wearing green for a reason This nigga Kai funny asf Lucky Charms Ass Dance LMFAOO W Kai, she was dry ass shit Fucking Leprechaun Dry ass bitch deserved it ngl even tho she had hella cake, her dry ass personality screwed it over smh lol he was hitting that shit thoðŸ’€",
    "Sockets for dummies  Excellent description of the random walk we do learning new stuff. You are a natural narrator! Great stuff, thanks very much, I will definitely read through this! Yeah, reading right now! Just read it and I like it! Good writeup and keep it up! Great stuff! I'm hoping you will eventually cover nonblocking sockets with select or epoll. I enjoy using the selectors module to build larger network applications that are single-threaded by simply relying on EpollSelector with I/O callbacks. I only skimmed it, but I noticed you have a section about ensuring that all the data was actually sent - which already makes this better than 99% of socket tutorials, even though you never mentioned the `sendall()` function.\n\nThat said, my personal advice for newbies is that they shouldn't even *think* about using sockets. They're far too easy to use incorrectly, and a pain in the butt in general. I'd recommend using websockets instead. Excellent, Nicely explained. All of this is so foreign to me but Iâ€™m in my infancy stages of python and Iâ€™m looking forward to understanding this! Nonetheless it looks like a very thorough piece +1! I wish more blog posts had the natural progression of thought like this Thanks for your input! I did try to capture that walk. I wrote the article _literally_ while learning :)",
    "\"LOCO: The 88-million-word language of conspiracy corpus\", Miani et al 2021  Wow thanks man! Appreciated that's the title? hilarious... and fascinating study... thanks will def check out. JSON files are pretty massive tho 1GB each goddamn Amaze!",
    "Just so you know, [my friend made a movie based on this post](https://www.youtube.com/watch?v=t9EftZNbvXo). ",
    "",
    "When your teacher says u can play Christmas music  NY niggas wild man ðŸ¤£ðŸ¤£\n\nI was bout to get sturdy ðŸ•ºðŸ¾ That song was type fire lol She was feeling it until she remembered what her job was lmao Nah this shit heat and you gotta respect the fact his classmates got sturdy to his shit too they was feeling it ðŸ˜‚ðŸ”¥ If you want the song its here  \n\n\nhttps://www.youtube.com/watch?v=GgMDwUz8JYI What song ? Bro you're not about to drop some hot shit  And not give the songðŸ˜‚ nah g \"Merry Christmas, only thing on my wishlist is bitches\" sheesh nah ny undefeated Class passed vibe check ðŸ¤£",
    "Iâ€™ve made a search engine with 5000+ quality data science repositories to help you save time on your data science projects! **Link to the website:** [**https://gitsearcher.com/**](https://gitsearcher.com/)\n\nIâ€™ve been working in data science for 15+ years, and over the years, Iâ€™ve found so many awesome data science GitHub repositories, so I created a site to make it easy to explore the best ones.Â \n\nThe site has more than 5k resources, for 60+ languages (but mostly Python, R & C++), in 90+ categories, and it will allow you to:Â \n\n* Have access to detailed stats about each repository (commits, number of contributors, number of stars, etc.)\n* Filter by language, topic, repository type and more to find the repositories that match your needs.Â \n\nHope it helps! Let me know if you have any feedback on the website.   [removed] Very nice. Bookmarked. I'll be sure to have a look through it later. Awesome. Thank you! ðŸ¤© The UI is so dope and the site is really useful. Thanks for sharing. Oh that's sick, definitely gonna use this. Thanks so much, this is brilliant! Thanks Santa!!! Any chance that you have the data set for that site in a downloadable format? :) Cool you get to mine what everyone searches for and what company they are at! Haha Thanks. Would be very useful.",
    "",
    "Use cases for \"treap\" data structure I am trying to develop an appreciation for the treap data structure; my goal is not to implement one but use boost when the problem calls for this construct. Some use cases, or small problems showing when the use of treap has advantages (over what?) or when it is pretty much a must will give me the bearings I need. The way I see it is that it doesn't have advantages in terms of complexity in any particular task to other balanced binary search trees. Although the binary tree it produces is balanced only in the average case, whereas most standard balancing methods give solid gurantees, its advantage lies in the fact that it is an extremely simple and concise implementation of a balanced binary search tree. \nA reasonable question is why you would have to ever implement a balanced BST yourself instead of importing something from the standard library. The answer is that sometimes you want to do more specific stuff with it than the interface of the data structure from the standard library allows. For example you can't search for an element's index in the sorted order of the elements in std::set from the c++ standard library, which is a very easy thing to do if you can modify your data structure and store additional information for the tree's nodes.\nYou can imagine how useful it could be if in such situations you could write what you need in 50 lines of code.\nAnother advantage that might come from the simplicity of the code is performance. Often simpler code is easier for compilers to optimize. As some previous comments have mentioned, treap is a good datastructure for calculating minimums, maximums or sums etc of arbitrary intervals in logarithmic time, but it really wouldn't be my first choice if these are the only requirements. There are faster datastructures such as segment tree and fenwick tree for such operations. \n\nWhat sets treap apart from these datastructures is the ability to reverse an arbitrary interval in logarithmic time as well being able to splice and rearrange in logarithmic time, while still being able to modify and query in logarithmic time. Thanks to all responders.\n\nIn the meanwhile, I found a paper titled [Fast Set Operations Using Treaps](https://www.cs.cmu.edu/~scandal/papers/treaps-spaa98.pdf), posted here for posterity. Treaps have been used in the [Linux kernel page cache](https://www.kernel.org/doc/mirror/ols2005v2.pdf). Treap is simpler than most if its competitors. From a practical point of view, if you want to implement a data structure based on holding a tree in sorted order with some sort of extra information held in the nodes describing the desecendants of that node this is an advantage. Another nice property of Treaps is their [canonical representation](https://people.csail.mit.edu/virgi/urtechreport.pdf), if an element priority is calculated with a consistent hash function over that element.\nCanonical representations have important use-cases, especially in the area of [authenticated data structures](http://www.bu.edu/hic/files/2015/01/versum-ccs14.pdf)/computations.\nNext to that, there are easy to make [persistent](https://arxiv.org/pdf/1301.3388.pdf) which make them suited for version control. Imho the essential part of the definition is: \"Finding sum, minimum or maximum element in a given range.\"\n\nAny problem that would benefit from identifying data based on size with ease would benefit from it.\n\nJust from the back of my head, items of different size that need to be packed in standardized boxes or Containers with different weight having to be distributed equally on a ship... \n\nThose are things that would draw me to this data structure.\n\n/myfewcents I can always copy paste from the standard library implementation and then extend the functionality. I don't think I need to do it from scratch. The standard library implementation is made extremely general purpose and that's its limitation. If you don't understand what I'm talking about and know some C++ check out some implementation of std::set, which I've heard is most often implemented with a red-black tree, which is also one of the more complicated solutions out there.\n That is going to be 10 times harder to modify towards your specific goal than your own code which if you implement with a treap will be about 50 lines of code and have around 3 functions total. That said you could copy someone else's code and start from there, which is a much more viable alternative than copying standard library code",
    "Model/Tool to use on Jetson for efficient Quantization/Pruning Hey everyone, I have a problem statement where I want to deploy a custom model on an Nvidia Jetson device. We have Jetson TX2 8GB with us.\n\nWe currently trained a YOLOv5s PyTorch and it is giving 15 FPS. But we require it to do inference in 50 FPS (Non-negotiable requirement by client). Itâ€™s okay if we donâ€™t achieve 50 FPS on TX2 we are just trying to optimize as much as we can and if required something like AGX or any other hardware we will go forward with that. TX2 is more like benchmark for us.\n\nWe are trying SparseML by NeuralMagic. But facing multiple errors. \n\nIf thereâ€™s any other way we can efficiently inference on a Jetson platform (High Quantization/Pruning).\n\nAlso we are open to try different models as well as Frameworks. The main goal is to achieve high accuracy with an efficient inference.\n\nPlease let me know if anyone has any idea. For best performance you should look into Nvidia TAO (train adopt optimize) toolkit. It has an export to TensorRT which you can in turn use to deploy on jetson with Nvidia DeepStream. \nTAO comes with built in Pruning Steps for a lot of different models. \n\nWe are currently running this setup after switching from yolov5 You need an Nvidia TensorRT solution and I suggest you develop your own [tkDNN](https://github.com/ceccocats/tkDNN) solution due to licensing issues.\n\n>tkDNN is a Deep Neural Network library built with cuDNN and tensorRT primitives, specifically thought to work on NVIDIA Jetson Boards. It has been tested on TK1(branch cudnn2), TX1, TX2, AGX Xavier, Nano and several discrete GPUs. The main goal of this project is to exploit NVIDIA boards as much as possible to obtain the best inference performance. It does not allow training.\n\nTo use tkDNN, train a model using Darknet and then convert it (Darknet is better than YOLOv5, the name was hijacked by someone unrelated to the original creator and maintainers of the YOLO algorithms). I'm in the process of doing something similar myself, planning on going the onnx-tensorrt path. Deci.ai optimization platform looks promising in that aspect. Also, if I remember correctly, the ultralytics Yolo v5 repo has a section on pruning/quantization no? [Qualcomm AIMET](https://github.com/quic/aimet) may help you You should use the TensorRT tool from\nNVIDIA Ohh this sounds great Iâ€™ll definitely look into it. Please share any good docs/videos you came across for the same! Ohh I see. \n\nYeah itâ€™s the same path with SparseML just Pyrorch->ONNX.\n\nAs far as I know Deci.ai is amazing but it isnâ€™t available on Jetson platforms or even normal GPUs itâ€™s only available on Teslaâ€™s and other GPUs of that category not sure though.\n\nOhh I wasnâ€™t aware of the Ultralytics Github part. Iâ€™ll definitely check it out.\n\nThanks! The [official docs](https://developer.nvidia.com/tao) are very detailed. I didnâ€™t need much info besides this and the forums. Do you how this is different to just train your own model in PyTorch and then convert to TensorRT? Is is easier to prune in TAO?",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "DD-1: The AI Solution to Depression. Omicron has released their new DD-1 model that can predict depression in Reddit users to a 93.11% accuracy. All you have to do is enter your username and you will receive a message within the next 24 hours with your mental wellness score. Try it out [here](https://omicron.life/). How do you measure accuracy and is your dataset balanced? Bro all reddit users are depressed lol, just playing, interesting program you got there. I bet a Better Help would be interested. I haven't received a message after 24h. Is this normal? Will give it a shot, I don't think I'm a depressed person, so we'll see how it does. So after taking in a username our model outputs a number from 0 to 1. 0 means they are not prone to depression and 1 means they are. So when our model was predicting the results for the validation data, if it returned anything .5 or above then the model predicts that they are depressed, and vice versa for less than .5. So in our dataset we used a 80:20 train test split and of the 20%, 93.11% of the results accurately predicted the user's mental state.\n\nOur dataset is intentionally unbalanced. 60% not depressed 40% depressed. Hey sorry about that. It was a problem at our end, you should be able to see your score now. We'll try to make sure this won't happen again! How did you get the ground truth for labeling. I think he means where did you get the data Thanks for answering so swiftly. Could you point me to where I can see the score? Same, tried it a couple days ago with no success.",
    "[P] AppleNeuralHash2ONNX: Reverse-Engineered Apple NeuralHash, in ONNX and Python As you may already know Apple is going to implement NeuralHash algorithm for on-device [CSAM detection](https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf) soon. Believe it or not, this algorithm already exists as early as iOS 14.3, hidden under obfuscated class names. After some digging and reverse engineering on the hidden APIs I managed to export its model (which is MobileNetV3) to ONNX and rebuild the whole NeuralHash algorithm in Python. You can now try NeuralHash even on Linux!\n\nSource code: [https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX](https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX)\n\nNo pre-exported model file will be provided here for obvious reasons. But it's very easy to export one yourself following the guide I included with the repo above. You don't even need any Apple devices to do it.\n\nEarly tests show that it can tolerate image resizing and compression, but not cropping or rotations.\n\nHope this will help us understand NeuralHash algorithm better and know its potential issues before it's enabled on all iOS devices.\n\nHappy hacking! Incredible work if true - can you explain more about how you know that the model extracted is the same NeuralHash that will be used for CSAM detection? I donâ€™t know about plugging it to GAN, but u/TomLube proposed this procedure for finding collisions: https://www.reddit.com/r/apple/comments/p3m7t0/daily_megathread_ondevice_csam_scanning/h8st9l4/ Hmm, I'm curious to know why the produced hashes in the repo are slightly different (off by a few bits) > Early tests show that it can tolerate image resizing and compression, but not cropping or rotations.\n\nI wonder if... this could somehow be repurposed to other uses...   \nI have two ideas in mind\n\nFor instance generating the hashes of an entire photo library, and using those hashes for robust duplicate detection  \n\nOr also  \nEither blurring the pictures beforehand, or resizing them down to something lower than 360x360 and then back up that, and using the resulting hashes for permissive similar picture detection Is there a visualisation of the network used here? Or of similar networks used for perceptual hashing? Fucking great work! [deleted] Great job thanks! BTW if the model is known, it could be possible to train a decoder by using the output hashes to reconstruct the input images. Using an autoencoder style decoder would most likely result in blurry images, but using some deep image compression/ GAN like techniques could work.\n\nSo theoretically, if someone gets their hands on the hashes, they might be able to reconstruct the original images. [deleted] WOW !",
    "CodeSignal companies Comment down below: preferably with a screenshot - note for 2022 summer/full time recruiting\n\nI will regularly update this post\n\n1.\t Two Sigma - Proctored\n2.\t Robinhood - 2 weeks\n3.\tCapitalOne\n4.\tAsana\n5.\tRoblox - 2 weeks\n6.\tDropbox\n7.\t  Uber (tbd)\n8.\teBay\n9.\tQuora - 2 weeks - Proctored\n10.  Databricks - 2 weeks - Proctored\n11. Samsara\n12. Square\n13. Circle Payments Asana Dropbox Heroes that don't wear capes What is a good score for the code signal test? Like Iâ€™m debating whether I should do it again if another company sends me one or just send them my score, my first one was from two sigma Roblox Square Following Samsara Uber Quora",
    "It depends where you go on Rainey. Container Bar and next door at Bungalow is becoming super dbaggy, Black Heart stays unique, Javelinas has its days and Craft Pride, Half Step and Lucille I still dig. Sat Nights in Austin though can be tough but nothing is dirty 6th ",
    "I've been maintaining a minimal Flask REST API to serve as a template for new projects. I've now added Flask 2 support among other things Lately when starting a new Flask project I found that I often had to rebuild a lot of functionality that I already built for different projects. To make my live easier I have been maintaining a minimal Flask REST API which can be used as a template for a new Flask REST API. I thought it might help other along as well!\n\nI recently updated the repo so that it now features:\n\n* Minimal Flask 2.X App\n* Async/Await Functionallity\n* Basic Type Hints\n* Unit tests\n* Integration With Redis For Background Tasks\n* App Structured Using Blueprints\n* Application Factory Pattern Used\n* Authentication Functionality Using JWT\n* Basic Database Functionality Included (SQLite3)\n* Rate Limiting Functionality Based on Flask-Limiter For All The Routes In The Authentication Blueprint\n* Support for .env and .flaskenv files build in\n\nYou can find the GitHub repo here:\n\nhttps://github.com/StefanVDWeide/flask-api-template\n\nHope this is useful for someone! Feedback is also always welcome! You have my appreciation and admiration, many thanks for this. Thank you for building this I can learn from it, I just started building my own API didnt know it was possible setting up the blueprint inside \\_\\_init\\_\\_! thanks for this <3 Nice. Will try it.",
    "House of Cheung at 71st and keystone, been going there for years, great food ",
    "Chinese food in Indy I just moved back to Indy after living in NYC for 16 years.  After having easy access to Chinatown in NYC, I am looking to see if there are similar options in Indy.  So far, I've found the Chinese food to be rather disappointing. House of Cheung at 71st and keystone, been going there for years, great food House of Cheung 71st and Keystone. Keystone is a mess with construction now though. Come from Allisonville if you can- 71st goes through Oriental Inn is really good on north Arlington on the East Side but you have to request the Korean Menu vs the regular one. Also Egg Roll #1 is really good. There used to be one good chef working at Szechuan Garden. He was previously the chef at Shanghai Lil, but I don't know where he's cooking now.  \nThe only real option in the city (in my opinion) is Asian Snack, the little kiosk inside Saraga on the west side.  \nEverything I've had from there has been real af. I second (third?) the suggestion for Egg Roll #1 on the south side! I moved from Los Angeles and my parents live in the SVG and so coming to Indy, found okay Chinese food places but not great ones. I go to Chicago to get my fix. Also, the lack of Chinese New Year celebrations here sucks. That said, my current favorite restaurant is in Castleton across from the Viet Hua market. It's called Eat Noodles and it's the most authentic and delicious Chinese in this area. They also have boba tea. I get the boba tea, put in an order, go to Viet Hua to pick up some groceries, and then head back to pick up the food. You should give it a try! The best I've had is Sichuan in Carmel.  \n\n\nI hear the restaurant inside the Buffet next to Viet Hou in Castleton is awesome, too.    \n\n\nTaste at Lucky Lou and Asian Snack are also up there.   Outside of those 4, if there's good authentic-quality Chinese in this town, I'd love to know about it.  \n\n\nAll the rest(including my experience with most of the places listed in this thread that are not one of the ones I mention) are typical, crap American Suburb Chinese. [Chow Express] (https://www.google.com/maps/place/Chow+Express/@39.8894997,-86.0459557,17z/data=!3m1!4b1!4m5!3m4!1s0x886b4ce692fae04d:0xe7a8788312309d5f!8m2!3d39.8894036!4d-86.0438622) at 75th and Shadeland is my favorite carry out place. I always need to add soy sauce but it's delicious. I would agree that Chinese food is crap in Indy.  Vietnamese is more prevalent for whatever reason.  There are Saigon Restaurant, King Wok and Sizzling Wok all in the west 38th and Lafayette Rd area.  Egg Roll #1 on the south side at 465 and Emerson.  And Pho 21 on the east side at 21st and Franklin.  They all serve good food and typically have a Chinese side to the menu, but they specialize in Vietnamese. Lucky Lou does lovely dim sum.",
    "Platform for efficient reading of AI/ML papers [R] Hey everyone, my friends and I have been working on a platform that aims to enable efficient reading and understanding of AI/ML papers. Our focus was to enable anyone to search and see trending papers, start a discussion for a specific paper, create annotations or notes for themselves, and most importantly, share everything with others if they want. I think it can be useful for the whole community here and I would love to hear your feedback.\n\nCheck it out -> [https://artigopapers.io/](https://artigopapers.io/)  \n\n\nEdit: Since some of you asked, we are currently in closed Beta, but if you would like to get an access, you can DM me. Small comment - the layout on mobile needs work I like the collaborative annotations. Wow looks very interesting! I will give it a look later today and let you know what I think! Thanks for sharing!\n\nBtw, where can I sign up? [removed] Super excited for this! But yes, agreed that a cleaned up mobile version would be nice to have. cool! great approach! I wonder how do you obtain the PDF files aside from arxiv? What if the paper is behind a paywall? I'm not sure how well I'd gel with something like this, but it's cool as fuck, and you deserve significant props for putting it together. Cograts ! Very cool project !!!",
    "I've been building a catalog of resources while learning ML, is this helpful to others?  I love the website style. It is so clean. It never hurts! I always like to see what resources people find helpful For calculus, professor Leonard's YouTube playlists are amazing. He has one for calc 1,2,3 and differential calc. Also has an amazing statistics course. Very nice OP.\n\nThough I personally find the specialization overhyped and underbaked at the moment, maybe another section about integration, deployment, pipelines, holistic solutions engineering and what is disgustingly referred to as â€œMLOpsâ€? I appreciate the inclusion of algorithms. I come from more of a stats background and only recently started learning classical algorithm theory. I think many data scientists are also missing a rigorous introduction to the field, despite how useful it is. I love it. I have been wanting to get started with ML but often find the websites cluttered, out of date or full of ads, this is perfect! Great!  \nI think that to organize content this way is a great way to learn, specially if you are critical about which links should go together.  \nI do something similar, but in the style of annotations in markdown files + links + books, it helps me a lot. In case you wanna take a look, it is there:  \nhttps://gitlab.com/lsbenitezpereira/engineering-knowledge-management/-/tree/master/01%20-%20Specific%20Subjects/06%20-%20Data%20Science This is great. I [added to my own list](https://www.williamrinehart.com/commonplace/#data-science-tools-and-resources). You might find some of the stuff interesting, so take as you please. You should remove TechLead imo, [he acts in bad faith](https://youtu.be/fUl-34SFEjk) and shouldn't be given a platform Thanks!",
    "Best Computer Vision Google Colab Notebooks List (Updated)  Thank you ! Thanks! This is gold ðŸ‘Œ Thanks for sharing !! Awesome!",
    "BulleX (BLX) ðŸ® 2000 BNB presale SOLD OUT in less than 10 secondsâ—Pancake Swap Launch 12th July 6PM EST ðŸš€ * **Revolutionary Way in Earning Passive Income**\n* **2000 BNB SOLD on PRESALE within seconds ðŸ’µ**\n* **BulleX is officially launching July 12, 6PM EST \\[10 PM UTC\\]** ðŸ“¢\n* **Hyper-Deflationary Buy-back Token That Automatically Rewards Holders With BNB ðŸ’°**\n* **Hold Bullex in Your Wallet and Watch as BNB Gets Distributed Amongst All Holders ðŸ¤‘**\n* **Bullex Contract Buys Back Any Sells. You Will Never See 2 Sells At Once! ðŸ“ˆ**\n\n# ðŸŒ’ About\n\nWhats the difference between Bullex and any other fork? Not your ordinary fork, BNB Reflection + BuyBack Contract. Team has added sophisticated functions that assist the proper execution of the contract. Presenting solution to over-exploited BuyBack functionality. The rewards contract will always have funds regardless of volume (Non-Reliant on volume). This was achieved by adding new dApps supporting the reward contract. Along with other resources, rewards contract will be funded with the BNB raised in the presale. Bullex^(TM) is also developing **Bullex Pad**, a platform where smart contracts can be launched, deployed and hold pre-sales. This comes with a full internal KYC system to attempt to resolve the current issues within the BSC Community, ensuring that any and all tokens launched on the Bullex Pad will be fully Rug-Proof and legitimate ventures. How does this benefit Bullex holders? Every token launched on the Bullex Pad will be charged a fee. The fee is a percentage of the supply of the token which is then airdropped to Bullex holders. According to how many Bullex tokens one holds, he/she will be entitled to a certain amount of airdropped tokens.  This will all be for the Rewards Contract - BulleX is revolutionizing the way we earn passive income.\n\n# ðŸŒ“ Launch Time\n\n* BulleX is officially launching July 12, 6PM EST \\[10 PM UTC\\].\n* Countdown TIMER on website LIVE.\n* Contract Address and Tokens released a day before launch.\n* Audit hopefully released before launch: depends on Techrate + Hashex.\n\n# ðŸŒ” Tokenomics\n\n* Team 7% (WHICH WILL BE LOCKED),\n* Partnerships 5%\n* Private Presale 9%\n* Public Presale 30.3%\n* Liquidity 46.7%\n\n**RATES**\n\n* Private Presale: 322,580 BLX per BNB\n* Public Presale: 303,000 BLX per BNB\n* PancakeSwap Price: 286,666 BLX per BNB\n\n**TAXES (16%)**\n\n* 10% BNB rewards\n* 4% Buy-Back\n* 2% Liquidity\n\n# ðŸŒ• Features\n\n1. **BNB Rewards Redistributed** **-** 10% of each transaction is distributed amongst all Bullex holders in BNB. If you hold a minimum of 10,000 Bullex, you are rewarded with BNB.\n2. **Auto Distribution - 30 minutes** **-** Bullex holders get BNB automatically rewarded to their address every 30 minutes. No need to claim, no need to request. It just appears in your wallet.\n3. **Buy-Back** **-** Every sell transaction is bought up by the contract to the extent of up to 10 BNB at once. Depending on the volume, Bullex tokens are bought back every time anyone sells Bullex.\n4. **Liquidity Pool Lock -** The Liquidity Pool pair is created after the public pre-sale and locked. 80% of the pre-sale is assigned to the LP Pair. 2% of each transaction is also sent to the LP. This stabilizes the price of Bullex.\n5. **Anti-Bot & Anti-Dump -** The contract stops bots from manipulating the buy-back feature by restricting and blacklisting the wallet after 2 consecutive sells within the same block or within a set time.\n6. **Community Driven -** A marketing wallet is setup to ensure Bullex is constantly being promoted on all Social Media Platforms. The community is given the power to vote for any and all transactions from this wallet.\n7. **Rewards Pool** \\-  BNB Rewards redistribution relies heavily on volume, trading and transactions. This means that if volume was to ever be depleted and run down, the rewards/redistribution will begin to dry up. Bullex is ensuring that the rewards continue to flow through a 'Rewards Pool'. An added tax that gets stored away in a Contract and is able to fund the Rewards Contract (Redistribution) when volume is generally low.This ensures that BNB Rewards always remain constant and projections are as accurate as possible.This contract will also be used in correlation with the Ad Revenue Share prospect.\n\n# ðŸŒ– How To Buy?\n\n1. Download the [Metamask](https://metamask.io/) app and setup your wallet.\n2. Purchase BNB on BSC (Binance Smart Chain).\n3. Open Browser (settings bar on the left) and navigate to [PancakeSwap](https://pancakeswap.finance/).\n4. Click select a currency and enter the contract address.\n5. Before swapping, click on the wheel icon and **set slippage to 16%.**\n6. Enter the amount of Bullex you would like to buy and hit **swap.**\n7. Confirm the transaction in your wallet. Hold Bullex for BNB rewards.\n\n&#x200B;\n\n# ðŸŒ— For more information please view contact details below â¬‡ï¸\n\n[Website](https://bullextoken.com/) | [Telegram](https://t.me/bullextoken) | [Twitter](https://twitter.com/bullextoken) | [Instagram](https://www.instagram.com/bullextoken/)\n\n&#x200B;\n\n# ðŸŒ˜ BulleX Sooo bullish!! GREAT DUAL SYSTEM! \n\nPASSIVE INCOME = FINANCIAL FREEDOM! #BLX #BULLEX #BulleXToken #BULLEXARMY\n\nâœ… doxxed developers from Australia\nâœ… 10% BNB rewards from holding\nâœ… 4% buyback feature\nâœ… BulleX launchpad, charts, tools â€” with revenue distributed to holders\nâœ…antibot antiwhale anti dump\nâœ… +10K members on TG\nhttps://t.me/bullextoken View in your timezone:  \n[12th July 6PM EDT][0]  \n\n[0]: https://timee.io/20210712T2200?tl=BulleX%20(BLX)%20%F0%9F%90%AE%202000%20BNB%20presale%20SOLD%20OUT%20in%20less%20than%2010%20seconds%E2%9D%97Pancake%20Swap%20Launch%2012th%20July%206PM%20EST%20%F0%9F%9A%80\n\n\n^(_*Assumed EDT instead of EST because DST is observed_) This is worth of check. Doxxed team and from Winland! https://t.me/addictfinance",
    "Udemy 10 (100% off Coupons) Programming Courses [Limited Time]  \n\nGood Evening everyone,\n\nLove Learning, Just found some of the top courses to learn programming on Udemy. Some of the instructors are giving 100% off coupons due to the quarantine. Grabbed most of them from [r/FreeUdemyCoupons](https://www.reddit.com/r/FreeUdemyCoupons/) and some from the Facebook group. Might help some of you out. Let's learn together\n\nOnce you enrol on this course you can get lifetime updates\n\nwill try adding more courses here (by updating the thread) as I find them.\n\n1. [Learn to Code in Python 3: Programming beginner to advanced](https://www.udemy.com/course/learn-python-programming-a-step-by-step-course-to-beginners/?couponCode=PYTHON_JUL_FREE)\n2. [Learn to code with Python from scratch.](https://www.udemy.com/course/learn-python-from-scratch-create-your-own-apps/?couponCode=7D597ACA6DCC6A36DFDB)\n3. [Bootcamp of Data Science with Python \\[+250 exercises\\]\\[A-Z\\]](https://www.udemy.com/course/bootcamp-data-science-with-python/?couponCode=FREE2021)\n4. [Machine Learning Bootcamp: SVM,Kmeans,KNN,LinReg,PCA,DBS](https://www.udemy.com/course/smtbm-ml-py/?couponCode=SMTML10JUL)\n5. [SQL with PostgreSQL for Beginners: Analyze | Manipulate Data](https://www.udemy.com/course/sql-with-postgresql-for-beginners-analyze-manipulate-data/?couponCode=639540BA19CF573CB425)\n6. [Time Series Analysis Real-World](https://www.udemy.com/course/time-series-analysis-real-world-projects-in-python/?couponCode=JULY_SALE)[ Projects in Python](https://www.udemy.com/course/time-series-analysis-real-world-projects-in-python/?couponCode=JULY_SALE)\n7. [Exploratory Data Analysis (EDA) for Machine Learning](https://www.udemy.com/course/exploratory-data-analysis-for-ml/?couponCode=JULY-EDA)\n8. [Mastering Time Series Forecasting with Python](https://www.udemy.com/course/complete-practical-time-series-forecasting-in-python/?couponCode=28F592A2D8974526A5B9)\n9. [SQLite Databases | Python Programming: (Build App and API )](https://www.udemy.com/course/sqlite-databases-python-programming-build-app-and-api/?couponCode=97A1F9273FDBE3346C7B)\n10. [Python and JavaScript for beginners: Build 10 Projects](https://www.udemy.com/course/python-and-javascript-for-beginners-build-10-projects/?couponCode=401564D04D228A371AF5) [deleted] If I could I would 10 upvotes for your effort and info.\nCheers mate Doesn't seem to work for existing users of Udemy it seems. Shame. Any recommendations? I love you ðŸ˜˜ The machine learning bootcamp and the time series analysis are 19.99 again :( but the other ones are still free at least for 1 day more thanks!! And worth every penny. /s Incredible. Thanks for sharing bless you brother. Thanks to the OP for this amazing list. However, if you are looking for those courses they are no longer available for free as of today.",
    "Programmers, Teach Non-Geeks The True Cost of Interruptions (2014)  I'm happiest in my job when I can get into flow mode and time disappears. It's when I get my best work done and it is always cut short by bullshit. I swear I spend more time in meetings with sales people than I do actually programming now, and Iâ€™m meant to be a senior developer :/ >youâ€™re going to be ordering a pizza and doing this again at 7 PM after everyone else leaves so that you can have some peace and quiet to work.\n\nDo people actually still do this? Sacrifice their own time off to compensate for their employer's unsuitable work environment? I work with a very small team, 3-4 devs, but lots of other engineers around to distract. When I was full time in the office I told people, \"E-mail me if the response can wait a day or two, text/message me if it can wait an hour or so and only call or walk up to me while I'm coding if you absolutely need the answer right now and are otherwise blocked. If I'm not coding then feel free to distract me for whatever.\" It worked really, really well. If I am ever a manager I think I would make this policy for my group. Is it rude to send this to my wife Ah yes the 3-4 1 hour long \"Agile\" meetings a day. And they wonder why the team of 3 which includes 1 guy writing most of the code and a 20 year old QA guy fuck up from time to time and \"embarrass\" the boss with a bug that impacts $2K in transactions out of $2B a month. Please kill me. [I regularly send this comic to people in my company.](https://i.imgur.com/3uyRWGJ.jpeg) Working from home over the pandemic has been amazing for this. If I'm deep in code I just mute Slack and then deal with it afterwards. If it's really urgent people can choose to send me a notification anyway, but the simple act of having to click that extra button to do so makes them question whether it's that urgent and usually they don't bother. ::In my third hour of flow, time and space have become meaningless, the laws of the universe are bending to my will, code seemingly appearing ou--::  \n::INCOMING,SOUL-SHATTERING SLACK MESSAGE:: \"HEY, I see you forgot to update your tasks in rally, can you please do that before the status meeting. I know I've asked you to do this in the past. Is something wrong? Is it too much to ask to get you to update your tasks in rally before the status meeting?\" Reminds me of a time when i worked at a company that had a weird culture of \"communication\" where the floors barely had any walls nor doors to \"encourage\" human contact and inevitably someone would talk to me every now and then interrupting hour-long sequences of debugging and investigation.\n\nBought a massive headphone and blasted music loud enough that i couldn't hear anything around me and sometimes my manager would spend around 15 minutes (literally) right next to me expecting i would remove the phones to listen to him. I never did.",
    "Any â€œdebatesâ€ like tabs vs spaces for mathematicians? For example, is water wet? \nOr for programmers, tabs vs spaces?\n\nDo mathematicians have anything people often debate about? Related to notation, or anything? Is 0 a natural number? Probably the closest to tabs vs spaces in writing mathematics is choosing in LaTeX whether in-line mathematics should be enclosed in dollar signs or backslash-parentheses:\n\n* $...$ or \\\\(...\\\\)\n\nIn terms of notation, here are some other dueling conventions:\n\n* Matrices: square brackets or parentheses?\n* Set subtraction: [backslash](https://www.tutorialspoint.com/tex_commands/setminus.htm), [small backslash](https://www.tutorialspoint.com/tex_commands/smallsetminus.htm), or minus sign?\n* Set builder notation: colon or vertical line? I had a professor who hated fraction notation and wished he could use negative exponents exclusively but I don't think it counts as a \"debate\" when its only one guy. \"Strictly increasing/increasing\" vs. \"Increasing/nondecreasing\" In French based educational curriculums and systems, 0 is both a neagtive and a positive number...making it the only number with both properties.\nIn the US, 0 is neither positive nor negative I think.. which makes it neutral.!?\n\nNote: to say that zero is neutral among teachers over here is blasphemy.... there are only two states for a real number and to introduce a third is unheard of.\n\nPositive in my country (French based) means greater than or equal to 0.\nStrictly positive means just greater than zero, because zero is not strictly positive.\nNonnegative means greater than 0.\n\nWhile teaching American system students, I found out that positive means greater than zero. And \"Nonnegative\" means greater than or equal to zero. Is the derivative of a scalar with respect to a vector a row or a column. At my university it was whether a graph with no vertices is a graph or not. Does collaborators who insist on using their own long, convoluted, non-standard list of LaTeX macros, custom font packages, and other super specific nonstandard typesetting conventions count? Cus that. \\phi versus \\varphi How do you denote \"is a subset of or equal to\"?",
    "How do I step up my game? I am interning at a high-growth unicorn this summer. Work is great, pay is good, but I want to target the bigger unicorns (think top 30 non-finance companies on [levels.fyi](https://levels.fyi)), and the FAANGs for full-time roles. Last time, I was too late for any of the major FAANGs to even consider me, and I basically got lucky with this unicorn. (That was because I wasn't in the US when applications started, and I'm an international student).   \n\n\nHow do I level up my game? I did mostly LC easies and mediums, and that did the trick, but I'm not sure that's gonna work out if I wanna target the big players. Basically, I got lucky this time, and I want to eliminate luck from the equation as much as possible. Should I target more referrals? What worked for you, and what didn't? Really curious to know if someone's been in a similar situation. Are you referring to the â€œpopular companiesâ€ from this list https://www.levels.fyi/company/ Yes this is a survey of what I was referring to. A bunch of 30-40 companies that would qualify as the top tier of tech companies. >Gotcha, well if youre looking to get into FANG/PAULS, the grind starts today. (ive gotten internship offers at these companies, but every experience is different so take this w a grain of salt)  \n>  \n>steps to take: ( i assume you have a good resume with decent personal projects so im not going to talk about those)\n\n1. start leetcoding\n2. find connections working at these companies\n3. double down on mocks. [pramp.com](https://pramp.com) \\- these companies are beginning to ask harder and harder questions. Focus on meaty stuff (bfs/dfs, dynamic programming, sliding window algos etc)\n4. hit up the connections you found in step 2 once youre confident and apps open. This will increase your chances by alot\n5. interview\n6. get the offer, share your journey and help someone else on reddit :)",
    "Advice on how to quickly become productive in Go (Python developer on a team using Go for backend) Hi everyone,   \nI have always been interested in Go but I am prone to awful analysis paralysis when I try to find the so-called best learning resources. This time, by mere coincidence my new team uses Go for all our back-end (essentially, it's a set of web services) and I have a chance, due to how small our team is, to step in and take part in the development. \n\nI have been a data scientist for around 2.5 years and I feel pretty confident in Python. I did my homework and checked most posts asking for Go learning resources. The most common ones are Tour of Go (done it already), Go By Example (partly read it), Effective Go (still reading through it), Learning Go with Tests (I don't like it very much honestly because the explanations seem a bit light in terms of depth). \n\nCan you please help me finalize my list for getting up and running with Go as quickly as possible. I am definitely not interested in resources teaching you loops and conditionals as concepts. Ideally, that would be just a learning resource that covers the essentials with enough details to be productive right away. It might be even more about the best practices and common gotcha to be aware of immediately. So far, I have seen 50 shades of Go and Darker Corners of Go (those look quite promising). \n\nProbably, it makes sense to just read The Go Programming Language from cover to cover (except the chapter on packages and modules) and then just Google things on the go. \n\nThanks in advance! I found Gophercises (https://gophercises.com) helpful when I was learning Go. If you want a crash course on Go web development with great explanations I would recommend Lets Go by Alex Edwards.  [Book Link](https://lets-go.alexedwards.net) As a Flask developer I loved this bookâ€™s approach to explaining what it takes to build a reasonable website in Go without using a monolithic framework. I find that I learn new programming languages best when there's a project I need to do that requires that language.\n\nFor instance, I had looked at Python before, but I really *learned* Python when my workplace had to migrate email accounts from one IMAP server to another; and the head sysadmin handed me a chunk of Python code he'd written to do this, that I needed to maintain and improve.\n\nI really learned Go when I needed to write a load-testing (i.e. DoS testing) tool for a specific work project. It needed to be (1) statically compiled to be deployed without dependencies, and (2) highly concurrent (ended up being 1k+ goroutines); so Go was a clearly better choice than Python or C++.\n\n(In that case, it was really more \"I want to not think about how to schedule thousands of threads that handle network I/O, so I have to write in Go.\")\n\nLater, I used Go for protobuf-based servers and automation for them. Turns out it's not *just* for attack tools. You might want to take a look at my book, \"Learning Go\", published by O'Reilly earlier this year. It's targeted at developers who are already familiar with another language. \n\nYou can find it on O'Reilly at: [https://learning.oreilly.com/library/view/learning-go/9781492077206/](https://learning.oreilly.com/library/view/learning-go/9781492077206/) (It's the 3rd most popular book on O'Reilly Learning) or on Amazon US at: [https://www.amazon.com/Learning-Go-Idiomatic-Real-World-Programming/dp/1492077216](https://www.amazon.com/Learning-Go-Idiomatic-Real-World-Programming/dp/1492077216) \n\nIf you don't have access to O'Reilly Learning, you can get a 30-day trial at [https://learning.oreilly.com/get-learning/?code=LEARNINGGO21](https://learning.oreilly.com/get-learning/?code=LEARNINGGO21) I would make two recommendations:\n\n1. Make sure you have a scratch pad that you can test things out, ideas, reproduce minimal examples of things. I've had this for years and it's been very helpful. I actually do this for each tech I need to work with, for Go you don't need more than a \\`tmp\\` folder with a single \\`main.go\\` file, for more complicated tech I usually have a \\`<tech>-playground\\` repo with a Makefile, etc.\n2. For the first couple of months, if not more, just work on conforming with how things are. Do yourself a massive favor, and don't come in to a new codebase with a new language and try to be clever. Just learn what's the current way things are being done, and try to understand why they're done this way. If you recognize quick simple wins for the team/codebase, by all means bring them up, but do yourself a favor and come in respectful. It's too common for a new dev to come in and immediately try to alter an entire codebase, worked on by a whole team to his view of things.\n\nDon't stress over it! Go is a language that favors simplicity over cleverness. It's definitely on the easier side of languages to become productive and even proficient in. Iâ€™ve just started doing this last week.\n\nIâ€™m using this as a reference book. \n\nhttps://www.practical-go-lessons.com/\n\nAnd this for practical learning \n\nhttps://gophercises.com/\n\nIâ€™m thinking the two of them will be enough to get a decent level\n\nThereâ€™s so many resources on the topic so hope that helps narrow it down! You need to leverage the awesome features of Go not found in Python:\n\n* Static typing, a brilliant time and life saver.\n* Verbose errors handling, it is quite annoying at first, but it is actually one of the best reason to use Go.\n* go fmt for standardizing code formatting universally. Do it with automatically on file save with your favorite text editor.\n* Easy concurrency with channel, sync packages, etc, build a tons of concurrency pattern with simple channel and sync packages, for example: you can create 100 concurrent workers at a time (make them wait for incoming message on channel, on infinite loop because that's what they are), make them receive a channel (of any data type) for such worker to process, and send 10000 data of that data type to that channel and wait for all of them to complete with waitGroups. You want to build a streaming mechanism in a single Go instance? You can do that with or-done-channel pattern. Or maybe you want to do some weird fan in / fan out channels? It is easy to do it as well in Go. 100 concurrent workers are not enough? You can spawn 1000 or 10000 workers if you want.\n* Awesome http package, by default http server can serve concurrent requests out of the box. You don't need anything else. You don't need fancy configs.\n\nWe don't joke when we say that Go is awesome for building concurrent apps. Elixir and Erlang also has it, but combine it with static typing Go has somewhat better safety about sending data to and receive data from channel. \n\nhttps://www.oreilly.com/library/view/concurrency-in-go/9781491941294/ch04.html\n\nhttps://blog.golang.org/pipelines go in with gobyexamples it will get you started look at other places to because its fairly new language and tons of resource doenat exist If I'm honest, the best method I've found so far after covering the basics of the language is to implement or re-implement a toy project in Go, leaning heavily on the following to make design decisions:\n\n- Effective Go\n- Go Proverbs (https://go-proverbs.github.io/)\n- Go CodeReviewComments (https://github.com/golang/go/wiki/CodeReviewComments)\n\nI made a few projects like a Merkle Tree implementation, a CRUD rest api, a helper to manage some configuration stuff (cli interface to my dotfiles), game engine, etc...\n\nNothing helped me get better at Go than working on these. Totally prepared to get a Golang job (came from Python as well) https://exercism.io/tracks/go is a good one, and at least a real one, :)",
    "I made a YouTube playlist of me building a real website from scratch of one of my clients and I explain everything I do and why to help beginners learn how to think like a developer. This is for everyone wishing they could job shadow someone as they worked. For anyone wanting to learn web development - Hereâ€™s the playlist:\n\nhttps://youtube.com/playlist?list=PLMPdeA59PPg2Cbd3cul0wFOY2KCbb4IID\n\nLots of good stuff in this one to learn how to make a mobile first and responsive website with no frameworks, just html and css. \n\nI go over all my decisions and explain why I do things a certain way. I did not plan this video out - I run into problems and I talk through them. I left everything on these videos so you can learn how to think through problems yourself when you get started building your own websites. \n\nSo I explain everything I do and why I make the decisions I make so others can see HOW to think like a front end developer. \n\nI also go over how to transfer a desktop design to a mobile design and how to decide what to keep and what to change. Itâ€™s not always easy to figure out how to make a desktop design into a mobile one, but thatâ€™s what I do here and hopefully it helps!\n\nIf you liked that, hereâ€™s the series I did last week for a MUCH more complicated and very modern design with a ton of useful css tricks and everything I mention earlier:\n\nhttps://youtube.com/playlist?list=PLMPdeA59PPg2sLFYU3f-vITZgOWVSCZ6e\n\nEDIT:\n\nHereâ€™s a live demo link to the site I made in the video all complete if yâ€™all wanted to see it:\n\nhttps://forcedevolution.netlify.app\n\nStill not finalized yet. Gotta write content and work with my other developer to integrate my code into Shopify and insert the store where it needs to be.\n\nHopefully this is helpful. Itâ€™s not exactly a tutorial, more like an implementation of what tutorials try to teach you. So if youâ€™re tired of tutorial hell this should be refreshing. Feel free to ask any questions! Nice. Thereâ€™s a plethora of resources for learning programming/web dev online, but I feel like there is a huge lack of examples of real world apps. I've always thought of doing something like this but the time and planning a structure to explain the essencials threw me off. \n\nRespect for your work and commitment deserved the award! This looks awesome btw Nice! I need to come back to this is 3 weeks! Thanks Thank you for this Awesome! Will check it out thank you Thank you for this! I love the idea being able to see a real world project being built in real time, with real problems being solved along the way. This is a great idea and Iâ€™ll definitely be watching both! Awesome man. Thereâ€™s lots of tutorials out there on how to build specific bits and pieces but not much that explains the order in which a website is constructed and the logic behind it.\n\nLook forward to watching ðŸ‘ The real MVP right there.",
    "An alternative to long if conditions, what are your thoughts?  [deleted] Well the \"get\" is wrong. If it gives you None, it will crash saying that NoneType cannot be invoked. So, might as well do [input] instead of .get and catch (or don't) the KeyError.\n\nThe rest of the pattern is common knowledge and works well. Callbacks are one of the most useful things in python. \"functools. partial\" is especially powerful. This pattern is useful to turn a worst case O(n) comparison chain into a O(1) function lookup. It actually only takes a couple chained conditions for the function lookup to be faster, especially when the dict is created once and reused for every subsequent invocation. I'd recommend assigning the dict to a global variable and then using it wherever you need to dispatch to the appropriate function.\n\nI've seen people mentioning switch/match statements but:\n\n1. Match statements are only available in the unreleased python 3.10, the language doesn't currently have any kind of switch statement.\n\n2. Even when match statements will be available they will still be slower than the dict approach because each case is tested one after the other. Python match statements have the same linear complexity as chained elif statements, the interpreter will not generate a lookup table like in some other languages. What font is that? So elegant I have used before with a small change. In the default, I have the default function. You can go even further and use a decorator to help annotate your functions with the associated values.\n\n    FUNCS = {}\n    \n    def handler(value):\n        def inner(func):\n            FUNCS[value] = func\n            return func\n        return inner\n    \n    @handler('VALUE1')\n    def foo(arg1):\n        ...\n    \n    @handler('VALUE2')\n    def bar(arg1):\n        ...\n    \n    def handle_input(input):\n        return FUNCS.get(input, default_func)(some_arg) Becareful with that `None` there I will say I do like this and I use it all the time in production code but for readability I usually donâ€™t chain get with calling the function.\n\nIt seems to make sense to me to go\n\n    func_to_call = lookup.get(input, default_func)\n    func_to_call(arg, kw_arg=True)\n\nThen itâ€™s really explicit what youâ€™re doing. Youâ€™re looking up the function you want, then calling it. Iâ€™ve never seen this and this is amazing. Hereâ€™s a hugz award for bringing this to my notice Isnâ€™t this the pattern thatâ€™s recommended in lieu of having case statements?",
    "Brian Alsruhe - QUICK Mobility Drills to Fix Your FRONT RACK!  **Reminder:** r/weightroom is a place for serious, useful discussion. Top level comments outside the Daily Thread that are off-topic, low effort, or demonstrate you didn't read the thread at all will result in a ban. [See here.](https://www.reddit.com/r/weightroom/comments/85x1dg/please_read_rules_update_announcement/) Please help us keep discussion quality high by reporting such comments.        \n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/weightroom) if you have any questions or concerns.* Would it be okay for me to shill my own video in the comments on how I set my grip for front squats?\n\nI use a weird hybrid grip that has been stable for a 2xBW front squat. I know people here are probably familiar with a few resources on improving your front rack, but I still find this one is worth sharing.\n\nI feel dumb writing this but: a good front rack is a game changer in any lift that uses it (i.e. front squat, push press, clean, power clean, jerk).\n\nSo if you do any of those lifts, it's definitely worth it to invest a couple of minutes everyday to improve your position there.\n\nAs always, Brian gives a pretty good range of options that may benefit different people. No need to do all of them. Just try one for a few weeks and see if it works for you.\n\nOnce that mobility is first developed, the movements themselves do a pretty good job of maintaining it, although one can always do one or two drills when feeling particularly tight. Here's me shilling a video I shot about a year back on how I set my front squat grip.\n\nI've been able to manage 385 at 190, so the coveted 2xBW metric.\n\nHoping to push it to 4 plate sometime.\n\n[shill shill shill](https://www.instagram.com/p/CCRvS3ZJ6Vm/) [removed] I stopped doing rack position front squats because they were torture. Much more comfortable crossing arms. But I will definitely take a look at this to see if it will help I just did my first ever sets of real front squats last week. Before I was doing that crossed arms thing but above two plates holding the bar was very hard.\n\nObviously I donâ€™t have experience with it, but thinking at some point I would never be able to get in that position and having just gotten it, I remember very clearly what made it work for me. It was a lot of stretching (forearms and lats), and those klokov drills where you start in a back squat position and progressively try to drive your elbows forward.\n\nThanks for the link Saw a video from Alex Trotsky yesterday about front squatting strapped up to bump up dat front rack mobility. Shill away! A solid front rack has always eluded me so I'll gladly take any resources I can! I think so.",
    "Well, when you put it that way....  By my house they put up an 8 foot steel fence to keep the homeless away. If your pastor is wearing $2,000.00 sneakers and a $5,000.00 outfit the chances your church is feeding the poor are slim. Tax those megachurches first. Make it fair they can write off 100% of tax burden with enough good work. It will be interesting to see how much new charity some of these churches have to do. I work at a garden store and weâ€™ve had a lady buy well over $2k in flowers using the church card this year alone. Obviously I love plants, but I wonder if the parishioners know how much of their weekly offerings are going into flower boxes and patio pots. Nobody bats an eye when the churches take PPP Money.  Joel Osteen took PPP Money.  Never paid any taxes. Iâ€™m just gonna say itâ€¦ this will give churches another reason to beg for even more money, because theyâ€™re â€œ*being attacked*â€ and thus, â€œ*we must fight the good fight*â€ ; because you know, itâ€™s an *ATTACK* on the righteous from the devil lol But, if you tax the Churches, theyâ€™ll take their operations to overseas tax havens...... #MormonChurch\n\nhttps://www.sltrib.com/news/2020/02/08/lds-church-kept-lid-its-b/\n\n100 Billion wow, that is such a good argument for taxing churches I work for a church.  Taxing churches is just.  It would hurt me and possibly my family as I assume giving would decrease.  However, I'm surprised more churches aren't in favor of this as it keeps religion and state separated.  Then churches could say whatever they won't about which ever president is running the country.  Or which candidate looks more like Jesus.  Seems like churches who were in favor of our last president didn't seem to mind lending support from them pulpit when many preachers who may have been less than happy with three last president didn't speak out in order to follow laws.",
    "A job for you: Archiving Parler posts from 6/1  **Edit:** Thank you so much for the awards! :)  \n\n\nTeam Archive - Parler Project: [irc](https://webirc.hackint.org/#irc://irc.hackint.org/#neparlepas) | [website](https://archiveteam.org/) | [tracker](https://tracker.archiveteam.org/parler/#show-all) | [graphs](https://atdash.meo.ws/d/attv2/archive-team-tracker-charts-v2?orgId=1&refresh=1m&var-project=parler)\n\nHere's instructions for quickly joining the Archive Team's distributed download of Parler. This project submits to the [Internet Archive](https://web.archive.org/web/*/parler.com):\n\n**Linux:** (Docker):\n\n>docker run --detach --name at\\_parler --restart unless-stopped [atdr.meo.ws/archiveteam/parler-grab:latest](https://atdr.meo.ws/archiveteam/parler-grab:latest) \\--concurrent 20 DataHoarder\n\nWatching activity from the cli:\n\n>docker logs -f --tail 10 at\\_parler\n\n**Windows (Docker):**\n\n1. [Install Docker](https://docs.docker.com/docker-for-windows/install/)\n2. Start docker, skip tutorial\n3. Start > Run > cmd\n4. c:\\\\Users\\\\You> **docker run -d  --name at\\_parler --restart unless-stopped atdr.meo.ws/archiveteam/parler-grab:latest --concurrent 20 DataHoarder**\n5. c:\\\\Users\\\\You> **docker run -d --name watchtower --restart unless-stopped -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower  -i 30 --cleanup**\n\n**NOTE:** Step #5, above, is a container that will update your Docker containers automatically when there is an update available. This will update any Docker container on your system. If you don't want that, skip step #5. If the Parler project is your only Docker container, then it's best to keep it up to date with step #5\n\nOnce it downloads and starts the image, you can watch activity in the Docker app under Containers / Apps (left side) > at\\_parler\n\nTomorrow, assuming Parler is offline, you can stop and remove the image:\n\n1. Start > run > cmd\n2. c:\\\\Users\\\\You> **docker stop at\\_parler**\n3. c:\\\\Users\\\\You> **docker stop watchtower**\n4. c:\\\\Users\\\\You> **docker container rm at\\_parler**\n5. c:\\\\Users\\\\You> **docker container rm watchtower**\n6. Un-install Docker (if desired) from Add/Remove Programs\n\n*If everyone here ran one Docker image just for today, we could easily push DataHoarder to the* [*top 5 contributors*](https://atdash.meo.ws/d/attv2/archive-team-tracker-charts-v2?orgId=1&refresh=1m&var-project=parler) *for Parler archiving.*\n\nEdit: [Some entertainment while you work](https://donk.sh/d/ett07kryjh.png) | [Favorite IRC Comment](https://i.imgur.com/DetLbgp.png) ;) This just became even more important!\n\nParler CEO â€œEvery vendor from text message services to email providers to our lawyers all ditched us too on the same day,â€ Matze said today on Fox News. Full Story: https://deadline.com/2021/01/parler-ceo-says-service-dropped-by-every-vendor-and-could-end-the-company-1234670607/ Seems like this is a bit confusing for those of us who don't want to look at the twitter feed or are working from mobile.  Essentially this is a list of links to be used with wget.  \nhttps://www.archiveteam.org/index.php?title=Wget_with_WARC_output  \nI am not going to dig any further as I am feeling particularly lazy today, so maybe someone smarter and less lazy than I can get it all figured out. :P Explain me like im an idiot. Whats the best way to backup this stuff using those .txt files?\n\nCommands please. Please don't everyone do this independently. There's a centralized ArchiveTeam project which will have a much better chance of getting everything: https://github.com/ArchiveTeam/parler-grab. She's dead, Jim. \n\nhttps://imgur.com/a/d017NXy\n\nSite and posts are down. Videos can still be grabbed at this time. (video.parler.com subdomain) RELEASE: Every Parler post made during the 06/01/2021 US Capitol riots. \n\n***\n\nposted by [@donk_enby](https://twitter.com/donk_enby)\n\n[Link in Tweet](https://donk.sh/06d639b2-0252-4b1e-883b-f275eff7e792/)\n\n^[(Github)](https://github.com/username) ^| ^[(What'sâ€…new)](https://github.com/username) Annndd Parler is down now by the looks of it, should we keep our containers running to make sure everything gets uploaded if we're receiving a failed rsync command?  \nrsync error: error starting client-server protocol (code 5) at main.c(1675) \\[sender=3.1.3\\]\n\nI figure it's still trying to upload to the archive teams servers Wrote a [python script](https://pastebin.com/B7zRJrjX) that could make things easier. Just run this from the same directory as you downloaded the text files and pass it the txt file name as a parameter one at a time (you could probably make bash script on top of this or some xarg trickery to make it a one liner).\n\nedit:  I'm an idiot, see [https://www.howtogeek.com/281663/how-to-use-wget-the-ultimate-command-line-downloading-tool/](https://www.howtogeek.com/281663/how-to-use-wget-the-ultimate-command-line-downloading-tool/). This functionality is already built into wget with the \"i\" flag lol The DOJ might have a field day with this. Could help them track down people who were at ground zero and participating that day. \"Doing the lord's work\" as it were with this. ðŸ‘ðŸ¾",
    "[SERIOUS] What is a seemingly normal photo that has a disturbing backstory?  **Attention! [Serious] Tag Notice**\n\n* [Jokes, puns, and off-topic comments are not permitted](https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_6-) in **any** comment, parent or child.\n\n* Parent comments that aren't from the target group will be removed, along with their child replies. \n\n* Report comments that violate these rules.\n\nPosts that have few relevant answers within the first hour, and posts that are not appropriate for the [Serious] tag will be removed. Consider doing an AMA request instead.\n\nThanks for your cooperation and enjoy the discussion!\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/AskReddit) if you have any questions or concerns.* https://imgur.com/a/WqgPQcW\n\nThis is the photo Kurt Diemberger took after his companion, the illustrious alpinist Hermann Buhl, fell into the abyss on the Himalayan mountain Chogolisa. Buhl was walking behind Diemberger and momentarily left the trail after which he fell through an overhanging cornice. He remains in the ice. [This is a pic of the 1970's-era gameshow,](https://i.ytimg.com/vi/8Kss30IQV0A/maxresdefault.jpg) The Dating Game.\n\nThe circled man is serial killer Rodney Alcala. By the time of that appearance on the show, [he had raped several women and murdered at least one.](https://en.wikipedia.org/wiki/Rodney_Alcala#Dating_Game_appearance)\n\n[He won the game,](https://allthatsinteresting.com/wordpress/wp-content/uploads/2017/10/alcala-on-dating-game.jpg) but the woman never went on the date with him. You can imagine how relieved she is. This isnâ€™t as gruesome as some of the others, but I always thought this guy looked more like a male model than an assassin.\r  \n\r  \n[https://en.wikipedia.org/wiki/File:Lewis\\_Payne\\_cwpb.04208\\_(cropped).jpg](https://en.wikipedia.org/wiki/File:Lewis_Payne_cwpb.04208_(cropped).jpg)\r  \n\r  \nLewis Powell was a co-conspirator of John Wilkes Booth and he attempted to assassinate William Henry Seward (the US Secretary of State).\r  \n\r  \nThis is a colorized digital restoration of one of his photos:\r  \n\r  \n[https://marinamaral.com/portfolio/lewis-powell/](https://marinamaral.com/portfolio/lewis-powell/)\r  \n\r  \nI guess the photo is only â€œseemingly normalâ€ if you donâ€™t notice the cuffs. The leading image on Franklin Delano Floyd's Wikipedia page: [A father and his daughter posing for a family photo](https://en.wikipedia.org/wiki/Franklin_Delano_Floyd).\n\nIn actuality, the little girl is Floyd's stepdaughter, Suzanne Marie Sevakis, who he'd kidnapped around 1974, when Suzanne was under 10 years old.  \nHe would go on to raise her as his daughter, putting her through highschool under several pseudonyms, then have a son with her in 1988^1 and marry her in 1989, under the name Tonya Hughes.  \n  \nBy 1990, Tonya/Suzanne had decided to leave Floyd, and take her son, Michael, with her. In April of that year, she was found beaten and bruised on the side of a highway, and subsequently died in hospital. Michael went into foster care and was adopted by a loving family, only to be kidnapped by Floyd in 1994 and to never be seen again.  \n  \nFloyd was arrested in late 1994. The news about his late 2nd wife being his kidnapped stepdaughter didn't come out until 2014.  \n   \n-----  \n  \n[1]: Someone rightly pointed out that Michael is not Floyd's biological son. This was only discovered when DNA testing was performed as part of Michael's adoption in 1994, when he was 4-5 years old. Presumably, up until that point, Floyd had reason to believe he *was* the biological father: photos of his were found that depicted sexual exploitation of Suzanne/Tonya from the age of 4.  \n  \n  \n^(edit: wording & edit2: footnote) [https://i.redd.it/lzcf33z3tjf31.png](https://i.redd.it/lzcf33z3tjf31.png)\n\nThis picture of First Lady Rosalynn Carter shaking hands with serial killer John Wayne Gacy, who was active in politics at the time. Raymond Cabalfin Jr, 19, was filmed leaping into the American River near Sacramento on May 11, 2017 after hiking with friends, but he was overcome by strong currents and icy water and died.\n\nI still remember this 4 years later. Very sad, he was just out with friends having fun. RIP Ray, I didnâ€™t know you but will always remember you. \n\nhttps://www.dailymail.co.uk/news/article-4555430/Body-hunt-teen-feared-drowned-California.html#v-5282108662491888450\n\nThere are photos from the video, but the video shows the situation. [Eyes of Hate, a candid photograph of Goebbels after he finds out his photographer was Jewish, 1933](https://rarehistoricalphotos.com/goebbels-eisenstaedt-1933/)\nIf looks could killâ€¦\n \n\nâ€œI found him sitting alone at a folding table on the lawn of the hotel. I photographed him from a distance without him being aware of it. As documentary reportage, the picture may have some value: it suggests his aloofness. Later I found him at the same table surrounded by aides and bodyguards. Goebbels seemed so small, while his bodyguards were huge. I walked up close and photographed Goebbels. It was horrible.\n\nHe looked up at me with an expression full of hate. The result, however, was a much stronger photograph. There is no substitute for close personal contact and involvement with a subject, no matter how unpleasant it may be. He looked at me with hateful eyes and waited for me to wither. But I didnâ€™t wither. If I have a camera in my hand, I donâ€™t know fear.â€ This [photo](https://extra.globo.com/incoming/7408345-ca9-545/w640h360-PROP/boatekiss.jpg) of Nightclub KISS posted on facebook by one of the DJ's. Later that night, 245 people would die and more than 680+ would be injured when the band \"Gurizada Fandangueira\" lit a flare that ignited the flammable acoustic foam in the ceiling.   \n\n\nThere wasn't enough emergency exits, it was overcrowded by hundreds and the security guards trapped the victims inside in an attemp to organize the crowd.  \n\n\nThe responsible are still unpunished.  \n[https://en.wikipedia.org/wiki/Kiss\\_nightclub\\_fire](https://en.wikipedia.org/wiki/Kiss_nightclub_fire) Politician [Budd Dwyer](https://bloximages.chicago2.vip.townnews.com/rapidcityjournal.com/content/tncms/assets/v3/editorial/f/a5/fa5af4a8-dd71-11e4-8118-a7693d507029/55245448e732b.image.jpg?resize=500%2C618) opening an envelope. He was holding a televised press conference about a scandal he was being accused of when the envelope was delivered to him during the press conference. He'd continue by opening the envelope and revealing a hand gun that he promptly put in his mouth, killing himself live on national television. This is one of the primary reasons many \"live\" news reports are preempted by a few minutes... Just in case.",
    "My First Chrome Extension (Python PyQuickie) Django backend  I made my first Chrome Extension it is called PyQuickie\n\nWhat is <PYQuickie>. Its a chrome extension I made for fun where you can practice your python coding skills easily and hassle free. No login recquired with just one click you can improve your coding skills and problem solving skills while still enjoy browsing through facebook and other web activities.\n\nFeatures:\n\n\\-Importing Python builtin Modules Work\n\n\\-working python IDLE\n\n\\-Python keywords highlighting\n\n\\-Python Tabbing Feature in textarea\n\n\\-Questions are ranked by level of difficulty: easy, medium, and hard. (Randomize)\n\nI made this because I wanted a quick access to a python idle to recap on the things I learned (currently in school) while browsing the web and why not add questions. Hope you guys like it. open for criticism and opinions on how to make it better or if it is bad or good.\n\n[https://chrome.google.com/webstore/detail/pyquickie/okpdnfgpbpifbncoleieajiblmebbkci](https://chrome.google.com/webstore/detail/pyquickie/okpdnfgpbpifbncoleieajiblmebbkci)\n\n&#x200B;\n\nhttps://preview.redd.it/dtpm0z2m7l971.png?width=687&format=png&auto=webp&s=2157608de76f75cf7d5eb77cef616f5a5ef4fea1\n\nhttps://preview.redd.it/7nz8lxmi7l971.png?width=1735&format=png&auto=webp&s=fbd5c7cc02b034f233be38034fc49435e55c56f2 How did you learn to make extensions? Any resource you'd recommend? [deleted] Can you make it for Firefox also? Where do you get the questions? Or is there a limited predefined amount? \n\nGreat idea btw !! Great work OP! Iâ€™ll install it and let you know what I think of it :) This looks amazing I'll surely check it out. Does the django backend run locally or server based. Look great but how to use it? I installed the extension but I have no clue how to use it. This is awesome Nice work! I have a Vendetta against Chrome though. I'll add it to my to-do and see if I can give any meaningful feedback. Also for my own improvement.",
    "Korean Bbq? Never have been to one, which one is the fan favorite in San Diego?? Buga on Clairemont Mesa Blvd. DJK Korean BBQ in Convoy. They use real charcoal instead of gas. Kogi or 356 KBBQ Kogi is my favorite kbbq restaurant here in SD. They are a bit pricey, but they always have rice papers in stock, which seems to runs out at most kbbq restaurants. Their quality of meat is on point as well. In order,\n\nKogi\n\nGen Korean BBQ\n\nManna Gen Korean BBQ has good food, a fun party atmosphere, and a bar. \n\nManna has better food but the wait is almost always long and parking isnâ€™t great. I like Mana for all you can eat... come hungry! I've really liked Taegukgi! Depends on my mood. \n\nIf I want larger and meatier portions with a side of middle aged Korean women glaring at me like I skipped church I go to Manna. \n\nFor new flavors and more non traditional offerings I go to gen or tgg depending on whichever one Iâ€™m closer too.\n\nOnce in a while Iâ€™ll hit up other places but those three I mentioned are my faves and go to them often with my lunch buddies at work. â€œFire spotâ€ in convoy use real charcoal and price is very reasonable. Busy most of the time\n\nâ€œShabumiâ€ In Claremont has shabu shabu and kbbq on the same table.\n\nâ€œBugaâ€ in Claremont has high quality meat and good sides. Busy most of the time.",
    "This guy is a true black-piller. It's honestly fascinating watching his videos, like a glimpse into the life and mind of a crazy man from the dark corners of reddit.  \n\n\n[Check it](https://www.youtube.com/watch?v=3WzTN_a2Yg0) ",
    "Matt Gaetz gets schooled by 4 star general  Who's the other Green Beret the General is referring to? Matt Gaetz shaking his head and smirking at a decorated General of the United States Army really shows you where his loyalty stands. I love his point about reading books by and about communist leaders doesnâ€™t make you a communist. Reading about racism doesnâ€™t make you a racist. Being a fucking racist makes you a racist! Mealy mouthed fucking twat couldnâ€™t even sit back and embrace knowledge coming from a 4 star general without a stupid fucking look on his face. Content aside, this clip shows why this guy is a general. Clear, concise, and powerful argument while maintaining a level of respect and decorum. Pure class. Now that's a leader!! never seen this gaetz guy before but holy shit what a rude asshole Damn his face is so punchable (gaetz) The fact that Gaetz is still sitting on a committee is an indictment of the whole GQP.\n\nThe fact that he got into Congress at all is an indictment of American politics in general, and Republican voters in specific. Military Mic-Drop",
    "American Reporter Gets Schooled On One Of The The Biggest Lies Of World War 2.... Still Doesn't Believe Soviets Ended The Holocaust!  The following alternative links are available:\n\n**Mirrors**\n\n\n* [Mirror #1](https://mirror.fro.wtf/reddit/post/3188785) (provided by /u/AdvinK)\n\n**Note:** this is a bot providing a directory service. **If you have trouble with any of the links above, please contact the user who provided them.**\n\n---\n\n[^(source code)](https://amirror.link/source) ^| [^(run your own mirror bot? let's integrate)](https://amirror.link/lets-talk) Dan Carlinâ€™s Hardcore History podcast covers this in spectacular detail. I saw the whole clip yesterday. She would just laugh loudly and very rudely when he corrected her or gave his opinion which didn't match hers. I was embarrassed for her. This clip cuts off right before she says something like \"I'd rather live under the US than the Taliban\" and Ryan Grimm answers \"Wait until you find out who funded the Taliban\" She looks so mad. She could have just listened and understood she might need to research a little better and made some other points; but noâ€¦. That woman is not some random show host. She's from The Federalist. It's her job to not hear the facts when they are spoken to her.\n\nhttps://thefederalist.com/author/emilyjashinsky/ I love everyone trying to teach Reddit community broken pieces of WW2 history.\n\nHERRRREâ€™S WHAT REALLY HAPPENED.... She looks like a child ffs. And has the demeanor of one, too She probably watched captain America and thought it was based on true facts.",
    "Kansas City Police officer shoots fellow cop when intending to shoot an apprehended suspect named Malcolm Johnson. She then incorrectly thinks the gunshot came from the suspect shooting and proceeds to shoot him two times. KCPD tried to cover this up until video showing the incident was released.  The following alternative links are available:\n\n**Downloads**\n\n\n* [Download #1](https://reddit.watch/r/PublicFreakout/comments/nse6u9/kansas_city_police_officer_shoots_fellow_cop_when/?utm_source=mirrorbot&utm_medium=PublicFreakout) (provided by /u/downloadvideo)\n\n**Note:** this is a bot providing a directory service. **If you have trouble with any of the links above, please contact the user who provided them.**\n\n---\n\n[^(source code)](https://amirror.link/source) ^| [^(run your own mirror bot? let's integrate)](https://amirror.link/lets-talk) Fuckin idiots Why the fuck would you pull a gun out when 4 cops are already on top of him WTF??? Falsifying a police report is perjury. But I guess that's not a serious crime. Who trains these fucking idiots? Who pulls a gun in a group of four-five people wrestling? \n\nYou fucking dumb asshole. Based on the position of the victim's feet, he was face down when the officer shot him.... why the hell did she pull a gun with the man under a dogpile? this looks like a huge fuckup then an exacution. The cops lied about what actually happend to cover it up, as usual Yo they just executed that guyâ€¦wtf I dont understand why drawing a gun was necessary in the first place, you arent allowed to just kill a suspect simply because they are making your job difficult. This is a murder video.",
    "An inebriated man argues with my friends and I because we refused to tell him who we voted for. -NSFW  This guy seems like a really unhappy person. Never seen someone cosplay as desperation. Ok so here is my understanding of the situation:\n\nThe guy is a moron Dude has a thinking problem that alcohol did not start but definitely didn't help him out. I look forward to seeing him on r/byebyejob if he has one. Thatâ€™s a man who has truly lost control of his life and has to resort drinking himself into a coma because he has nothing else left going for. I think we found a winner for the open picture in the dictionary for absolute loser\n\nIdiots who feel they need to push them selves into other tables business.  And who cares if your recording itâ€™s your table.   The F out of here with him. What a dumbass I voted for TRUMP OBVIOUSLY IM A FUCKING LOON \n\n- says the drunk guy making a scene \n\nClassic. Poor guy at his age still hasnâ€™t learned that calling people â€œfa***tâ€ only insults yourself and makes you look like an idiot. Maybe we should get him a time machine back to the 80â€™s when he was in middle school",
    "Sober Post: Things I've learned as an industry engineer Inspired by [Drunk Post: Things I've learned as a Sr Engineer : ExperiencedDevs (reddit.com)](https://www.reddit.com/r/ExperiencedDevs/comments/nmodyl/drunk_post_things_ive_learned_as_a_sr_engineer/)\n\nThought I would jot down everything I've learned through college and over the last \\~2 years in the industry.\n\nBackground: Top 20 CS program, high school/college internships were a mix of gov't, FAANG, Big N, defense contractors\n\nFull time work: FAANG + Unicorn\n\n&#x200B;\n\n* Getting started:\n   * The best time to start is now. some people start in high school, some in college, some when they're 60. Don't compare yourself to others with different backgrounds, just compare yourself to your past self. As long as you're improving and better than yesterday, that's what matters\n   * Imposter syndrome is normal - use it to your advantage. thinking your entire team is smart should motivate you to get to that level, not keep you from learning. everyone starts somewhere and soon you'll have people looking up to you too\n   * don't do CS for the money unless you have an extremely strong will. this field will burn you out if you do it for money unless you're somehow able to separate the outcome and your day-to-day. i would recommend against it\n   * laptop recommendations get asked a lot. I would personally say get a mac product (used or new) made in the last \\~1-3 years for simplicity. things will work out of the box and you have unix support from day 1. If you're more adventurous, get a pc and load linux, or get a VM or build a hackintosh. these approaches require a lot of work. Swappa is a good place to find used deals\n   * Programming languages don't really matter too much - I would recommend python or java to get started with\n   * College is what you make of it - you can go to a low-tier school and do great if you push yourself. You can go to MIT and be a bum. it is easier to do well if you go to a high tier school and push yourself though\n   * CS is a learning experience even past college. you'll be learning new technologies, frameworks and having to brush up interview skills continuously. make sure you enjoy learning new things\n   * bootcamps vs college is an interesting debate. bootcamps teach the high-level knowledge without in-depth fundamentals. that you have to learn on your own. don't expect just a bootcamp to set you up for success against college grads. you have to put in more work than the minimum. [Would you choose a coding bootcamp or a computer science related degree? Why? - Quora](https://www.quora.com/Would-you-choose-a-coding-bootcamp-or-a-computer-science-related-degree-Why) The top answer here is a solid one. Generally, bootcamp grads are extremely rare in FAANG because they want fundamental knowledge. bootcamp grads do very well at small local tech companies that might want something basic without having to worry about scale\n* Once you're in college\n   * Try new things. go to hackathons, try new clubs, make friends. You learn from those around you and this is an easy way to surround yourself with smart people\n   * go to class. as someone that skipped a lot of classes, it's not worth it. you'll spend the same amount of time if not more trying to learn things yourself. the only potential exception is if the classes are recorded and you have enough discipline to watch them\n   * GPA matters and it doesn't matter. It matters for government, trading firms, traditional companies (although they'll stop caring once you hit a few years of experience). Normal tech companies don't really care ASSUMING you can show your value in other ways. Having a low GPA and no projects is a bad combo\n   * Personal projects are just another way to showcase your skills. it can be substituted with a contribution to open source, part-time work, etc.  It's better to have them than not\n   * Core classes to take in college IMO are network security, databases, algorithms, linear algebra, up to calc 2, an advanced data structures class, compilers, OS. you don't need to take the highest level classes but knowing these are good.\n   * Have a social life - growing as a software engineer requires soft skills. you can be the smartest person in the room but won't grow unless you're also easy to learn with\n   * Be humble and eager to learn. try not to be in an environment where you're the smartest person in the room. Goes back to point 1 where you should get comfortable being uncomfortable and learning\n   * Careers fairs are good but do your research. some companies just tell you to apply online, others will give you an interview on the spot. Go first to the ones that will give you an interview and go to the other ones last\n   * Hackathons and clubs are a good place to find jobs too\n   * [http://angel.co/](http://angel.co/) is a good place to get started on the startup hunt\n   * your professors and TA's are there to help you - ask them for help\n* Internships/new grad jobs\n   * getting the first internship is the biggest hurdle. after that it kind of compounds\n   * there's a correlation between the number of applications submitted and job offers. success = attempts x success rate. even if your success rate says the same, applying to twice as many places is good\n   * failing interviews is normal. its not a reflection of you as a person or your skillset but your demonstration of that skillset given at the time and situation. learn from it and move on\n   * Algorithms and data structures is the core of CS. Do leetcode and get started on these things as soon as possible\n   * FAANG has specific programs (FBU, Google engineering practicum, Microsoft explorer) geared towards underrepresented minorities and freshman/sophomores. apply to them\n   * [GitHub - j-delaney/easy-application: Over 400 software engineering companies that are easy to apply to](https://github.com/j-delaney/easy-application) and [Intern Supply](https://intern.supply/) are good places to start\n   * Optimize your internships for learning and growth. Learning means trying new things, pushing boundaries etc. Growth means jumping around from company to company. Use a defense contractor to go to Big N and then to FAANG.\n   * Learning standard tools like git, docker, etc can make you more effective at internships\n   * being young is the best time to take risks. if you want to do a startup over a large company, go for it but do your research. don't turn down google for a company that does IoT socks.\n   * information is power. especially when it comes to negotiating. sites like [https://www.teamblind.com/](https://www.teamblind.com/), reddit, and [https://www.levels.fyi/](https://www.levels.fyi/) are crucial to make sure you're compensated fairly\n   * practice coding on paper/whiteboards. most interviews expect this and will probably be the norm once covid ends\n* Industry experience/new grad tips\n   * Optimize your first job for (in order) learning, manager, interest in work, compensation. How much they matter should be up to you. ex - don't turn down a 100k job for a 50k job that has a slightly better learning opportunity. but a 90k vs 95k job, optimize on things other than compensation\n   * FAANG is overrated and underrated at the same time.  There are plenty of smart people but also plenty of slackers. That being said, the pay and benefits is fantastic. But there are always different and potentially better opportunities. Finance for higher pay and worst wlb, unicorns for higher pay but with more uncertainty, gov't for wlb and low stress. The one thing about FAANG is, there are very few other places in the world where you can work on things at such a large scale\n   * silicon valley is a good place to be when you're young, not so much when you're older (unless you're doing really well). living in a house with 3 roommates paying 1500/month is fine in your 20's but paying 2 million for a small house in your 30's with kids is not optimal\n   * not all jobs are in silicon valley/est coast but a lot of them are. new york and DC are also top contenders now\n   * learn personal finance. ESPECIALLY if you already have internships. Invest as early as you can so you set yourself up for a financially successful life\n   * invest in a good setup if you can - ergonomic chair, keyboard, a mouse so you don't have to deal with issues later on\n   * dual monitor/ultrawide screens are great for productivity\n   * noise-canceling headphones are essential for office work\n* General life tips\n   * your health is your wealth. eat well, sleep, exercise. money, success, intelligence means nothing if you die early\n   * be kind to people - you never know when you'll run into them again\n   * take risks when you're young, it'll be harder (not impossible) once you hit 30ish\n   * generally have a balanced life. an extreme of anything tends to be bad\n   * have a good group of friends - they mean a lot once you get out of college. as time goes on, the opportunities to make new friends come by less often - people go out less often and you don't get the same interaction levels you get in college with clubs and classes. once you're late 20's/early 30's you've pretty much made your core friend group and it becomes harder to break into new friend groups (not impossible though)\n   * spend time with family - by now you've spent 90% of the time you will with them so make the last 10% really count\n   * money and other things in life are only a part of it. i know people worth tens of millions that barely spend time with family, i know people making a very average income that are happier than people making 300k. everyone has their own issues\n\nI can't really think of anything else at the moment. If you disagree with anything i've said, feel free to ignore or just post a comment so others can see your point of view. i'll respond to comments/dm's when I can.\n\n&#x200B;\n\nedit: thank you for the awards :)\n\n&#x200B;\n\n&#x200B; Good post! Resonates with a lot Iâ€™ve learned as well working in industry. Itâ€™s still fuck pandas out here in these streets Thanks for the post! What is your opinion on pursuing a master's in CompSci? Are there any significant benefits to doing one? > living in a house with 3 roommates paying 1500/month is fine in your 20's \n\nWait?! This is in Silicon Valley? I live in LA and its the equivalent. I feel like Im getting scammed here ):< Spot on, also learned some things as well. Canâ€™t agree more on work life balance. The worst thing I ever did was stopped hanging out with friends and doing hobbies to focus on self-development/learning. Itâ€™s so crucial to have time away to avoid burnout.\n\nThank you! I didn't see anything about *not* stealing corporate secrets and selling them. So I think that means we are in the clear ðŸ‘Œ I have no friends... Besides those websites, are there any other ways I can know if my salary is right? Or how do I negotiate if I feel my salary is low? Wow not just career advice but life advice too. Thank you. Absolutely thank you for this post",
    "[D] Machine Learning Interview book by Huyen Chip. [https://huyenchip.com/ml-interviews-book/](https://huyenchip.com/ml-interviews-book/)\n\nI have just skimmed part of the book but it looks very good and contains lots of insight from a recruiter point of view that I would never know otherwise and is applicable to more than just ML interview IMO. What do you think?\n\nQuote from the Github page:\n\nThis book is the result of the collective wisdom of many people who  have sat on both sides of the table and who have spent a lot of time  thinking about the hiring process. It was written with candidates in  mind, but hiring managers who saw the early drafts told me that they  found it helpful to learn how other companies are hiring, and to rethink  their own process.\n\nThe book consists of two parts. The first part provides an overview  of the machine learning interview process, what types of machine  learning roles are available, what skills each role requires, what kinds  of questions are often asked, and how to prepare for them. This part  also explains the interviewersâ€™ mindset and what kind of signals they  look for.\n\nThe second part consists of over 200 knowledge questions, each noted  with its level of difficulty -- interviews for more senior roles should  expect harder questions -- that cover important concepts and common  misconceptions in machine learning. After scanning through, this guide seems impressively thorough. Being brand new, it also gets right the current changes in industry, for example: \n\n> However, there are many differences between ML engineering and data science. The goal of data science is to generate business insights, whereas the goal of ML engineering is to turn data into products.\n\nWhich is exactly the split that just happened at my company. When people explain the sea change from DS to ML, I think this is the most popular answer. \n\n_Part II. Questions_ is exactly what I've been looking for myself. A decent set of MLE interview math problems isn't too easy to find, and this set looks good.\n\nIf I had one criticism after scanning, it's that _Chapter 1_ makes this whole big thing about how important the engineering side of things is, and it is important, but the _Resources_ section in _Chapter 4_ has next to nothing engineering focused. Not even Designing Data Intensive Applications. >âš  Never ask your interviewers about compensation âš   \nUnless the topic is explicitly brought up by the interviewers. Some   \nhiring managers consider this a red flag as it signals that the   \ncandidate only cares about money and will jump ship as soon as a better   \noffer comes along.\n\nThis is a stupid mindset. Compensation is an essential element of any job and should absolutely be discussed in the hiring process. I really wish they included solutions. It would make it so much easier to validate your knowledge. This book is great. But, I didn't know answers for many questions. Does anyone know resources to find all the solutions at one place? Thanks, Huyen! Thanks Awesome thanks! Huyen Thank you! Great job as always yup its good! Hello guys? Im new to this one, now im learning to get Tensorflow certificate. All i want to ask is what is the job can i get with this certificate? My future way with it, my benefit or what will i have to learn in the future? Any advice for me?\n\nSorry for posting like this but i don't have enough karma",
    "What is your biggest non-academic, non work-related accomplishment?  running the table at pool where after the other person broke and i sank every single one of my balls and the eight ball in one turn (i'm not usually good at pool). a stranger came up to me said it was one of the greatest things he's ever seen. I think about this often lol. Probably not the biggest but I flat out slapped this random man on the street after he grabbed my ass\nMy hand shook for almost the rest of the day but I was so proud of myself! My step kids removed the â€œstepâ€ portion of the label by asking me to adopt them as adults. \nThey did the research to make sure it was doable, and I did all the paperwork on my own, and now I am dad of 3 rather than dad of 1! Managed to strike out the gym teacher during a softball match My old band got played on a local radio station a few times [deleted] An artist at a major animation studio saw my fanart and shared it on their Tumblr, they commented on how funny they thought it was. That was years ago but it felt great Lost over 100lbs to do an Ironman triathlon and also compete and place in a bodybuilding competition. Growing veggies and herbs without killing them. And making pickles/jams/infused butter with the results. So thatâ€™s pretty cool I guess.\n\nEdit: Thanks for the awesome feedback and good luck to you all in your own efforts! :) Adopted my little sister (16) when I was 21 after my father murdered my mother helped her finish school and kept a room over her head till she was old enough to move out on her own.",
    "Trump asked whether the DOJ and FCC could investigate 'SNL' after it mocked him, report says  >\"It's truly incredible that shows like Saturday Night Live, not funny/no talent, can spend all of their time knocking the same person (me), over & over, without so much of a mention of 'the other side,'\" he said. \n\nI'm sure he was just as outraged when they started making fun of presidents back in the 70s when the show began. I bet he could barely contain his rage back when he hosted in 2004 and again in 2015. Imagine being one of those idiots that thinks Trump is an \"alpha.\"  This loser is the biggest snowflake on the planet. What blows my mind is how he somehow must have assumed that he'd *not* be subject of mockery? What national political figure from the past 45 years hasn't been the target of lampooning by one side or the other? It's essentially part of the job. If you can't handle it, why even run for office? It would be like applying to be a helicopter pilot when you have a crippling fear of heights.\n\nThe fact that citizens of modern democracies can openly mock and denigrate their leaders is one of the cornerstones of freedom of speech, it's one of fundamental principles that separate them from authoritarian regimes around the world. A program like SNL wouldn't even exist in Russia, or China, or in countless other places.\n\nSo of course, Trump thinks it's something that needs to be investigated.\n\nIt's like he's allergic to the very concepts that make America American. So Donnie can make fun of the handicapped, but canâ€™t take a joke. Sad little man, sad little man. Trump probably wanted his own Gestapo to suppress his political enemies. What happened at the DOJ during his reign could have been far far worse. Where are all the conservatives calling him out for gross government overreach?\n\n&#x200B;\n\nEdit: RIP my inbox Mentally ill. Not even being funny here. The Party of \"Fuck Your Feelings\" everyone! I know it's petty, but I love the fact that stupid SNL jokes got under his skin that much. President Snowflake",
    "In secret recording, Florida Republican threatens to send Russian-Ukrainian â€˜hit squadâ€™ after rival  \nAs a reminder, this subreddit [is for civil discussion.](/r/politics/wiki/index#wiki_be_civil)\n\nIn general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, **any** advocating or wishing death/physical harm, and other rule violations can result in a permanent ban. \n\nIf you see comments in violation of our rules, please report them.\n\n For those who have questions regarding any media outlets being posted on this subreddit, please click [here](https://www.reddit.com/r/politics/wiki/approveddomainslist) to review our details as to our approved domains list and outlet criteria.\n\n***\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.* >Asked repeatedly via text if he mentioned Russian-Ukrainian hit squads, Braddock wouldnâ€™t give a yes or no answer, saying he had not heard the recording and that itâ€™s â€œallegedly me â€¦ there is no proof of that.â€ He also suggested the recording â€œmay even be altered and edited.â€\n\n...\n\n>Asked if the killers were snipers, Braddock described them as, â€œRussian mafia. Close-battle combat, Tech 9s, Mack 10s, silencers kind of thing. No snipers. Up close and personal. So they know that the target has gone.â€\n\nEdited. Lol. What possible conversation was he having where those words could be edited from? \"Gonna head out to the market. You need any weaponry from the Russian mafia?\" \"Ok will pick up some...\" This guy is proper fucked. > â€œThis is a dirty political tactic that has caused a lot of people a lot of stress and is completely unnecessary,â€ he said.\n\n\"How dare you repeat my words and use them against me.  How DARE!\" It's not real, but I'm going to sue you for recording it. \"It's unclear exactly why Braddock has such dislike toward Luna.\"\n\nOh, I've got a pretty good idea. >â€œI really don't want to have to end anybody's life for the good of the people of the United States of America,â€ Braddock said at one point in the conversation last week, according to the recording exclusively obtained by POLITICO. â€œThat will break my heart. But if it needs to be done, it needs to be done. Luna is a f---ing speed bump in the road. She's a dead squirrel you run over every day when you leave the neighborhood.â€\n\nHe runs over squirrels daily??!! This story will probably give him a bump in polling among Republicans. > A little-known GOP candidate in one of Floridaâ€™s most competitive congressional seats was secretly recorded threatening to send â€œa Russian and Ukrainian hit squadâ€ to a fellow Republican opponent to make her â€œdisappear.â€\n\n> During a 30-minute call with a conservative activist that was recorded before he became a candidate, William Braddock repeatedly warned the activist to not support GOP candidate Anna Paulina Luna in the Republican primary for a Tampa Bay-area congressional seat because he had access to assassins. The seat is being vacated by Rep. Charlie Crist (D-Fla.), who is running for governor.\n\n> â€œI really don't want to have to end anybody's life for the good of the people of the United States of America,â€ Braddock said at one point in the conversation last week, according to the recording exclusively obtained by POLITICO. â€œThat will break my heart. But if it needs to be done, it needs to be done. Luna is a f---ing speed bump in the road. She's a dead squirrel you run over every day when you leave the neighborhood.â€\n\n> Reached by text message, Braddock refused to say whether he made any threats about Luna to the person who recorded him, Erin Olszewski.\n\n> Asked repeatedly via text if he mentioned Russian-Ukrainian hit squads, Braddock wouldnâ€™t give a yes or no answer, saying he had not heard the recording and that itâ€™s â€œallegedly me â€¦ there is no proof of that.â€ He also suggested the recording â€œmay even be altered and edited.â€\n\n> â€œThis is a dirty political tactic that has caused a lot of people a lot of stress and is completely unnecessary,â€ he said.\n\n> Olszewski denied editing or altering the recording. She said she made it because she was concerned about Braddockâ€™s â€œunhingedâ€ dislike of Luna that he had previously expressed. After she made the recording just after midnight last Wednesday, she promptly turned it over to St. Petersburg, Fla., police and gave a heads-up to her friend Luna, who filed a petition for an injunction against Braddock. Luna received a temporary restraining order against him last Friday. Braddock filed to run Monday.\n\n> In the recording, Braddock early in the call brought up the alleged assassins. He also made rambling statements about getting financial help from fellow Freemasons or by somehow importing millions of dollars from Malta and Gibraltar.\n\n...\n\n> It's unclear exactly why Braddock has such dislike toward Luna. The two do not appear to have any previous connection to one another, and Braddock is a lower-tier candidate in an increasingly crowded race for Cristâ€™s seat. \n\n...\n\n> With such a closely divided Congress currently in Democratic control, Braddock said on the recorded call that the â€œpivotalâ€ St. Petersburg-based district will take on outsized importance in 2022 to keep America from devolving into a â€œcommunist-socialist s---hole.â€ When Olszewski asked him why he had Russians at the ready, Braddock indicated they were to stop Luna.\n\n> â€œMy polling people are going to charge me $20,000 to do a poll right before the primary. And if the poll says Lunaâ€™s gonna win, sheâ€™s gonna be gone. She's gonna disappear,â€ Braddock said in the recorded call, pledging Olszewski to secrecy. â€œFor the good of our country, we have to sacrifice the few. â€¦ For the better or the good of the majority of the people, we've got to sacrifice the few.â€\n\n> Later in the call, Olszewski asked what would happen if â€œLuna is gonna winâ€ and Braddock assured her that wouldnâ€™t happen.\n\n> â€œSheâ€™s gonna be gone. Period. That's the end of the discussion. Luna is not an issue,â€ he said.\n\n> Olszewski pushed him, asking â€œhow do we make her go, though? I just donâ€™t understand that.â€\n\n> â€œI call up my Russian and Ukrainian hit squad, and within 24 hours, they're sending me pictures of her disappearing,â€ he replied. â€œNo, I'm not joking. Like, this is beyond my control this point.â€\n\n> Asked if the killers were snipers, Braddock described them as, â€œRussian mafia. Close-battle combat, Tech 9s, Mack 10s, silencers kind of thing. No snipers. Up close and personal. So they know that the target has gone.â€\n\n> Olszewski said that threats like the ones Braddock made â€œyou canâ€™t take lightly. Normal people donâ€™t say these things.â€\n\n> Olszewski called Braddock on one smartphone and recorded video of the call with another, occasionally displaying his name and number on the video to show it was him on the call. POLITICO also obtained a separate recording, a voicemail message, Braddock left with a consultant in which his phone number was identical and voice seemed to match the information Olszewski shot in her video.\n\n> In Florida, itâ€™s a third-degree felony to record another person without their knowledge. But Olszewski said that St. Petersburg police told her she had nothing to worry about in recording the conversation and turning it over to authorities. A spokesperson for the St. Petersburg police declined to comment on the recording or whether it was legally recorded.\n\n> Braddock, though, indicated he was ready to sue Olszewski.\n\n...\n\n> In her petition for the restraining order, Luna made it clear that she took Braddockâ€™s threats seriously.\n\n> â€œI do not feel safe and am currently in fear for my life,â€ Luna wrote, according to a copy of it.\n\n> Olszewski, too, said Braddock sounded dangerous. At one point, Braddock even said he was scared himself.\n\n> â€œDonâ€™t be on the f---ing wrong side of supporting Luna because if you're near her when the time comes, I just don't want that to happen to you because you've got kids,â€ Braddock said on the call. â€œSo don't be associated with Luna under any circumstances. Please. And do not repeat this anybody because both of us will be in jeopardy if you do. I'm not just blowing smoke here. I'm f---ing being dead ass serious and it scares the s--- out of me, too.â€ Every three letter agency we have needs to be up in this guy's business immediately. The hit squad is disturbing but somehow this is just as disturbing:\n\n> Luna is a f---ing speed bump in the road. She's a dead squirrel you run over every day when you leave the neighborhood.\n\nThat has to be on the list of warning signs next to kids that mutilate animals.",
    "Modern alternatives to Unix commands  I was all ready to be â€œWe donâ€™t need any of them newfangled GUI-heavy toolsâ€.  And then I looked and thereâ€™s not a GUI to be seen, but there are a bunch of modern, simpler, smarter ways to work on the command line. Absolutely aces. Thanks Are these tools as pipe-able as the tools they try to improve upon? Can vouch for fd, ripgrep, hyperfine, jq. All are excellent tools that are 100% worth using!\n\nGonna recommend ~~[ncdu](https://dev.yorhel.nl/ncdu/scr)~~ [gdu](https://github.com/dundee/gdu) instead of dust, and [fasd](https://github.com/clvv/fasd) for directory switching.\n\nProbably don't bother with:\n\n* ls replacements: gnu ls can look just as good, just use an alias. mine: `alias ls='ls -lAGh1vX --group-directories-first --color=auto'`\n* ag: just use ripgrep.\n* curl replacements: curl and jq can cover most use-cases.\n* bat: meh. make an alias to open files in your editor/ide if you don't have an easy command already. I love fzf so much.\n\nI pipe every searchable list to it Can anyone vouch for 'doas' instead of 'sudo'? Definitely seconding `tldr`. Gives you a good gist of a commandâ€™s functionality and strips out a lot of what you donâ€™t always need from a full man page if youâ€™re just trying to remember parameters. The big huge thing this list is missing is `htop`.\n\nThere are a couple things like glances and bottom on the list (glances is even billed as a top/htop alternative), but those are more *system* monitors while htop is a process manager. I have little use for either of those, but I use htop pervasively. Like I think it's outright misleading to bill glances as an htop alternative. Unless it's not documented or I'm just not finding it, you can't even send signals to processes; how is that an htop alternative? Can you even get it to show a process tree?\n\n`htop` for me is maybe *the* canonical example of where a new tool has more or less completely supplanted a classic one. Good list. But the old tools are still important to know if you need to ssh to many different machines, or to write at least semi portable scripts. A different sort of tool (quite a lot of those are aiming to improve/replace existing tools, this isn't), is [rclone](https://github.com/rclone/rclone).\n\nIts rsync, but integrated with cloud APIs. So you can setup scripts to sync your local data to/from Dropbox/Google Drive/S3/OneDrive etcetcetc (or Dropbox to Google Drive etc!)\n\nI have scripts across various machines to just sync small files over to my Dropbox, or scripts to backup the more important ones of them also down to my home PC etc.\n\nI work a lot across various machines and its nice to have an easy way to sync small bits of data around seamlessly. You can setup access rights etc too, so that its only authenticated for a specific folder in your Google Drive etc. It's funny to me that many of them specifically mention \"written in Rust\". I wonder if _all_ the ones written in Rust say that and if _all_ the ones not written in Rust don't say their language. Maybe I'll check when I'm not with a foot out the door :p",
    "Jeff  Talking about apandah because he is a interesting point of discussion ðŸ™‚ We're going to be talking about the penis J u/savevideo ###[View link](https://redditsave.com/info?url=/r/Apandah/comments/o192n1/jeff/)\n\n\n --- \n [**Info**](https://np.reddit.com/user/SaveVideo/comments/jv323v/info/)&#32;|&#32; [**Feedback**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Feedback for savevideo)&#32;|&#32;[**Donate**](https://ko-fi.com/getvideo) &#32;|&#32; [**DMCA**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Content removal request for savevideo&message=https://np.reddit.com//r/Apandah/comments/o192n1/jeff/)",
    "POV: You try dive a Baptiste  Baptiste is about that life...\n\nNothing like hitting that triple crit on a Tracer that thinks you're pussy *Doomfist thinking it can power up his rocket punch* *LIGHT THEM UP* wait baptiste is a healer? Man I love when you kill members of Talon and he says â€œStop coming after me!â€\n\nReaper: *death cry* â€œuaghhhh!â€ Last night in a single round a Sigma ulted me three times, each time to have me use lamp and survive. He never learned to wait until after I'd used it on something else. But then u understand ur doomfist and just 1 shot him by fisting him out of his safe ring Bap is the 3rd dps Moira wishes she was. Thank you baptiste! Ohhhhh youâ€™re welcome!!! Would you like a bandage for that?",
    "This is my contribution to all developers who are learning a new language and need an interface to practice new knowledge. The PokÃ©dex prototype has mobile interfaces with style guide and wireframes, so that you can only worry about what really matters, which is coding.  Cool [deleted] Iâ€™ve tried to get my kid into coding. This may be the thing that gets his interest- thanks! The first page is just a mockup. In the other two pages, you can find the style guide, icons, components, wireframes and the prototypes to inspect all UI details",
    "All AlgoExpert Questions and Solutions in Java This [repo](https://github.com/alpha037/data-structures-and-algorithms/tree/main/AlgoExSolutions) consists of all the AlgoExpert questions and their solutions. Feel free to star/fork it.\n\nHappy problem solving! Was algoexpert really good? Did it help you in your problem solving ability and what are you doing now to improve upon what you know? Do folks have similar questions in Python? u/alpha-037 I could find only the solutions. How can I read the questions? thanks really appreciate it. If you have time can you add python solutions. One of the biggest thing I don't like about algoexpert is that it does not allow you to copy and paste their solution I can not find the questions. Where are the questions? They do not have information or algorithm problems that you cannot find on internet. If your are too lazy to do a search maybe these type of services are for you but in my opinion, is not necessary to purchase the service. Tbh, I bought AlgoExpert just because of curiosity. Yes, my problem solving skills have improved a bit. But it's not because I bought AlgoExpert. I guess it's because of the practice. Right now, I'm picking up topics I'm uncomfortable with and practicing questions under those categories. Yep, the questions are all the same for all languages. Did you find the questions? Yeah, it's funny to see them bicker over who is actually a good algorithm-learning service, when they are all basically a scam.",
    "I developed an open-source periodic table app, 'Atomic - Periodic TableÂ´', with tons of data for your physics work! Hello!\n\nDuring the last couple of years, I have as a hobby started to develop apps for Android. During the last year and a half, I have focused on 'Atomic - Periodic Table', which is a periodic table app that also features other tables as for example, an isotope table, ionization energies table, formulas table and many more.\n\nhttps://preview.redd.it/7au4e7ran0571.png?width=4240&format=png&auto=webp&s=97533e9554c0ef49d8a666b53ccd2a74c22e6e3b\n\n# Overview of 'Atomic - Periodic Table'\n\n**Â· No ads:** All apps I develop, doesn't include, and will not include any ads or other nonsense. So easily navigate the periodic table and more without getting interrupted!\n\nÂ· **Interactive Table:** The main table has different options to not only show elements names, but also display data like electronegativity, atomic weight, element groups and much more.\n\nÂ· **Element Info:** Clicking on any element in the periodic table will send you to an information page, which contains tons of data of all 118 elements, including thermodynamic properties, electromagnetic properties, nuclear properties and much more.\n\nÂ· **Favorite Bar:** Easily mark the data of which has the most importance to you and get it displayed first and centered in the info page.\n\nÂ· **Isotope Page:** You can also view isotopes of different elements in the isotope table page, which shows you their halftime and respective mass, as well as their protons, neutrons, and nucleons.\n\nÂ· **Formulas:** To aid your studies there is a page with many formulas for solving primarily physics-based problems.\n\nÂ· **pH-indicators:** Get an overview over which color different indicators have in different pH-values.\n\nÂ· **Ionization energies table:** Find the ionization energies of different elements, easily in a single interactive table.\n\nÂ· **Solubility Table:** Find out which compounds are soluble with each other.\n\nÂ· **Dictionary:** Donâ€™t know what a certain term means, simply open the apps built in dictionary.\n\n# Latest update\n\nRecently I released update 1.4.0 which adds an ionization energies table, some nuclear data, filtering options in the dictionary and much more. This is just the first update for the summer, with two more coming. Finally, I recently made the app open-source and GitHub, where if there is any app developer here, all the data is free to use under the license for other projects.\n\n# Get it\n\nPlay Store: [https://play.google.com/store/apps/details?id=com.jlindemann.science](https://play.google.com/store/apps/details?id=com.jlindemann.science)\n\nFor GitHub and more: [https://www.jlindemann.se/homepage/atomic](https://www.jlindemann.se/homepage/atomic) WOW So... I downloaded ur app and here's my first impression plus an issue.\n\nLooks neat. Glad to see no ads. (Sorry, I know it's earning devs money but it often annoys me) Was so glad there was dark theme! That was a pleasant surprise. (Maybe u mentioned it in ur Post but honestly I didn't even bother reading and immediately decided to download it coz it looked cool.)\n\nNow, onto the issues/Questions\n\n1. How do you make elements colorful like in the pic? [EDIT: Found it! You just filter by groups]\n\n2. When I click on Isotopes and scroll through, sometimes it doesn't open. Fixed once I closed it and reopened. But I noticed that it doesn't slide down when I click on the back button. I have to scroll it using the slider. So, can you check that out? It kinda seems like a bug.\n\nReview: Will check out for a little while longer after this. Good job, dev. Great app! I did encounter an issue (sorry if had already been brought to your attention). Ok my Pixel 5, the \"back\" gesture (swipe from edge of screen) does not cause the isotope page to go back to the previous page. Only clicking the arrow at the top of the app allowed me to go back. Great job with this app. As a HS science teacher, I will be recommending this app for my students! It is a very nice app at a cursory glance, very clean interface and data well presented. One minute issue i noticed, when looking at the Electron she'll configuration, if the M shell is full the app will not show the M itself. In other words, it will show â€™K2 L8 18 ...â€™. Does it include any of the info in Chart of the Nucliedes and Isotopes? Astatine has missing density information, which signals a failed table lookup. Will you consider releasing it on F-Droid? thx Canâ€™t wait to download this ! Thank you :) I am very impressed! Good job!",
    "I wanted to interview at companies doing good in the world, then I built a job board for engineers who want to do the same.  There should be more programmers like you. If you're interested in companies doing good you may also want to look at https://80000hours.org/job-board/?role-type=engineering Looks great, although the company logo images aren't showing. This is great, although it seems to be more focused on the US. Is there anything similar for Europe by any chance ? https://www.reddit.com/r/programming/comments/nqkzzs/i_wanted_to_interview_at_companies_doing_good_in/ see /r/programming's discussion from a few days ago That might be the nicest compliment Iâ€™ve ever received :) Totally, 80000hours was a big inspiration for GoodJobs Only the featured posts have them atm, Check this out!  (If you live in Germany) [https://goodjobs.eu/de/jobs](https://goodjobs.eu/de/jobs) Thanks ! Unfortunately I'm in France. I'll keep looking :)",
    "",
    "",
    "",
    "Want $2000??  Hi, Databricks / PySpark Aspirants!  \n\n\nHow to get Apache Spark training worth $ 2000.00 USD absolutely FREE!  \n\n\nThese training courses are prepared by \"Databricks\" hence the content quality is unmatched! (An enterprise software company founded by the original creators of Apache Spark). Databricks offer different learning paths matching your interests to learn new skills and unleash the power of data! These learning paths include:  \n\n\n1) Business Leader  \n2) Platform Admin  \n3) SQL Analyst  \n4) Data Engineer   \n5) Data Scientist  \n\n\nEach learning path has many \"courses\" and each \"course\" has many text and video lessons! What makes the learning process great is the Quizzes they have after each lesson and \"certificates\" that are awarded by Databricks as you successfully complete a course. Here are the steps:  \n\n\nStep 1) Google Databricks Learning paths & Visit the website  \nStep 2) Select a \"Learning Path\"  \nStep 3) Click \"Add to Cart\"  \nStep 4) Apply Coupon \"DB\\_CE\" and click checkout  \nStep 5) Create your account.  \nStep 6) Enjoy upskilling!! :)  \n\n\nKnowledge increases by sharing!  \n\n\nPlease re-share so others can learn too! Leaving this post up since itâ€™s actually helpful but OP should probably be aware of how scammy the post reads.\n\nEdit: Check out our new wiki page of [learning resources](https://dataengineering.wiki/FAQ/Learning+Resources) recommended by this sub. This reads like a scam email, but it's actually great free training. I'm halfway through the DS pathway, and have a few fragments to add:\n\n- you can create a \"community\" databricks account (completely separate from your \"learning\" account).  This lets you do the exercises for free.  The main restriction on community is that you have to create a brand new cluster for each session, and manually attach your notebook to the new cluster name.\n\n- your \"learning\" account doesn't really track where you are in the selected roadman.  You have to remember which mini-course you're working on, scroll through the big list of ~ 100 courses, and click resume.\n\n- The learning pathways are kind of baffling and most of the courses seemed to spend a lot of time reintroducing very basic stuff.  Skip the fundamentals and don't bother with the electives unless you have specific knowledge gaps or learning objectives.  EG, if you're interested in Spark for ML, jump straight to the \"Scalable Machine Learning\" course.  \n- since this is the DE sub, it's worth pointing out that the \"Advanced Data Engineering on Databricks\" course does not seem to exist yet, and is labelled \"Q4 2021\" on the pathway graphic. My man out here sounding like a phish in water. Well, that's the weirdest most helpful message I've seen in a while, thanks. I guess. It works. Coupen **DB_CE** works for other learning paths as well. Might as well be interested in those too. What is the best path to learn? Wow this is great! Thank you. Anyone tried registering for both DE and DS courses using the same account?\n\nEdit: it worked! Not working anymore.  \nGuess they read reddit too)  \nJust in case, anyone got a spare Data Engineer|Data Scientist account? THIS IS AMAZING!!! This works guys! Thank you so much ðŸ˜­ðŸ™ this means a lot. \nAnd can we try with this code after three months or something? Right now occupied with few stuff",
    "That's fully stupidity...  What a twat Yeah someoneâ€™s getting a shard of glass in their foot at some point Sounds like the start of stone cold Steve Austin's intro.\n\nSomeone please add this to the video Thats gonna hurt Is this Mrs. Featherbottom from Arrested Development? *fully stupidity* Smh good grief Jesus mesiesus thats gotta hurt\n\n\nIm happy some people are adding this to their lexicon :) If had had been wearing shoes, they would be gone. Hell has no fury like an idiot's will power.",
    "Two lads ditch a stolen car after police chase. Keep an eye on the driver (right side). Very slick move.  You've got to have balls of steel to do that He's like an NPC being reset Keyser SÃ¶ze \"He went *vaddaway*\" Britain? I hope he got back in the car and drove away. That was slicker than owl snot... I donâ€™t like the fact he pointed in the direction his friend ran off in That is a Smooth Criminal... it would have been slick if he jumped back in the stolen car, looped around the block and picked up his buddy who was still running. Classic misdirection",
    "Head up short kings <3  The following alternative links are available:\n\n**Mirrors**\n\n\n* [Mirror #1](https://mirror.fro.wtf/reddit/post/3186110) (provided by /u/AdvinK)\n\n**Note:** this is a bot providing a directory service. **If you have trouble with any of the links above, please contact the user who provided them.**\n\n---\n\n[^(source code)](https://amirror.link/source) ^| [^(run your own mirror bot? let's integrate)](https://amirror.link/lets-talk) I mean he got up after that tackle and continued his tantrum so points for consistency â€œSir this is a bakeryâ€ [deleted] Probably sucks being a guy that short,  but damn that's cringe as hell.  I want to know what triggered this freakout. I recommend he avoid those dating sites. [deleted] How to deescalate something like this? \"Go ahead and attack me!\"\n\n\\*attacks him\\*\n\n\"Oh and a guy three times my size tackles me... that's okay?!\" Now he's definitely getting laid! Who can resist a man who acts like that in public?",
    "What is Kalman Filter? | A Bayesian Probabilistic View  I am not the owner of this video. The uniqueness of this video is, its very intuitive explanations about the concepts and reasoning of kalman filter in simple English. Thank you, I really enjoyed that! r/ECE Why did you need to look up kalman filter? I'm curious how you're using it, if not as part of a curriculum Thanks, u/begooboi for the appreciation. It's been a while since you posted it here but I noticed it today. Its widely used in robotics and self driving  cars. The most important reason, because I want to understand it. What kind of question is this? Why anyone needs to look up anything? Shouldn't someone learn something new out of their curriculum? What if s/he wants to make a new kalman filter API which only use Go as a language or say Scala as a language? The OP gave you a very humble reply but I felt offended by your audacity to question someones motive to learn and share something. And If you are not being rude then the post should be \"How are you planning to use kalman filter? Is it a part of your curriculum or are you using it in some project? I will like to hear a bit more about it's application if it is related to a real world project, should be exciting. Anyways thanks for sharing.\" How are you planning to use kalman filter? Is it a part of your curriculum or are you using it in some project? I will like to hear a bit more about it's application if it is related to a real world project, should be exciting. Anyways thanks for sharing. Damn man.. you're sensitive. I would advise you to take it easy, it will save you a lot of bother in life.",
    "What's the most fucked up thing someone has told you about themselves after barely getting to know them?  Visited a coffee shop for the first time on holiday. Barista commented on my tattoos. I said thank you. She told me she's not allowed to get tattoos but she cuts herself to enjoy the pain and that's nearly the same thing. I found a different coffee shop for the rest of the holiday. Chatted with a huge middle-aged dude in a bar once who after about 2 minutes, told me that he had been in prison for bashing his dad's head in with a hammer. His dad used to beat his mom and one day he'd had enough of it. Temporary coworker tells me she was kidnapped raped and beaten by her ex husband. Burned with cigarettes, hands shoved in the garbage disposal, head beaten with a hammer. The incident resulted in a baby she somehow still has. And theyâ€™re not even divorced cause he wonâ€™t sign the divorce papers. I work in a small town gas station, Iâ€™m tryna check out customers and sheâ€™s reciting a true crime episode to me. The conversation started with mascara recommendations. It was the craziest thing Iâ€™ve ever heard Stuck driving a coworker out to a remote gas plant to do a system install.  He was kinda fucked up but assumed it was just socially awkward IT way.  Nope.  He starts telling me about him and his dad collecting nazi memorabilia and how proud he was of his German grandparents.   Trying to make other small talk and he would just trail off answering questions and start singing to himself.  Thought for sure Iâ€™d end up on the news and a manhunt would be conducted. \n\nSecond best story - met the neighbour right after we moved in and she started telling me about them wanting another kid but doing the deed was hard because she was overweight and had bad knees and it just made it difficult.  Iâ€™m a guy who never met her and have my kids playing mere feet away so I canâ€™t call her batshit crazy. A customer explained to me the benefits of a coffee enema to heal everything from my acne to preventing cancer. I couldn't get her to leave me alone for an hour because it was dead and no one was there to help. I worked for a skincare counter in a department store. Like if you don't need my products because cleaning your ass with coffee fixes it, why are you here?\n\nBut she went on about how she started her kids on these and did their enemas until they could do theirs on their own. What. \n\nThen she also grabbed my hands and kept saying promise me you'll try it. Promise me. She left after I promised. \n\nNo, I didn't try it. A guy told me during our first shift that his youngest daughter was suicidal, his eldest daughters boyfriend was terribly abusive, and his wife was sleeping with someone at her work. Apparently heâ€™d just gotten out of jail after flying home from out of state, beating the shit out of his daughters boyfriend, his brothers, and his dad, driving to his wifeâ€™s work and beating the shit out of her boyfriend, then driving to the hospital to hold his daughters hand after she had attempted suicide until the cops arrived to arrest him for aggravated assault. Had to get my picture taken for a visa so went to a local photography shop that took the pictures and printed them out for you right there. I had been talking to the guy as he worked on other people's photos and when I finally got my picture taken he started opening up about his family.\n\nApparently his son was killed 3 years ago in a car accident and he was telling me how much I reminded him of his son (going to school for engineering, 1st generation college student etc.). The son was killed in his senior year so didn't even get to graduate, he even showed me pictures it was heartbreaking.\n\nTo make things worse he said he had a degenerative muscular disease and doctors had given him about 2-3 years before he'd be bed ridden. He then went on to say his daughter was taking care of him and how she isn't married yet and deserves to live a young persons life and man, it really put into perspective how bad some people have it. I still think about that guy to this day and hope he's doing well. I made the unfortunate mistake of inviting my old neighbour over when we were having a party. He had like five gins in my kitchen and confessed to an unsolved murder in Nunavut, Canada.\n\nHe's in jail. Moved to a neighborhood not to long ago first person I meet was a older woman in her 50s. She told me all about her drug use and how sometimes she ends up outside naked and asked if I would help her back inside and put clothes on her. This was all in 5 minutes of saying hello. Sat on an Amtrak across from a very sweet older man, who within twenty minutes was telling me about the purpose of his trip to Maryland: to meet his biological father, who he had discovered via 23andMe, to discuss changing his last name, which was the condition of becoming being the sole inheritor of his fatherâ€™s estate. And that he was feeling a little guilty about that because his three half sisters would be excluded from their fatherâ€™s will because he â€œfinally had a legacy.â€ Woof. \nHe disembarked twenty minutes later, and I have thought about it constantly for the following four years.",
    "I quit my job to focus on SerenityOS full time  [deleted] It still blows me away how far this project has come in such a short period of time. Good luck! Wow! Congrats, dude.\n\nIt's heartening to see how much support you've garnered. I've been watching on and off for a while now (probably since late 2019 or so). Great to see how far this has gone! Really? That's awesome! Congrats to Andreas! Good luck you crazy man! You know, as someone who isn't and never has been religious in the slightest, I always did enjoy the serenity prayer quote, and I didn't even know it was called that until now! I'm not quite sure how to phrase this, but this reminds me of TempleOS.. but in a good way. Cool stuff! There are so many hundreds of videos, which one is best to start with? Hope it works out for you. In generations to come serenity might be the new Linux ;) Andreas you're the best. Your YouTube channel rocks. You should get Linus to make a channel as well, or even just go for a SerenityOS channel where you and Linus/others could post programming videos!\n\nGlad you have been able to stay on the straight and narrow for a while.",
    "A lot of people entering this field are like over-fitted models No disrespect to Ph'd's,  just an interesting analogy.\n\nlots of internal validation and creds,  but poor performance in the wild. Oh come on. Have you read job descriptions?\n\nMust have PhD in machine learning and computer vision and drug design and pharmaceutical engineering and rocket science plus demonstrated 20 years experience in each field. \n\nYou wonder why there's over fitting?. It's because employers over-hire skilled people to do bitch work. Overfitting gets stakeholdersâ€™ initial buy in. Poor performance guarantees your job next year.\n\n*TAPS HEAD Showerthoughts by data people Is it the model's (job seeker's) fault for over-fitting OR is it the fact the training dataset (pre-job training, e.g. what is taught in MSDS programs) is unlike the testing dataset (on-the-job responsibilities)? Let's get something out of the way: that is true of every single business profession. No one enters their job knowing what they should know about it.\n\nSome people here are saying \"oh, it's because professors don't know what the real world is like\" - which is abjectly wrong considering a lot of professors run businesses on the side. \n\nNo, the reason schools focus so much on such a small subset of the work is different - it's because workplaces do not have the time or expertise to teach you that stuff.\n\nHave any of y'all tried teaching someone Linear Algebra on the job? What about Calculus? Probability Theory?\n\nFollow-up: would you feel confident teaching someone those areas from scratch?\n\nThe answers are (with few exceptions) no and no.\n\nThat is the reason why schools focus so much on that stuff - because it's the only situation in your life where you will have both the time and the talent (professors) to teach you this stuff at the level that it needs to be taught.\n\nMore than that, for most people it's the only time in their careers where they will learn how to learn - i.e., learn how to go about tackling a completely new topic without substantial support. A lot of people in this field like to gate keep out passionate people who donâ€™t have PhDs as well. This is a weird statement because the PhDs in my department are the ones trying to keep the ones without PhDs from seeing everything as an excuse to throw the most complicated, resource-intensive deep learning model they can find at the problem from step one without any concern for experimental design. \n\nEverybody in this field seems to think theyâ€™re hot shit, but we all need to listen to each other better. Dunning-Kruger is a real thing. If you think somebody much more educated/experienced than you is an idiot, you should be very careful about that assumption and take a long hard look in the mirror before writing them off. Well when the fuckin recruiters need you to jump through ten million hoops, its hard to be good at anything other than jumping through hoops. That's true for any field though PhD in stats here, in the field for 20 years.  In my experience the best statisticians Iâ€™ve come across either have an MS in stats or a PhD in another field.  Enough training to be curious about data, but not so much as to want to reinvent the wheel each time.",
    "Tkinter Designer, Automate and beautify GUI creation â˜„ï¸ Tkinter Designer is created to speed up and beautify Python GUI Experience. It uses well know design software called Figma. Which makes creating Tkinter GUI in Python a piece of cake.\n\nhttps://github.com/ParthJadhav/Tkinter-Designer\n\nOf course you will need to tweak some things after itâ€™s created but it saves a lot of time. [deleted] Impressive. Still waiting for the day when a full fledged TK Designer will be shipped with Python, like Qt Designer This is awesome,  I was planning to do something similar. Is it ok that I write simple tutorial for this? Sure I will check it. No way, you said Tkinter and beautiful in the same sentence, that really looks awesome I am not so thrilled depending on external SaaS products. Iâ€™ll check this out. Big if true! Will definitely have a look, since I've been struggling to understand Tkinter wow looks interesting i'll check it out! Will give it a try",
    "Yes, I am in the process of correcting something similar now. My philosophy has been that, whenever you have something that hurts consistently like this, go and see a physiotherapist. Good physios are worth their weight in gold. \n\nThe problem has turned out to be a combination of tight [hip flexor](http://en.wikipedia.org/wiki/Hip_flexor) muscles, tight [piriformis](http://en.wikipedia.org/wiki/Piriformis_muscle), and weak glutes. Basically, my squat technique was slightly off, and I was not using my glutes as much as I was other muscles to compensate for their weakness, and this vastly aggravated the problem. \n\nI saw a physio who took me off squats immediately, and told me two horror stories of former patients who had consistently ignored problems like mine, and ended up having surgery on their hips. I was given some stretches and some remedial exercises, and I've been slowly improving over the last month or two. \n\nThe stretches/exercises I was given are roughly these:\n\n[Piriformis release](http://www.youtube.com/watch?v=HWfnAUsYUTI) (5 minutes each side)\n\n[Glute stretch](http://www.youtube.com/watch?v=gE6mJ0VjK7Y&feature=related) 1 min each side\n\n[Hip stretch](http://www.youtube.com/watch?v=qKFJOTk-cUE) I min each side\n\n[Glute bridge/march](http://www.youtube.com/watch?v=0oUhPdwgOOg) \n\n\nThe first exercise hurt so much on the tender spots that I found it hard to make it to 5 minutes. I also used foam roller exercises. \n\n**tldr;** Go and see a physio before you fuck up something important.\n\nEDIT: Also changed the way I sit at work, crossing one leg over the other at the ankle/knee an periodically leaning forward and contracting the target muscles. My physio says he has never seen anyone recover so fast, but part of the reason for this may be that I went to see him early before the pain became a serious issue. ",
    "1 month bucketlist I'm moving from San Diego in 1 month to the midwest.  What are the places I must try or have once more before leaving? Tacos El Gordo (tacos), Menya Ultra (ramen) I fucking love the effort people put into these comments, such a goldmine Taqueria Tuetano\nLola 55\nSalud\nTJ Oyster Bar\nFish tacos from your local truck\nCarne Asada fries from your favorite burrito/taco shop\n\n\nYouâ€™ll find new food to love (probably better barbecue, for example) but even if you find reasonably good Mexican food, it wonâ€™t be /San Diego/ Mexican food. Get it while you can. Tribute Pizza. Named by Thrillist one of the best pizzerias in the US. Also the best brunch in San Diego. Just ridiculously good. -\tChurchills for wings in San Marcos\n-\tjalapeÃ±os in carmel mtn for their California/carne asada burrito\n-\tplumeria\n-\tmorning glory\n-\tcoyote cafe for their homemade tortillas (and anything that has their chipotle cream sauce)\n-\thash house\n-\tsnooze\n-\ttacos el gordo/tj tacos for their adobada\n-\thandles/salt and straw\n-\tBatch & box\n-\tSide car or donut bar\n-\textraordinary desserts if youâ€™re into that thing\n-\tyellow deli if you donâ€™t mind eating at a cult lol\n\nIâ€™m not a fan of a few of the places but most of those are the â€œgo-toâ€™sâ€ despite everybody having their own personal spot that they like better. Like I donâ€™t like hash house and prefer a dozen other breakfast spots but itâ€™s pretty popular . Rakiraki Ramen on Convoy\n\n. Lolitas for a California burrito\n\n. The Taco Stand for Carne Asada fries\n\n. Crack Shack for their Chicken Sandwiches and Mexican Poutine\n\n. Better Buzz for an AÃ§aÃ­ Bowl. Your favorite taco shop. A fresh West coast IPA Sushi Ota and Wrench and Rodent. Omakase all the way - fun to compare the two very different styles and appreciate what a sushi chef can do. \n\nFor a non-sushi Japanese food option highly recommend Okan (lunch) or Oton (dinner). Or honestly just take a tour down Convoy and enjoy the diversity San Diego has to offer.\n\nHonorable mention - Muzita Abyssinia which is always my request for bday dinner. Beautiful dining experience and amazing food go to Tom Hamâ€™s Lighthouse! When we went they were doing endless mimosas and brunch buffet. Itâ€™s expensive but worth it.\n\nLos Titoâ€™s in La Mesa (looks sketchy but great food) for amazing California burritos and pickled carrots/jalapeÃ±os.",
    "The Economist's excess deaths model  This was some of the best analysis done on COVID death rates. It does what few others tried to do, which is mostly eliminate the at least somewhat frequently subjective, unscientific classification of deaths during the last year as COVID-related.  \n\n\nIt stands to reason that, short of natural disasters and other relatively rare phenomena throwing a wrench in the works, excess deaths would be a better measure of COVID deaths in the absence of virology findings from the coroner's office or hospitals for every corpse. Looking at the quality of the code helps me with my imposter syndrome. Mine ain't too bad Their confidence intervals are constructed by retraining their model on a bootstrapped sample of their data, and using the nth percentile of the model predictions as the upper bound of an nth percent confidence interval.\n\nIs this justified with gradient boosting models? I thought generally sampling with replacement wont work here either because of min data in leaf criteria or early stopping criteria I do like how they got burned by `select()` getting masked, this happens to me all the time in R \"Economics, the science of explaining why the predictions you made yesterday did not come true.\" - inspirational poster Shhh! You're not allowed to talk about how terrible all of the modeling was during the pandemic. That's a lot of work for a similar number to what I would have ballparked in my head given my background in respiratory epidemiology? \n\nI love infectious diease modeling probably more than the next guy, but this entire pandemic I've been bewlildered by the staggering amount of resources that have been thrown at super approximate ML models. Like, what value do these provide? It frustrates me because it confuses the decision-makers--they don't know what a model might be good at predicting for when, and how it should be used. They just know they need one!\n\nThis doesn't add new information, but it sounds fancy. It's interesting to look at from an academic perspective, but I've watched this stuff unseat experts that are needed at the table. This is going to feed into everyone's pre-existing biases:\n\npro-lockdown side: See covid death estimates of 3 million were actually under-estimated, they were anywhere from 7-13 million. If we hadn't locked down that number would be even larger.  \n\n\nanti-lockdown side: See covid deaths were nothing compared to lockdown deaths. Only 3 million died of covid, another 4-10 million died from covid lockdown policies.  \n\n\nWe should be able to use data science to differentiate the causes given the different countries with different responses to the virus right? This graph just doesn't do it. [deleted] W-why is the code bad? I'm just asking for a friend, I definitely don't have a script open on the second monitor with code that's written in a remarkably similar style, no no.",
    "California Wonâ€™t Be Getting Speed Enforcement Cameras  Instead they will be investing in cameras at every controlled intersection. Fining drivers failing to make a complete stop when making a right turn /s Can we get rid of the traffic signal ones? Cameras can't discriminate between your car and the car of powerful folks who are outraged to get a speeding ticket. What we really need is WAY better public transport and probably stricter enforcement on reckless driving. Looking at this thread, it's a total mystery why traffic deaths went up even as vehicle miles traveled plummeted this last year. car sociopaths wiling-out in this thread\n\nhttps://i.imgur.com/ZcTYikI.gif Having lived in d.c. where speed cameras are embraced I can tell you they provide nothing. All the locals know where they are and the entire traffic pattern is 75 mph then it slows to 55mph for a .3 miles stretch, and bam back up to speeding.\n\n\nEven the GPS app ways and google maps will provide an alert for \"speed camera ahead\" hmm, but realistically speaking, what is the best way to enforce speed limits inside cities?  Besides making streets narrow and taking away lanes, what is the most cost effective and efficient way to fairly and equitably enforce speeding laws and perhaps other traffic laws?  I think everyone can agree that when most people are driving above the posted limit, each police officer can only catch one speeder per 10-30 minutes, which isnâ€™t a very good way to go about it. good Then whatâ€™s a better alternative cause my street just had a 7 car pile up today earlier in the evening.",
    "A tutorial on how to organize a Selenium Bot Project being a more production-ready project, Dynamically adding Driver to PATH, and the ability to run the project from a CLI more smoothly.  I recently discovered [pylenium](https://docs.pylenium.io/).  Lots of user friendly features that basically eliminates all the scaffolding you would normally have to build yourself with plain vanilla selenium.  It even does automatic driver management.\n\nEdit: Thank you for the silver! May I suggest kootenpv/cliche library for creating the cli Remind me! 1day Bro Kevin,I wanna ask that how can you let your written python codes output work on mobile ? > Also, many people blame Selenium for bad or flaky tests. This usually tells me that they have yet to experience someone that truly knows how to make Selenium amazing! This also tells me that they are not aware of the usual root causes that make Test Automation fail:\n- Poor programming skills, test design and practices\n- Flaky applications\n- Complex frameworks\n\nThese are the main reasons. Also, unless I do testing for an application Iâ€™m directly involved, where I advocate the use of test-exclusive data tags, I first try to see if targeting text or text similarity is a better idea.\n\nI wish there was something like CodeceptJS for Python. Itâ€™s by far the best solution for testing and automation that Iâ€™ve encountered. Mate, my life's work was based in selenium and I think you saved my life! How did I not come across this! Will def check this out!! Didn't know about this - will be checking it out! This project looks amazing, I regret I did not read the MD of the repository the minute you shared this comment!   \nAre you the maintainer? I am even thinking about creating a tutorial on this one. Just replying to find later. Def will be using this",
    "[P] Find Trending Machine Learning Research Papers on Twitter We developed a website to find popular/trending research papers on Twitter. \n\n**Link:** [https://papers.labml.ai/](https://papers.labml.ai/)\n\nFeatures that I like to highlight here:\n\n* Analyses the Twitter feed and shows popular/trending research papers daily, weekly and monthly basis.\n* Shows tweets, retweets and likes count for each paper so that the user can filter out random papers.\n* Shows, popular tweets that related to each research paper.\n\n**We love to hear your feedback and suggestions**. Thank you all and I appreciate the support. **\\*Update\\*:** Thanks for the feedback about not working on certain browsers, and all the help with debugging the cause. It looks like Sentry integration (ironically, to find bugs) was causing the problems, and we just removed the integration. And s few users confirmed that it's working now. ðŸ˜Š Thanks again for the support! ah yes, now I don't need to log into twitter everyday [removed] I'm in Materials Science - is there a similar similar for battery papers? That's amazing.Later on you could also add searching for different tags (NLP,CV etc) It doesn't work on Firefox. It just shows blank page Really great work, congratulations! Release it on Producthunt too? Will help a lot of people. Damn! This is really cool! awesome project. Thanks so much for sharing. Would it be possible to add Atom RSS feed? Not sure if it has been suggested but here goes some dream features:  \n\n\nMy top feature would be **a way to filter for recent \"popular\" papers** and then have some prespecified metrics i.e. likes etc. Without this feature the website is basically just my twitter feed.  \nHaving this feature work with timeframes like daily, weekly and monthly would make it alot easier to stay up to date each week with the popular papers.\n\n**Filtering by specialization** would of course also great.  \n\n\nIf possible i would also love if there was a **byline containing the research institution or company that produced the paper**, as i am naturally more interested in specific institutions research due to their field and scope aligning with mine.\n\n&#x200B;\n\nAwesome initiative and i really love your other community initiatives such as the annotated Pytorch models.",
    "Kevin Murphy's second ML book draft is out! [https://probml.github.io/pml-book/book1.html](https://probml.github.io/pml-book/book1.html)\n\nHis first book (book0) was published in 2012, it lacks deep learning and reinforcement learning.\n\nHis second book's draft is out recently (official publish date is Feb 2022). Good to see neural network stuffs in his rigorous writings.\n\nHis third book (book2) is expected coming out late 2022. [https://probml.github.io/pml-book/book2.html](https://probml.github.io/pml-book/book2.html)\n\nI'm working on solutions on the second book (book1) in my GitHub (Solutions for book0 : [https://github.com/frozenca/ML-Murphy](https://github.com/frozenca/ML-Murphy)). Will upload them once finished! Mildly related question - how long does it normally take for you all to go through a book? Iâ€™m going through Hands on ML by Aureleon Geron and I feel like Iâ€™ve been very slow with it. I have an engineering background but very little experience with programming so I find myself spending quite sometime just figuring out programming related things more than actual ML. Any insight or advice would be appreciated Hi , a small question.\n\nI was about to try this book. Which do you think is more rigorous this or PRML by bishop.? Is this stuff a great way of learning the concepts initially? It seems more like a reference book for people who've already learned it all. Oh yes!!!!!!!!!!!! RemindMe! 2 weeks. RemindMe! 2 weeks RemindMe! 1 week RemindMe! 2 weeks RemindMe! 1 week I've been reading PRML and it took me...3 years.\n\nThat's not to say I've really *read* read it until the past year. I tried reading chapters 1 and 2 in 2017, with no prior programming or stats experience and I got virtually nowhere. The book's probability section was too hard for me to follow.\n\nSo I detoured for a long time to learn programming, and then last year I got around to learning stats until I could say now that I spiritually have a minor in stats. Now I can actually read it and fill in gaps where it's oversimplifying things.",
    "[N] Pornhub uses machine learning to re-colour 20 historic erotic films (1890 to 1940, even some by Thomas Eddison) As a data scientist, got to say it was pretty interesting to read about the use of machine learning to \"train\" an AI with 100,000 nudey videos and images to help it know how to colour films that were never in colour in the first place.\n\nSafe for work (non-Porhub) link -> https://itwire.com/business-it-news/data/pornhub-uses-ai-to-restore-century-old-erotic-films-to-titillating-technicolour.html The real purpose of machine learning has been fulfilled, peace So are you saying PornHub is gonna be a leader in ML research soon? FAANG will be soon replaced by FAAP? (Jk) If the quality is only as good as in that trailer, I'm surprised they considered it \"good enough\" with such intense temporal inconsistency issues... [deleted] DeOldify creator here- at 0:53 they show a screen which is literally DeOldify code plus their new get\\_porn\\_video\\_colorizer model.  I'm assuming this is real, based on the video quality looking an awful lot like DeOldify- the noted temporal consistency issues, etc.\n\nFinally, something useful  came out of that project! Thatâ€™s why I got into this field. Think of list \"Pornhub Research/Brain/Inc. \" as institution in a top conference paper. \n\nResearch scientist at Pornhub just became my dream job. [deleted] Any available code for this? What did they use - TF2, Pytorch, etc? Which algorithms/research papers? Machine Learning's Rule34",
    "The chalk drawing I made for my daughter and her fellow graduating classmates  This is amazing! How long did it take you to do? Username definitely checks out here. I gave a quick scroll through your post history really amazing stuff! What made you get into chalk art in the first place? Hereâ€™s the [reverse angle](https://ibb.co/9vDB8Bs) It's so good it looks fake. Crazy that it's chalk...how long does it last?  This is really amazing work! If you see this comment, I'd love to know the process of planning one of these out! Thatâ€™s insanely wonderful! Great job!! Nice work! Looks like the sun hid long enough to get a perfect picture. Yinz did good nâ€™at. No way! If this is south west PA then this is the current town I live in!!! It pops right off the screen, this is some next level shit, I'd pay you to do this at my kid's school, fuck yeah",
    "Am I irrationally upset? Yes. But refried beans inside a California Burrito besmirches our good name!  Where they hell did they do this research???\n\n>In San Diego, theyâ€™re sometimes served with carne asada by default\n\nSometimes???\n\n>A humble bean and cheese burrito, a school lunch staple in Southern California\n\nThat's just a staple, no qualifications necessary. Could be worse. There was a pretty good burrito place in Seattle, guy was from Texas, salsas and meat were on point, and most importantly *he didnâ€™t put rice in by default*.  You had to ask for that nonsense. Honestly one of my favorite spots for a burrito. \n\nExcept the Cali. \n\nThe â€œCalifornia burritoâ€ had rice. *And* fries. \n\nBoth. \n\nI didnâ€™t even have the heart to tell him. This is worse than when The NY Times put peas in their guacamole.   Unforgivable. They should call it something else. It's not a Cali burrito if there are beans in it. I just want to take a moment to give a shout-out to my favorite shop Don Tommyâ€™s. The handmade tortillas are superb. They start out by saying California burritos are maligned? Pfft I just finished eating my favorite breakfast burrito. I like it because it has beans in it. But in a California? No. Depends on the person honestly. Iâ€™m Mexican & put beans on everything. But I always ask if the beans are fresh or canned. Thatâ€™s what makes the difference Former New Yorker here- they have awful mexican food there. i didnt see beans on it on their menu. i think the eater writer just doesn't know. more likely than a self-described local doing it. who knows. bizarre.",
    "Trading commandments that are necessary [removed] I was just talking to someone about #9 in the crypto sub. OP on that post sold their crypto profits after years of holding to pay off their mortgage! It was amazing! :D But someone in the comments was pissed,  basically saying \"what if you sell now and the market suddenly explodes?\" They were speaking through the perspective of greed and emotion while the OP on that post was rational and took the profits and won the game. \n\nIt's soooo important to keep our emotions in check or else that Fear of Missing Out (FOMO) and greed will be your downfall. Great post man! Number 3 is to not buy stocks under the 50 day SMA. Maybe this past year is an exception, but the best investments you could have made a year ago were stocks very much below their 50 day SMA. I feel personally attacked ***never be so greedy you donâ€™t take profits.***\n\nnot following this advice has led me to have many regrets... A stock you bought is up 100%? For godsake, sell at least some of it \"Follow these rules, you'll have mad bread to break up\" Good post I need to follow 1 & 2. Good post These are super great. I made a copy. \n\nOne issue I struggle with is that I feel generally reluctant to sell, mainly due to tax implications. \n\nI could make an effort to do all my active trading in the tax-free zone of an Roth IRA account (I have a new Roth IRA account now on Webull). This might allow me to be less trigger-shy on hitting the sell button. Nice post",
    "A guide to load (almost) anything into a DataFrame Pandas provides so many options of reading data into a DataFrame, here's our short guide to ones that we found most useful. [https://gretel.ai/blog/a-guide-to-load-almost-anything-into-a-dataframe](https://gretel.ai/blog/a-guide-to-load-almost-anything-into-a-dataframe) This is a great reference for people who don't want to scour stack overflow when they need to load something into a data frame\n\nWell done Love the one-liner to load a Wikipedia page as a Pandas DataFrame NICE. Didn't know about the S3 cache stuff\n\nDon't forget about https://aws-data-wrangler.readthedocs.io/\n\nBasically AWS interop w Pandas Push a CR to the docs. Is there a difference between read_sql_query and just plain read_sql? Also a shame you didnâ€™t go in my biggest pita xml to df remindme! 40 days Thank you for this That was quite helpful! Thanks for sharing it here! Awww yeah. Love me some fsspec. The lines for loading stuff is all fine and well. The real problem is having the right libraries. Like trying to import an excel spreadsheet usually means installing one library that tells you it also needs another library that in turn tells you its the wrong library and that another one is correct if you are importing an xlsx and not xls file.",
    "Ranking every class I ever took at Purdue Easiest to hardest.\n\nFor some perspective, I am a dual major with CS and Math and an Econ minor. I like math, and hate writing. Everything is only an opinion. YMMV.\n\n&#x200B;\n\n1. MA 490 - Show up, pass. No homework.\n2. CS 191 - Seminar, minimal work.\n3. CS 193 - Small labs, slightly annoying but very little work.\n4. ECON 251 - Extremely easy course. Everything intuitive.\n5. MA 375 - Very easy, sometimes homeworks can be tedious.\n6. ECON 252 - Slightly harder than ECON 251, but you can still get an A without watching lectures.\n7. CS 391 - Online for me, weekly one-page essays. Just sorta annoying.\n8. AGEC 250 - Had a brilliant professor (Otto Doering) who would just tell stories. Fascinating, easy exams, one HW assignment all semester.\n9. STAT 350 - Extremely easy content, extremely cancerous class setup. Complete waste of time and money.\n10. CS 180 - Pretty easy intro CS course.\n11. BCHM 100 - Some lessons were middle school level, some were somewhat advanced. In that regard, it tricked me.\n12. EAPS 327 - Easy all semester, but the essay at the end was a big time sink for me. I do not like essays.\n13. MA 362 - Calc 4, but basically just a review of calc 3 with a few added concepts. Easy when you already took MA 261.\n14. ECON 340 - ECON 251 but with calc. Not bad.\n15. MA 385 - Content was pretty easy, but homeworks and exams were long. Probably gave me mild arthritis.\n16. CS 373 - Homeworks were just translating pseudocode into python. Exams weren't easy, but we were given 24 hours to do them.\n17. MA 261 - Just grind the practice tests until you get every question, and you will ace the tests. Trust me.\n18. ECON 461 - Not bad, but take ECON 340 first. Lots of overlap with ECON 451 too.\n19. MA 366 - Labs and homework were tedious, but content was pretty well laid out and easy to reproduce on exams.\n20. MA 351 - More thinking involved than MA 366, but less overall content.\n21. CS 314 - Low quality class, didn't learn much, but not terribly difficult. Quizzes and exams were either very hard or very easy.\n22. ECON 451 - Exams were too long. Interesting class though. Overlap with ECON 461.\n23. CS 182 - A grab bag of a ton of random mathematical concepts related to CS. Hard because it's just so disjointed.\n24. ENGL 106 - I do not like essays.\n25. CS 250 - Not terrible, but can be a bit overwhelming at first with assembly / hardware.\n26. CS 251 - Mid-tier CS class. Not easy, but not impossible. Also critically important for getting a job.\n27. COM 217 - I do not like essays part 2, but with speaking too.\n28. CS 240 - Thx Turkdaddy for the code standard that was extremely stringent and hard to follow. Plus, fuck pop quizzes.\n29. CS 355 - Took with Maji - extremely math heavy, tons of proofs. Learned a lot though.\n30. MA 353 - Linear 2, bad prof, content hard to follow, didn't learn much.\n31. MA 453 - Hard in every aspect, but very interesting.\n32. CS 381 - A few homeworks with a few questions each, but each question took a ton of thinking and explaining. Exams are rough. Absolute must take if you're a CS major.\n33. MA 341 - Represents a shift in the way that you do math. No more learning processes and regurgitating it on an exam like calc, linear and diffeq. You gotta actually prove things.\n34. CS 354 - OS, learned a lot - but more from the lectures than labs, which was unexpected. Exams were long, free response, and graded harshly. Labs were hard too.\n35. CS 252 - Just so much work. Thanks for your insight! I'm thinking about doing something like this when I graduate, but for ECE classes. [deleted] What was your track choice? Or choices if you took multiple? I'm shocked at your placement of ECON 251. I had a lot of trouble with that class (even though Dr. Blanchard is awesome) and didn't find it all that intuitive. I will agree with your notes on ECON 252, though. I just finished that course and think I'm getting an 85 or so. To each their own. Thanks for all the insight! The Econâ€™s are not easy work. I had to work extremely hard to get a c in the class. What was the title of the MA490 you took and what prof did you have? How many credits did you take it for You can't just mention an 490 and not say whose 490 it was.  At Purdue, 490 means \"whatever the professor wants to do, lol\".  One professor's 490 will be 100% different than another's 490. Love this post. Rank from 1 to 10 overall on the professors..10 is superb. Overall all together. Oo I'm graduating from ME next semester, I would kinda like to do this too hehe [deleted]",
    "Suggested courses / material / books to start working as an DE Hi, I worked as a Data Analyst last year and I will start working as a Data Engineer.\n\n\nIn this new position I will work with Python, PySpark, SQL and Airflow, IoT platforms such as ThingWorx, container technologies and cloud solutions such as Azure, namely Data Lake and Machine Learning services.\n\nMy last year as a Data Analyst I worked daily with Python and some SQL.\n\n\nI would like to know suggestions for courses / videos / books / material to learn more about PySpark and Apache Spark, Airflow and the rest of the technologies mentioned above.\n\n\nThank you very much\n\nEDIT: I have recently bought the book \"Designing Data-Intensive Applications\" and know about the \"Awesome Data Engineering\" github (https://github.com/igorbarinov/awesome-data-engineering) YMMV, each DE and role has different needs but I found these helpful. My team and myself built a weekly study session around these and it has already paid dividends many times over.\n\n&#x200B;\n\n*  The Data Engineering Cookbook by Andreas Kretz\n* Agile Data Warehouse Design: Collaborative Dimensional Modeling, from Whiteboard to Star Schema by Lawrence Corr\n   * This one particularly helped me when lifting 19 distributed databases in mixed db architextures to a MDL in AWS.\n* Foundations for Architecting Data Solutions: Managing Successful Data Projects\n\n## Microsoft has a ton of free courses for data engineering on Azure. Here is ten hours of content for Databricks. https://docs.microsoft.com/en-us/learn/paths/data-engineer-azure-databricks/ There's an awesome list for learning path too  \n[https://awesomedataengineering.com/](https://awesomedataengineering.com/) # DE Prep\n\n## Database Basics\n* ACID\n\t* [wiki ACID](https://en.wikipedia.org/wiki/ACID)\n\t* [SQL ACID](https://blog.sqlauthority.com/2007/12/09/sql-server-acid-atomicity-consistency-isolation-durability/) \n\t* [ACID vs BASE](https://www.dummies.com/programming/big-data/hadoop/acid-versus-base-data-stores/)\n* CAP Theorm\n\t* [CAP theorm](https://robertgreiner.com/cap-theorem-revisited/) \n\t* [CAP theorm basics](https://www.learncloudnative.com/blog/2019-11-22-basics_cap_theorem)\n* Indexes\n\t* [index basics](https://www.red-gate.com/simple-talk/sql/learn-sql-server/sql-server-index-basics/) \n* Partitions\n\t* [partitioning-in-sql-server](https://www.cathrinewilhelmsen.net/table-partitioning-in-sql-server/)\n\t* [mysql-partitions](https://www.vertabelo.com/blog/everything-you-need-to-know-about-mysql-partitions/)  \n* [consistency models](https://jepsen.io/consistency)\n\n\n## SQL\n* Query Processing\n\t* [linkedin learning query processing](https://www.linkedin.com/learning/advanced-sql-logical-query-processing-part-1)\n\t* [sql query processing order](https://sqlbolt.com/lesson/select_queries_order_of_execution) \t\n\t* [query-processing-order](https://github.com/ujwaltrivedi/dataengineering/tree/main/SQL#query-processing-order)\n* Window Functions\n\t* [linkedin learning](https://www.linkedin.com/learning/advanced-sql-window-functions) \t\n \t* [mysqltutorial window functions](https://www.mysqltutorial.org/mysql-window-functions/)\n  \t* [toptal window functions](https://www.toptal.com/sql/intro-to-sql-windows-functions)\n* Analytical Functions\n* String Functions\n* JSON Functions\n\t* [MySQL JSON functions](https://dev.mysql.com/doc/refman/8.0/en/json-search-functions.html) \n* DateTime Functions\n* [Grouping with rollup](https://dev.mysql.com/doc/refman/8.0/en/group-by-modifiers.html)\n\t* [grouping](https://dev.mysql.com/doc/refman/8.0/en/miscellaneous-functions.html#function_grouping) \n* Joins\n\t* [SQL joins](https://riptutorial.com/sql/example/22934/join-terminology--inner--outer--semi--anti---) \t\n* Recursive CTE \n\t* [percona-recursive-cte](https://www.percona.com/blog/2020/02/13/introduction-to-mysql-8-0-recursive-common-table-expression-part-2/)\n* Anomaly Detection\n\t* [sql-anomaly-detection](https://hakibenita.com/sql-anomaly-detection)\n\t* [sql-find-outliers](https://dataschool.com/how-to-teach-people-sql/how-to-find-outliers-with-sql/)\n* Customer/Churn Analysis\n* LearnSQL Course \n\t* [learnsql](https://learnsql.com/course/sql-basic-reporting)\n* Functions\n* Performance Tuning\n\t* [linkedin-learning-performance-optimization](https://www.linkedin.com/learning/advanced-sql-for-query-tuning-and-performance-optimization)\n\n\n## Data Modeling\n* [linkedin learning 1](https://www.linkedin.com/learning/relational-databases-essential-training) \n* [linkedin learning 2](https://www.linkedin.com/learning/database-foundations-data-structures)\n* [data modeling 1](https://www.guru99.com/data-modelling-conceptual-logical.html)\n* [data modeling 2](https://www.credera.com/insights/data-modeling-explained-in-10-minutes-or-less/)\n* [ont to one](https://en.wikipedia.org/wiki/One-to-one_(data_model))\n* [one to many](https://en.wikipedia.org/wiki/One-to-many_(data_model))\n* [many to many](https://en.wikipedia.org/wiki/Many-to-many_(data_model))\n\t* [associative entity](https://en.wikipedia.org/wiki/Associative_entity) \n* Database Normalization\n\t* [database-normalization 1](https://www.essentialsql.com/get-ready-to-learn-sql-database-normalization-explained-in-simple-english/) \n  \t* [database-normalization 2](https://docs.microsoft.com/en-us/office/troubleshoot/access/database-normalization-description)\n  \t* [wiki database normalization](https://en.wikipedia.org/wiki/Database_normalization)\n* Best Practices\n\n## AWS Guides\n* Redshift \n\t* [re-invent 2019](https://www.youtube.com/watch?v=lj8oaSpCFTc&ab_channel=AWSEvents)\n\t* [Redshift Analyst Guide](https://dev.to/ronsoak/series/3044)\n\t* [amazon-redshift-fundamentals](https://s3-eu-west-1.amazonaws.com/cdn.jefclaes.be/amazon-redshift-fundamentals/aws-redshift-fundamentals.html)\n\t* [speed-up-redshift-syncs](https://segment.com/blog/speed-up-redshift-syncs/#)\n\t* [redshift-performance-tuning-techniques](https://www.intermix.io/blog/top-14-performance-tuning-techniques-for-amazon-redshift/)\n* Athena\n\t* [performance-tuning-tips](https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/) \t\n* Glue\n* EMR\n\t* [EMR best practices](https://www.youtube.com/watch?v=dU40df0Suoo&ab_channel=AWSOnlineTechTalks) \n\n## DW Theory / Kimball \n* [youtube playlist](https://www.youtube.com/watch?v=DV4IMjnL_IU&list=PLPhtPwFG9i7sJmGzzwMUCcbGR4YCWEvQx)\n* [how to read kimball](https://www.holistics.io/blog/how-to-read-data-warehouse-toolkit/)\n* [kimball techniques***](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)\n* [data warehousing basics](https://www.guru99.com/data-warehousing.html)\n* [data warehousing basics](https://www.1keydata.com/datawarehousing/dimensional.html)\n* OLAP vs OLTP \n\t* [vertabelo: oltp-vs-olap](https://academy.vertabelo.com/blog/oltp-vs-olap-whats-difference/)\n* Star Schema vs Snowflake Schema\n\t* [star schema](https://www.geeksforgeeks.org/star-schema-in-data-warehouse-modeling/)\n\t* [snowflake schema](https://www.geeksforgeeks.org/snowflake-schema-in-data-warehouse-model/)\n\t* [star vs snowflake](https://www.guru99.com/star-snowflake-data-warehousing.html)\n\t* [star vs snowflake](https://www.xplenty.com/blog/snowflake-schemas-vs-star-schemas-what-are-they-and-how-are-they-different/)\n\t* [star vs snowflake](https://www.upsolver.com/blog/difference-between-star-schema-and-snowflake-schema)\n* Types of Dimensions\n* Types of Facts\n* Slowly changing dimensions\n* Data Marts\n\t* [data mart 1](https://panoply.io/data-warehouse-guide/data-mart-vs-data-warehouse/)\n\t* [data mart 2](https://www.guru99.com/data-warehouse-vs-data-mart.html) \n* Important Topics\n\nOther than that (and putting aside all of the awesome knowledge from the DE lord and savior, Kimball) it largely boils down to: \n\n\t* SCD2/5 and merge statements\n\t* implementing auditing and DQ tables\n\t* handling early/late arriving facts\n\t* experience knowing what calculations belong in the relational/storage layer vs the semantic layer\n\t* query optimization + a few other practical issues.\n \n* Best Practices\n\n## Python Coding\n* LeetCode Easy\n* [Python DSA](https://www.programiz.com/dsa/algorithm)\n* [grokking-the-coding-interview](https://www.educative.io/courses/grokking-the-coding-interview/N7rwVyAZl6D)\n* [Python reference](https://www.programiz.com/python-programming/methods)\n* [14-patterns-of-coding](https://hackernoon.com/14-patterns-to-ace-any-coding-interview-question-c5bb3357f6ed)\n* [Big O](https://web.stanford.edu/class/archive/cs/cs106b/cs106b.1176/handouts/midterm/5-BigO.pdf)\n* [Time Complexity of Recursive Function](https://stackoverflow.com/questions/13467674/determining-complexity-for-recursive-functions-big-o-notation)\n* [Big O Practice](https://www.geeksforgeeks.org/practice-questions-time-complexity-analysis/)\n\n## Airflow Concepts\n* [youtube playlist](https://www.youtube.com/watch?v=IH1-0hwFZRQ&list=PL79i7SgJCJ9hu5GqcA091h6zuewmsvSyy&index=31)\n\n## ETL/ Data Pipeline\n* [designing-a-big-data-solution](https://medium.com/data-alchemist/what-questions-to-ask-when-designing-a-big-data-solution-on-aws-8db8905d8712)\n* [AWS Data Analytics Fundamentals](https://www.aws.training/Details/eLearning?id=35364)\n* [Data Pipeline Examples](https://www.intermix.io/blog/14-data-pipelines-amazon-redshift/)\n* [Uber's Big Data Platforrm](https://eng.uber.com/uber-big-data-platform/)\n\n# Misc\n\n## Distributed Systems\n* [patterns-of-distributed-systems](https://martinfowler.com/articles/patterns-of-distributed-systems/)\n* [fallacies of distributed systems](https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing)\n\n## misc misc\n* [brag document](https://jvns.ca/blog/brag-documents/)\n* [howtobragatwork](https://www.careerfair.io/reviews/howtobragatwork)\n* [managing up](https://jvns.ca/blog/things-your-manager-might-not-know/)\n* [data-engineer-roadmap](https://github.com/datastacktv/data-engineer-roadmap)\n* [awesome data engineering](https://awesomedataengineering.com/)\n* [data-science-linux-command-line](https://blog.robertelder.org/data-science-linux-command-line/) [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://1lib.us/book/3367370/62327b)\n\n[The Data Warehouse ETL Toolkit : Practical Techniques for Extracting, Cleaning, Conforming, and Delivering Data ](https://1lib.us/book/968413/b18393)\n\nThe second one, written by Ralph Kimball, is basically the Bible for data warehouse developers. You won't see any HDFS/Spark/NoSQL in that book, but the data modeling fundamentals are so important to get right. Designing data intensive applications is a great book. Also the data warehouse toolkit by kimball is very good. Just put together a blog on this. [https://www.whiteowleducation.com/best-practices-to-become-a-data-engineer/](https://www.whiteowleducation.com/best-practices-to-become-a-data-engineer/) It covers really everything that you need in terms of the prep work (although the data engineering part of the blog topically touches into Google Cloud and AWS). Congrats on moving forward in your career!! Wish you luck. Iâ€™m not a data engineer just celebrating your progress. For further data warehouse modeling Star Schema: The Complete Reference by Chris Adamson is a great book to supplement with the Ralph Kimball text. RemindMe! 10 days",
    "Our template to kickstart your deep learning pytorch projects, with list of best practices. Minimal boilerplate code. Focused on scalability, reproducibility and fast experimentation. Link: [https://github.com/ashleve/lightning-hydra-template](https://github.com/ashleve/lightning-hydra-template)\n\nHi all,\n\nI   kept running into scaling issues with my Machine Learning projects -  it's really hard to  maintain all the differents configurations of  experiments, proper file  structure, clean code, and make it possible to  run the same code on  multi-GPU setup or computing clusters.\n\nAfter iterating over a couple of different frameworks and project structures I found the PyTorch Lightning + Hydra combination to be really simple but powerful at the same time.\n\nIt allows us to:\n\n* encapsulate our usual pytorch code into Lightning abstractions, which make it more clear and easy to read\n* easily   switch between different models, data, optimizers, etc. (thanks  to  Hydra configuration management) and override any yaml config part from   command line without writing argparse\n* running the same code on multi-gpu\n* setup the whole hyperparameter optimization of any new model with single yaml  file\n* and many more! (checkout the [\\#Your Superpowers](https://github.com/ashleve/lightning-hydra-template#your-superpowers) section of the readme)\n\nAll of this with relatively little boilerplate.\n\nI hope some of you will find it useful! This is amazing!!!\nFor a beginner like me, it would give lots of insight on how to be productive with experiments and knowledge of different frameworks used by professionals. \nThanks a lot. Love well organized project structures! Thanks for the good work here <3",
    "Most Helpful GitHub Repositories for Computer Science People  Thanks for posting to /r/computerscience! Unfortunately, your submission has been removed for the following reason(s):\r\n\r\n* **Rule 4:** Posts advertising a product, service, blog, YouTube channel, job opening, etc.\r\n\r\n\r\n\r\nIf you feel like your post was removed in error, please [message the moderators](https://reddit.com/message/compose?to=/r/computerscience). [deleted] That may be accurate, but it's imprecise and a bit mean.\n\nI do disagree with the list as well, simply on the principle that it is a list. I think it's very strange to pick out these repositories on a site whose entire purpose caters to \"computer science people.\"\n\nAnd by that they probably mean students, as people with degrees and jobs would likely have their own list. But then why these? Or why not \"how to find your own resources\", or a link to the \"awesome lists\" that are much, much more comprehensive than this blog post.\n\nIt comes of as sketchy self-promotion more than anything useful.",
    "https://mml-book.com\n\nEdit: For an ML Eng that will cover the basics quick, but of course it depends on the role. I've had trickier probability questions than is covered in that book asked. For example once a question about a blinded survey: So from covid everyone knows that the positivity rate isn't the true positive rate, you have to convert using Bayes rule. So say now some number of results are randomly flipped? ",
    "how to talk with a human at the IRS  They'll change the decision tree matrix now. I talk with humans from the IRS all the time, they call me every day telling me that thereâ€™s a warrant out for my arrest Whoever put this together is a hero. I just cannot STAND this stuff... the worst  is navigating your way around a maze of questions and then you get close to where you need to be and press the wrong digit, then have to redial and wait and try to remember the sequence, and when they make you listen to the full options before allowing your digit to register and go thru to the next level... oh man I havenâ€™t had to do it in a long time but just thinking about it is stressing me out!!\n\nOh and having to listen to the â€œdid you know you can do x y a on our website? Simply go to blah blah, where ...â€ Yes I know! I know! Lol [removed] Real Life Walkthroughs/Cheats My country is mandatory to have an option to a real person in the first set of options Or in other countries, you just let the government do your taxes, you just have to double check, and you can thank corrupt government and lobbying by accountants for all the extra work you have to do to file your taxes. What an absolute circus. This is an awesome guide! Very sad that it has come to this though... Iâ€™ve learned if it is a automated voice to talk in gibberish theyâ€™ll send you to a real person because they cannot understand you.  I could be wrong itâ€™s worked for me I learned through trial and error.",
    "The NLP Index: 3,000+ code repos for hackers and researchers. [Project] Want to introduce â€œThe NLP Indexâ€, a new asset in NLP code discovery. It's free and open to the public.\n\nIt houses over 3,000 code repositories that one can search including a side bar with some of the most important topics in NLP today. The engine is search as you type and typo tolerant (itâ€™s crazy fast). The index includes the arxiv research paper PDF, ConnectedPapers link, and its GitHub repo.\n\nhttps://index.quantumstat.com/ I love it. I appreciate people who build stuff to make other people's life easier. Cool! Yes! v cool, thank you! Dope Cool. Oh wow, that's fucking amazing. Where do you get the data from? Paperswithcode? Chill Very cool Thanks Thanks ðŸ‘ðŸ˜Š",
    "Convert low res picture to high res picture [Project] I (noob) have a huge data set of images that have two variants - 1st very high res image from a professional camera, 2nd very low res from a cheap camera. Both images are identical - difference is just the quality. Can I use this dataset to train a neural network to output high-res image of any low-res input image?\n\n&#x200B;\n\nIf possible, what is the best approach to do this? GANs, Deep Learning (again... total noob)? Try pix2pixHD but I think you'll have to make some architecture change. I had worked on this during my internship. Someone suggested the Gan based approach and although it is the seminal approach in Single Image Super Resolution (SISR), I would suggest trying the EDSR (resnet based approach) first. You can easily find the paper and the code for it. Try the ESRGAN implementation, pre-trained weights are readily available (you can find them on github or paperswithcode). I would argue you could use some unpaired image-to-image translation networks, such as CycleGAN, as you have two different domains: low-res with a cheap camera and high-res with an expensive one. Both the optics and resolution will be different, which is not exactly what is being said here of simple super-resolution which uses paired data (e.g., get an image, lower its resolution, have a NN predict the original image and train with that).   \n\n\nYou could try that, as I am using it currently to go from Low to Epic resolution using Unreal Engine, and the results are quite good. However, you will need to train and prepare the data, so perhaps try what others have suggested so that you have a baseline to compare with.   \n\n\nGood luck! [removed] Can you end up creating high res images from a low res image, what happens, add more pixel density, does it increase image size, wonâ€™t the image blur? Does anyone have an idea how to build such a dataset with audio recordings? Or how OP's dataset was constructed? look into wifu2x, thats what got me started considering that many of the top research and development labs have been working on this tech for years already, what do you imagine you'd be able to accomplish that they haven't? I would say it depends on what you're trying to do (classification, data generation (like with a GAN), etc.). But, in this post I a going to assume you are trying to use the data for classification using a deep neural network here are two potential approaches based on your situation:\n\n1) Your computer is bad:\n\nScale the higher ones down to the same resolution as the low res ones because this is less data to take in and thus less computational expense. But one caveat is that too low of a resolution will make learning/generalization hard for a neural network. Similar to a human with really bad eyesight having a hard time telling what an object is.\n\n2) Your computer is good:\n\nScale the low res ones to the higher resolution. This will cause your neural network to potentially learn/generalize better because there is more data to work with, but you will have more computational expense on your computer when training.",
    "Why indeed  ## Hello there! Unfortunately, your post has been removed.\n* **This post is a repost. Try to refrain from making posts that have been posted previously.**\n-------------\n^(If you feel something is wrong, please reply or [message us directly](https://www.reddit.com/message/compose?to=/r/youngpeopleyoutube).) Youâ€™re laughing. He was born in the generator and youâ€™re laughing. I was born in the right generator\n\nBtw I'm a Briggs and Stratton 6250 watt storm responder gas powered portable generator is that wiz khalifa real Wes khalifa we found the cobblestone boys Guess you can say he was born into a powerful home he got generated like a fucking minecraft chunk Because your dad fucked a generator Yeah kid's are stupid so I sold my one.",
    "[OC] Which States are the Most Beautiful. States by the number of posts in r/EarthPorn over 10,000 points.  Thank you for your [Original Content](https://www.reddit.com/r/dataisbeautiful/wiki/rules/rule3), /u/SodaDonut!  \n**Here is some important information about this post:**\n\n* [View the author's citations](https://www.reddit.com/r/dataisbeautiful/comments/my0isy/oc_which_states_are_the_most_beautiful_states_by/gvsabr6/)\n\n* [View other OC posts by this author](https://www.reddit.com/r/dataisbeautiful/search?q=author%3A\"SodaDonut\"+title%3AOC&sort=new&include_over_18=on&restrict_sr=on)\n\nRemember that all visualizations on r/DataIsBeautiful should be viewed with a healthy dose of skepticism. If you see a potential issue or oversight in the visualization, please post a constructive comment below. Post approval does not signify that this visualization has been verified or its sources checked.\n\n[Join the Discord Community](https://discord.gg/NRnrWE7)\n\nNot satisfied with this visual? Think you can do better? [Remix this visual](https://www.reddit.com/r/dataisbeautiful/wiki/rules/rule3#wiki_remixing) with the data in the author's citation.\n\n---\n\n^^[I'm&nbsp;open&nbsp;source](https://github.com/r-dataisbeautiful/dataisbeautiful-bot)&nbsp;|&nbsp;[How&nbsp;I&nbsp;work](https://www.reddit.com/r/dataisbeautiful/wiki/flair#wiki_oc_flair) [deleted] All Oregon beaches are public, there are few condos interfering with our photogenic, rugged coastlines Sad to see Massachusetts so low. Amazing shoreline in the east and mountains/forest in the west. Underrated. You don't even take pictures of your kids in Kentucky West Virginia is criminally underrepresented. I will need to submit some pics I was proud MN came thru with the same strength of ME! Fall colors on Lake Superior are gorg!! Iâ€™m shocked Ohio is higher than Pennsylvania. Iâ€™ve lived in both as well as Illinois and Pennsylvania is really beautiful Wish you showed Canada here. Alberta would be pitch black with the millions of posts of Moraine Lake. I moved from MD to OR and can say there's a drastic difference. Oregon is photogenic",
    "The marbling on this Prime ribeye filet  Whatever they ask, pay it That is glorious, how much was it per pound? Filet? One of my favorite colors. Filet? Looks like like a different cut Thatâ€™s awesome!  Not sure what the cost per pound was but I would guess $25.  Which I would gladly pay.  Hope it tastes as good as it looks. Jesus Murphy. That looks great. Looks so good, Iâ€™d be scared to cook it myself! Why is it missing its spinnalis? Looks awesome! Ä°t's just great",
    "Machine learning resources: a curated list of most popular ML, DL libraries, frameworks. Hello there,\n\nThe repository can be found here: [https://github.com/addy1997/Machine\\_Learning\\_Resources](https://github.com/addy1997/Machine_Learning_Resources) I was so disappointed when I saw ggplot2 mentioned and it was only referring to the R library... I was really hoping for a Python implementation that i had simply missed ðŸ™ˆ Amazing! Thanks! Sorry to hear that. I have added ggpy for python. What about plotnine?",
    "A more elevated spice mix someone posted \n\n1 Tbsp Coriander\n1 Tbsp Cumin\n1 Tbsp Paprika\n1 tsp Cardamom\n1 tsp Cinnamon\n1 tsp Cloves\n1 tsp Nutmeg\n1 tsp Pepper\n1 tsp Sumac\n1 tsp Turmeric\n1/2 tsp Allspice\n1/2 tsp Cayenne\n1/2 tsp Ginger\nGarlic powder and granulated onion \nOlive oil 1/4 Cup\nCrushed garlic 2-3\n1 Lemon juice \n2-4 hrs marinade \n\nAnd for the white sauce\n\n3/4 Cup Sour Cream strained\n3/4 Cup Mayonnaise\n1.5 Cup Greek Yogurt, strained\n2 Tbsp White Vinegar\n2 Tbsp Olive Oil\n1 Tsp Sesame oil\n1 Med Cucumber middle out salted\n2 clove Garlic\n4 fresh Mint Leaves\n4 sprig Dill\n6 cilantro sprigs tops\n1 tsp Salt\n1 lemon juiced \nBlend until smooth ",
    "'Designing Data-Intensive Applications' project ideas? For those that are familiar with DDIA by Martin Kleppmann, what intermediate-level projects would you recommend to solidify the most important ideas from the book? I have just finished reading chapter 4. I'm thinking of implementing a small database just the append writing and SSTable indexing in rust. I'm trying to learn rust as well so it will be a cool project to work on. Complete the labs from [MIT 6.824](http://nil.csail.mit.edu/6.824/2020/schedule.html). I am reading the book and all my notes are uploaded to GitHub, I did generate a content index using markdown, each time, if I need to remember a concept I will be able to browse over my project. You should at least play with cockroachdb and gundb. The only critique I have of this text is the lack of exercises. However, that's hardly a fair critique considering Kleppmann did not intend to write a traditional textbook. Love how comprehensive it is, though!\n\nAnyone else have any critiques or praises? Hmm would love to hear as well You may be interested to know that there are lecture notes with exercises from the author on distributed systems available online now: [https://www.cl.cam.ac.uk/teaching/2122/ConcDisSys/](https://www.cl.cam.ac.uk/teaching/2122/ConcDisSys/). They aren't labs/projects, but I think they're still worth trying to help solidify the material in your mind. Iâ€™m doing exactly the same thing in golang >  the append writing and SSTable indexing in rust.\n\nany resources to get started on this other than DDIA These look pretty good, thanks for the recommendation",
    "[D] AutoML MOOC In a collaboration of groups working on AutoML we developed a ***free*** ***MOOC*** on this topic. If you'd like to learn more about AutoML the MOOC is live at [https://learn.ki-campus.org/courses/automl-luh2021](https://learn.ki-campus.org/courses/automl-luh2021).\n\nIn 65 videos with overall \\~19h, we cover Hyperparameter Optimization (HPO), Neural Architecture Search (NAS), Bayesian Optimization (BO), Evolutionary Algorithms (EAs) and meta-learning for AutoML. The course includes quizzes and coding exercises (in python and R) to allow you to deepen your expertise.\n\nIf you're interested check out the trailer for the course [https://youtu.be/9wzS7tGwI9g](https://youtu.be/9wzS7tGwI9g)\n\nEdit: Tried to make more apparent that the course is free. Just taking a quick look through the material and it actually contains content that isn't \"beginner\" level like so many other MOOC. Looks great! Do you have any other recommended materials on your site for moderate/advances learners? Is it paid or free? I am not able to see price for this course. Whoa! This is awesome! this is useful. Thanks! I recently found out AutoML is super important and so much can be gained by just tuning hyperparameters. Thank you very much for creating this course! Thanks! Looks like 14h/week x8 weeks? Pretty intense This is great, thanks! Are there any other courses like this? \n\nGlad you like the material :)\n\nWe have a lot of stuff on AutoML on our website https://www.automl.org/. Of interest to you might be the free open access book \"AutoML: Methods, Systems, Challenges\" (https://www.automl.org/book/) or the list of tutorials (https://www.automl.org/talks/) where we put the slides and other materials for these. Thanks for your interest in our course. Other groups have indeed also a few MOOC videos online, but these are tailored to specific tools (such as Google AutoML or H2O). Our goal was to give a broad overview --- however, I have to admit that also we are a bit biased.\n\nIn addition to the links provided by u/Science_Squid you could also subscribe our youtube channel: [https://www.youtube.com/channel/UCFFqgQoJlPh55Dk56C1u7iQ](https://www.youtube.com/channel/UCFFqgQoJlPh55Dk56C1u7iQ)",
    "Awesome data engineering learning path  This is great, thanks for putting this together. I'd suggest adding some cloud and programming resources (Python, JVM based languages) to make this a bit more complete if you have the chance. I am someone who is finishing an MS in Statistics, and I need to build up some data engineering chops. What is the best way to go about *doing that*? As one dude all alone and no databases to cook with, I'm not sure how to build up that vital experience. Whoever did this should overthink how they define \"depth\" and \"coverage\".  \n\n\nHaving the python crash course at 100% coverage and 80% depth seems weird UPDATE:  \nI heard your feedback that the list might be overwhelming, so I added an \"essentiality\" measures to categories, to indicate what is a must and what is not.\n\ne.g: SQL is 3/3 in the measure. GDPR compliance issues are 1/3.\n\nHope it's even more helpful now (: Looking through here, I'm a Data Analyst and do about 75% of this including Data Governance and Security. Does this mean I'm more of an Engineer than an Analyst? Thank you . This looks pretty neat and organized. Great content, one thing that I could suggest is adding a Data Quality/QA section into the pipeline management. I'm a Data Quality Engineer and something that is very little documentation online is the need is the intersection of QA and Data Engineering.\n\nHere's a list of resources in this space that I've found helpful. \n\nQA/Data Quality\n\n[https://greatexpectations.io/](https://greatexpectations.io/) \\- Unit Testing Generation Library in Python\n\n[https://docs.pytest.org/en/stable/](https://docs.pytest.org/en/stable/) \\- PyTest can run in pipelines to kick off tests that unit/integration test your pipelines before pushing into the next environments.\n\n[https://github.com/microsoft/nutter](https://github.com/microsoft/nutter) \\- This is a pytest extension built by Microsoft for Databricks. Mainly to run tests in notebooks/pipelines.\n\n[https://github.com/awslabs/deequ](https://github.com/awslabs/deequ) \\- I haven't really used this but I've heard good things about it. Product from AWS for helping you generate unit tests for data similar to GE.\n\nAdding these are the keystones to enabling CI/CD in data platforms, which could be a separate section towards the end.\n\n[https://cloudarchitected.com/2019/04/devops-in-azure-with-databricks-and-data-factory/](https://cloudarchitected.com/2019/04/devops-in-azure-with-databricks-and-data-factory/)\n\nIf you wouldn't mind I could submit these as a PR, I'll be up for helping contribute and increase knowledge of QA and software engineering practices into this workflow. Which looks great, nice content and design on it! >Awesome data engineering learning path\n\nThank you for all awesome data engineering learning resources in one place. This is truly amazing tysm",
    "The deck we used to raise our Seed round for our open-source EL(T) platform  Thanks Jean for sharing this ! Really cool ! Thanks for sharing and being transparent! Always interesting to read about what goes on behind the scenes Awesome flow - v simple even for someone w/ not that much background in ELT Nice deck, flowed really well the entire way through, you sold me, have a upvote Great slide deck and congratulations on the funding round. Curious to hear what your most popular connectors are right now? Curious if you would take on some of the functionality of Airflow or similar tool ? I'm no expert on this area, but your story sounds good. Can I be en-lighted what problem this solves?\n\nFor example the [REST-API Request Connector](https://airbyte.io/source/dev-tools/rest-api/). \n\n>On each sync, this source makes a single http request to the provided URL. Whatever json body is returned is written to the destination.\n\nSo basically you replace 1 http request and 1 insert statement. What you I actually benefit here? Even in worst case this replaces maybe 10 lines of code.\n\nThe problem is always the T which requires the complex custom logic. I don't see here how replacing 10 lines of code with an entire new system/API benefits me? Great slide deck.  I've got to say that I love your philosophy.  \n\n1. I agree that the space is ripe for disruption.  Fivetran is a great product but the prices they charge are highway robbery.  \n\n2.  It looks like Airbyte does not support streaming.  I know that is not a trivial thing, but I see more and more workloads going that route.  Having a consolidated UI over Kafka connect would make my day. this is awesome (your company) Great deck and really well explained! I was curious when I saw yet another open source ETL but fully get why you are getting into the space!! Go build a super product and get rich!",
    "Kelly's criterion for gamblers: one of the most important concepts for understanding how investment size impacts returns I go to a casino and walk over to the first table I see. The sign above the table says, \"Kelly's Game\". The dealer says, \"Place a bet and The House will flip a coin. If you win the flip, The House will pay you 150% your money back. If you lose the bet, The House will keep 40% and return the remaining 60% to you.\"\n\n\"That sounds great,\" I say. *Positive expected value. If I bet a lot, I should expect to get 105% of my money back on average. That's a good bet.* \"What's the catch?\"\n\n\"Ah, yes. There *is* one more rule,\" says the dealer. \"You must bet all of the money you have each bet or not at all.\"\n\nHow many times should I bet?\n\nMy intuition tells me that the more times I bet, the better I should do. The law of large numbers should mean that over time, my overall winnings per bet converge on my expected value of 105%. In the long run, I feel like this is a rational bet. So, my strategy will be to make the bet 800 times and see where I am at.Â \n\nSince I'm betting all my money on each bet, I can only actually test my strategy once. Let's think of that as a single universe, my universe, where we see a single unique chain of events. But, before I actually go to the casino and bet it all, I want to guess what my universe will likely actually look like. To do that, we will simulate a multitude of universes, each completely independent of the others.Â \n\nHere's 1,000 simulations of my strategy where each colored line is my total bank, each simulating a single possible universe where I execute the strategy faithfully:\n\n[ 1000 simulations of 800 sequential bets of 100&#37; of the bank with 50&#37; to go 1.5x or 0.6x ](https://preview.redd.it/hm4rjm9ph0s61.png?width=820&format=png&auto=webp&s=e2dcc4d8c1cce3b68e8c7379987f0fbe34cb00f1)\n\nNotice the log Y scale. The dashed grey line with slope of 0 is breaking even. Negative slopes are losing money, and positive slopes are winning against The House.\n\nThe dotted black line is what I expected to gain, 105% per bet for 800 bets, netting me an expected 80,000,000,000,000 more than I started with. If I take the average of an infinite number of universes, my mean return *is* equal to the dotted black line.Â \n\n**But I only sampled 1,000 universes.** After 800 bets, only 1 universe in 1,000 has (just barely) more money than they started with. The more bets that I make, the worse it gets for me. The typical (median) return marked by the dashed white line is 1,000,000,000,000,000,000 *less* than what I started with (since you can never reach 0, you always get 60% back). I have a few tiny fractions of a penny left and a dying dream to recoup my money.\n\n**The typical universe is very, very different than the average of all possible universes.** I'm not from a mean universe. I'm from a typical, likely, universe. The median of a small number of samples more accurately reflects my reality than the mean of the infinite set. While the total money in all universes grows at 105% per bet, the money leaks from the typical universes to just a few extremely rare, lottery winner universes. There are some small number of universes in the set where I win an ungodly amount of money, but in almost every *other* one I lose big.\n\nWhy is this so? In short, there are many more ways to lose money than to win money. Let's look at all four of the possible universes of 2 sequential bets:\n\n[ There are more ways to lose than win ](https://preview.redd.it/lsxlexpqh0s61.png?width=581&format=png&auto=webp&s=ce2b45e69f6aa175042115a605fa83be2b066e14)\n\nThere are more ways to lose than win\n\nThere is 1 way to win and 3 ways to lose. The average winnings are still 105% per bet, compounded to 110.25% over two bets, but 75% of the time you lose money and 25% of the time you win big. The more times you bet, the worse it will typically get for you since you are more and more likely to be in one of the exponentially growing number of losing universes rather than the rare, exponentially rich ones.\n\nIn this game, the rational number of times to bet depends on how much you care about losing 40% or more of all of your money. Since I consider having a 50% chance to lose 40% of my money too unpalatable, the number of times it is rational for me to bet is zero, even though the bet is positive expected value.\n\n*Screw this game.* In the universes where I bet 800 times I've lost all my money. In one of those universes, I go back home and wait for my next paycheck.\n\nHow can I win the game?\n\nWhen my paycheck comes in, I go back to the casino and back to the same table with the same dealer. \"Your game is rigged,\" I say. \"I want to bet against The House with my paycheck again, except this time I won't bet everything I own every time. I want to bet less and see how it goes.\"Â \n\nThe dealer considers this, and says. \"Fine. But you must pick a percentage and you must make every bet with that percentage of all of your money.\"\n\n\"Great. I'll bet half my money each time.\" *That way if I lose in the beginning, I'll still have money to bet with.*\n\nLet the gods simulate another 1,000 universes, using our new strategy:\n\n[ 1000 simulations of 800 bets of 50&#37; of your bank with 50&#37; to go 1.5x or 0.6x ](https://preview.redd.it/bmpxe4vrh0s61.png?width=820&format=png&auto=webp&s=a04440eeb61c3370265eb06b5773be63a9bb9e3c)\n\nAfter 800 bets, half of our universes have made money, and half have lost money. Keep in mind that **nothing has changed except how much of my total bank I use to bet**. My typical universe is doing much better than before, but a far cry from the 80,000,000,000,000 return that my infinite selves are earning on average.\n\nAfter 800 bets, I'm right back to where I started. The dealer says, \"The House is feeling generous. You may now choose a new percentage to place on each bet. What will it be?\"\n\n*Reducing my bet size improved my situation. Perhaps even smaller bets will continue to make things better.*\n\n\"Twenty five percent,\" I declare as I lay down last week's paycheck on the table, again. The gods flip the coin 800 times in 1,000 universes yet again:\n\n[ 1000 simulations of 800 bets of 25&#37; of your bank with 50&#37; to go 1.5x or 0.6x ](https://preview.redd.it/nelmf21th0s61.png?width=820&format=png&auto=webp&s=56a84c6aec05d5a85dc58d732b05bc3628ca8096)\n\nNow my typical universe is making good money, most of them are up more than 10x, and some as much as 100,000x. Now, satisfied, I finally get up to leave the casino with my money in my pocket. *But, I have to know.* I look at the dealer and ask, \"So what's the optimal bet?\"\n\nKelly's Criterion\n\n*In probability theory and intertemporal portfolio choice, the* [*Kelly criterion*](https://en.wikipedia.org/wiki/Kelly_criterion) *(or Kelly strategy or Kelly bet), also known as the scientific gambling method, is a formula for bet sizing that leads almost surely to higher wealth compared to any other strategy in the long run (i.e. approaching the limit as the number of bets goes to infinity). The Kelly bet size is found by maximizing the expected value of the logarithm of wealth, which is equivalent to maximizing the expected geometric growth rate. The Kelly Criterion is to bet a predetermined fraction of assets, and it can seem counterintuitive.*\n\nTo calculate the optimal bet size use\n\n[ Kelly's criterion ](https://preview.redd.it/v73ctfjuh0s61.png?width=126&format=png&auto=webp&s=c097a3cf12753a0aa30c9216758ffc575fb02f71)\n\nKelly's criterion\n\nwhereÂ \n\n**{b}** is the the percent your investment increases by (from 1  to 1 + b)\n\n**{a}** is the percent that your investment decreases by (from 1 to 1-a)\n\n**{p}** is the probability of a win\n\n**{q=1-p}** is the probability of a loss\n\n**{f\\*}** is the fraction of the current bankroll to wager (i.e. how much to bet)\n\nUsing the calculator, you can see the **the optimal bet size is 25%** of your money on each bet:\n\nhttps://preview.redd.it/3ke002qvh0s61.png?width=820&format=png&auto=webp&s=c481a3b92d16d77c3490e581bbbe399b73dc9343\n\nLooking again at the above graph, that means that **the optimal betting strategy typically yields less than the expected value** for the strategy.\n\nKelly's Criterion Bet Size Calculator\n\n[Here's a spreadsheet](https://docs.google.com/spreadsheets/d/1gXIAsFgf86_RPiiG8qfoKScj9e4v5DZp4k1FgvbTQC4/edit?usp=sharing) toÂ play around with the above equation and calculate optimal bet sizes.  Make a copy and edit the cells highlighted in yellow to see what the optimal bet is. Read more in this [awesome Nature Physics paper](https://www.nature.com/articles/s41567-019-0732-0) and this [great article an AMMs](https://research.paradigm.xyz/uniswaps-alchemy). I love this shit. Monte Carlo simulations were my favourite programs to run in school, and are INVALUABLE. Thank you for putting in the work TLDR; He graphed the uppies and downies of 800 trials of the game where you either win 1.5 or lose 0.6. If you bet all your money each time, most of the time you will see downies. If you bet *some* of your money each time, you will have enough left over to stay in the game long enough to see some uppies. \n\nThere's an equation called Kelly's Criterion that can tell you how much to bet to see more uppies than downies, but you have to know the exact parameters of the game, so it could be hard to apply to something as complex as options trading in real life with non-discrete outcomes and variable probabilities. But the theory is betting a portion of your portfolio instead of YOLOing it all means you can stay solvent long enough to maybe come out on top. The thing about Kellyâ€™s criterion in practice is you never get a good estimate for your input:\n\nWhat is your expected payoff for stock/options position in a win-lose scenario? With option you might get a better picture of min/max payoff but thatâ€™s not your EXPECTED value\n\nWhat is your REAL probability for winning? Risk neutral probability (your delta) is not REAL\n\nWhen market is efficient (everything is 50/50ish) your Kelly criterion output very quickly approaches zero, which gives no guidance to your trade Wow.  So many angry comments on a basic premise: the expected value of one round is 105% of the wager.\n\nThat's a really, really easy stat to verify:\n\nthe expected value of round one is equal to the sum of \\[probability of outcome (i) x value of outcome (i)\\] across all (i)\n\nIn on other words, \\[50% X 1.50\\] + \\[50% x 0.60\\] = 0.75 + 0.30 = 1.05\n\nThere is, in fact, a positive expected value for this wager. Love to see this posted, but word of warning: Literally no one does full Kelly betting in the stock market. Not Edward Thorpe(the guy who many credit with popularizing it in stocks), not any quant hedge fund, not even Ren Tech(probably). Basically everyone is doing fractional Kelly betting, i.e where you size the position at a fraction of the optimal Kelly bet. You do this because since you cannot compute the exact parameters of the stock market, you may be overbetting with full Kelly. At 50% fractional Kelly you are already much safer.\n\nAs for people who disagree with using Kelly, there really isn't any mathematical model that is this applicable on a broad scale. The other popular choice is Markowitz, but that has absolutely insane correlation risk and moreover the notion of \"risk=variance\" doesn't sit well with most people. Anything else that's based on efficient market hypothesis or even worse assumptions like Gaussianity gets blown up during a crisis, and spectacularly so. Here, you don't need any of this stuff, you just need to estimate probabilities, get the payoffs correct and reduce to account for miscalculation. I _love_ this write up and have opened up a Pandoraâ€™s box of learning about this now. \n\nMy biggest take away for options are:\n \nDecreasing the total yolo of your port on each play generally is good in the long run rather than blowing it all up at once. \n\nWhile not exactly related, finding the optimal chance of winning is important. An option going to 3% seems to have a higher likelihood of success than once of 8, or 20 or more. The more you diamond hand to hold out tor the 20%+s, the less likely in the long run you will have more than you started with. At least thatâ€™s how Iâ€™m thinking about it. In my trade journal my average is 5%. Yet there are more times Iâ€™ve won on a lower percentage (say under 8) then Iâ€™ve won higher ones (like a 20% win). Does this mean I have higher likelihood of winning if I get out sooner?\n\nProbably. I read the whole thing, great writeup for a very interesting concept.\n\nMy problem is tending towards bets where the max loss totally blows out my anus.\n\nSetting the loss percentage in your sheet above 70% breaks the criterion Another \"I'm going to be studying this\" post. This sub is pure, bendable 24K gold. Thanks so much for putting in the time to teach us this. I stopped reading early, but appreciate your coloring skills I just bought more GME",
    "I just got offered a data science internship with Amazon. I've been lurking on the sub for 3 years and just wanted to thank the folks who put together stats/ml cheat sheets. This sub really motivated me to take my undergraduate degree in biomathematics/statistics and turn it into a masters in data science. I use to think I wouldn't have the programing background or that I wouldn't have the technical skills people wanted. It took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but I've gotten this far. Thank you all so much.\n\nEdit: Just came back to this post and saw all the support. For any one interested i have been applying since September to internships and have since then applied to 83 positions, reworked my resume twice, ended up making my own website for my projects just to look better on paper, and got 5 interviews at the end of March. I have gotten offers so far from every place I interviewed at and used the smaller offers to ask Amazon to give me a decision earlier, which ended up working. I only did 2 interviews with Amazon before I got my team and offer, which from reading online isn't common as they usually have a 3rd or 4th interview for interns. Its been a long process and a battle at every stage. Just 2 weeks ago I was resigned to the idea of a summer with no internship, but here we are now. Congrats on the offer. Amazon is a great first role, you'll learn a lot. I don't know if they still have the program for interns, but try to ask your manager to help you find a mentor. It makes a world of difference. Good luck :) Mind sharing some of the cheat sheets? congratulations! i recently switched to data science and thatâ€™s one of my goals. so happy for you Congratulations!!! And thank you for sharing this amazing news with us. Felt good and inspiring to see this as a new beginner. OMG! Congratulations! Very well done. I hope you know that you being offered this position is a testament to the work youâ€™ve done, whether you believe it was good work or not, Amazon did. So I hope you enjoy this experience! \n\nAlso yay for women in STEM! â¤ï¸â¤ï¸â¤ï¸ Congrats! Congrats! I wish i could land a job, i'm not sure since i'm civil engineer. :( Congrats, g!!! Love to see people succeed! ðŸ™ŒðŸ¾ðŸ™ŒðŸ¾ðŸ™ŒðŸ¾ Congrats! congrats!  You will never regret being a data scientist",
    "â€žOur blockchain based AI platform makes it possible to save you time & material by using the cloud for your enterprise process. By applying machine learning to your augmented reality workflow you are able to cut onpremise costs by more than half. The intelligent cryptographic algorithm makes sure all your teammates collaborate trough our quantum computing pipeline. The military grade encrypted vertical integration into the tokenized world leverages extended reality to hold down the distributed cloud latency for your success. With our 5G investment we make sure to have enough monitoring-as-a-service resource pools ready for you. The Git-Dev-Sec-Ops model ensures maximum troughput and ROI on your serverless lambda cyber edge computing clusters. Our business intelligence uses hyperautomation to deploy chatbots into the kubernetes mesh to support your customers with great UX. Opt in now for more information on our agile training range and lock in future profits on our NFTâ€˜s. Donâ€™t miss out: 3 billion IoT devices run our solution already.â€œ\n\nIâ€˜d buy it instantly if I were some FOMO-manager. ",
    "Would there be any interest in a post where we discuss (initially) unintuitive concepts in math? Hey everyone, Iâ€™m thinking of writing a post that discusses mathematical concepts and objects that many people find unintuitive at first. By far the biggest struggle Iâ€™ve faced while learning math is the question of why these definitions are the right ones to make. In the same vein, why we would expect a theorem to even be true. And especially with certain concepts, at least among the few math people I know, I find Iâ€™m at least not the only one. \n\nSo I thought a post like this would help others who struggle with the same problem. I would start by writing a moderately detailed exposition on how I currently understand these concepts, and then we could have a back and forth discussion in the comments. The focus of the main post and discussion should hopefully be about not just the properties/behaviour of the objects, but why the objects are the right ones to talk about in the first place. \n\nOf course I make no claims as to the originality of the stuff I might write - most, if not all of them have been gathered from scattered sources around the web and chewing on them for a bit. And I canâ€™t guarantee that what I share will be a good way, or even a correct way to view things.\n\nBut they may spark some good discussion nonetheless, and it would benefit me greatly as well to have people to banter with, hopefully reinforcing good intuitions and snuffing out bad ones.\n\nSo some of the things I had in mind, just off the top of my head are:\n\n- Determinants, and their connection to wedge products\n\n- Conditional expectation (of a random variable with respect to another RV/a sub sigma algebra)\n\n- The exterior derivative\n\n- Ultrafilters, and their interpretation as convolutions of â€œmeasuresâ€\n\n- Weakly differentiable functions, i.e. Sobolev and bounded variation functions\n\n- Connections and covariant derivatives\n\nSo if any of this sounds appealing to anyone, let me know! If thereâ€™s enough interest Iâ€™ll be glad to open the discussion. Suggestions for other good concepts to discuss would be very welcome too.\n\nEdit: The necessary and sufficient conditions have been met. I will begin writing most soonishly. Generating functions ... why not just write the post and see what happens lol Take a circle of diameter 2n where n is natural, and center it on (n,n) such that it touches the positive axes\n\nLet a_i be the factors of 2n. Then we can construct a Pythagorean triple right triangle that perfectly circumscribes the circle by taking the point (0, 2n+a_i) for each a_i and drawing a line segment tangent to the circle\n\nEx. Take a circle of diameter 6 centered at (3,3). The factors of 6 other than itself are {1,2,3}. Adding each of these to 6, we get the set {7,8,9}\n\nThe Pythagorean triples (7,24,25), (8,15,17), and (9,12,15) all perfectly circumscribe said circle\n\nEvery single Pythagorean triple can be found this way until you get to (36,77,85) Ito integral I have no comment on your specific definitions, but I wrote a [previous post](https://www.reddit.com/r/math/comments/8alqwc/how_do_mathematicians_determine_what_is_worth/dwzmf7q/) on how mathematicians determine which definitions are the right ones to make.\n\nI also teach students, in my intro to proofs class, how to make definitions, by *not telling students what the correct definitions should be, and forcing students to come up with definitions on their own*. I strongly believe that you can never learn where definitions come from unless you yourself have direct, firsthand experience in creating them. gimme Compactness! I think it would be great to have more resources that motivated the definitions we memorize with the concepts that make them useful.  Determinants as (hyper)volumes.  Wedge products of vectors as 2D things that have meaningful units of area, with a footnote about how the cross product lets you mostly pretend grade 1 and grade 2 elements are equivalent in the special case of 3D space.  I'd also love to see more on how elliptic trig and hyperbolic trig are fundamentally different cross sections of the exponential function with a given choice of metric for how basis elements square, with dual numbers completing the spectrum for how all the conic sections and quadratic forms are really just varying flavors of circles. Hereâ€™s something I thought was initially unintuitive that Iâ€™ve never heard anyone else say was unintuitive:\n\nLinearity of expectation Iâ€™d like it",
    "ShrÃ¼mi/Combo - 50mg Thc + 1/2 gram magic mushroom, topped with Nerds and sugar coated; a delectable gourmet treat  I really wish using thc while Iâ€™m tripping didnâ€™t send me into a world of anxiety lol 5 of those would be a nice day ðŸ‘ Dude that looks like perfection I would love a tip on how to keep the nerds from sweating, I've tried everything I can think of and the nerds always. break down and leave a gooey mess. The only way I have found that works is melting down actual gummy bears (instead of making a homemade version). Ooo itâ€™s adorable Those are beautiful.. I want Feel good in a candy mane Is that like a gummy? Or what is the base? Yum yum ðŸ˜‹ ðŸ’¸ðŸ’¸ðŸ“¬ Late comment but OP can we get a recipe / tek on this?",
    "How to: Grow Bulk without a PC or brf cakes. (Broke Boi Bulk Tek) Do you find yourself thinking, \"Hmmm, brf cakes suck. They take forever to colonize. But I'm a broke boi and won't spend money on a pressure cooker.\"?\n\nThen you are in the right place. Colonizing bulk grains is possible without a pressure cooker, agar, LC, or any of that stuff you are too cheap to go buy or learn how to use. You can pull those thicc canopies with nothing more than spores and brown rice. Sure, you see people knocking up pre-sterilized grain bags with spore syringes all the time. But that is a total crap shoot. Spores are only acceptable for two things: brown rice and agar. Brown rice due to its inherently low endospore count.\n\nToday, we'll be using brown rice. Because it's cheap, easy as fuck to prepare, and you can shoot spores straight on it with consistent results. Plus you can grab a bag at the grocery store and nobody is asking why you are carrying a 50lb bag of oats home to your fucking apartment. After using this spawn method, you'll never mix up brf jars again. Also, I will describe using unmodified jar lids in this write up because I know if you're trying this method, you're lazy and you don't want to bother with making jar lids. If you do have proper lids with a SHIP and gas exchange filter, well, you probably don't even need this write up.\n\nDon't like reading? Check out [this video](https://www.youtube.com/watch?v=UgCW-ZPkxIU) by u/PhillyGoldenTeacher to get started.\n\n#**Materials needed:** (Total:~$50)\n\n* Any size of jar ($8 or free if you grab them from the recycling)\n\n* Large pot ($15)\n\n* Whole brown rice ($0.86-2.00) (2lbs of rice ~equals 2 qts)\n\n* aluminum foil ($1)\n\n* Spore syringe ($15)\n\n* [SAB](https://www.shroomery.org/forums/showflat.php/Number/23990888#23990888) (still air box) ($4)\n\n* Flame\n\n**Optional Upgrade**\n\nPop a hole in the center of your jar lids and cover it with micropore tape. Then you can remove the foil after inoculating and keep the jar lid tight.\n\n#**Prep the rice**\n\nJust cook the damn rice. At my elevation, we normally cook rice on med-low heat for 15min. Since you will be putting this rice in the steam bath later, you only need about a 10-12 minute cook time. If you are using instant or \"10min\" rice, reduce the cook time. We don't want to cook the rice, just hydrate it.\n\nWhen the water begins to boil add the rice and turn the heat down to med-low. Wait 10-12 min. Remove the pot from the heat.\n\nIf you use a rice cooker or cook it fully, the rice will puff up and stick together. If that happens, you can't shake them up and you might as well have stayed with brf cakes. If your rice does cook fully or \"burst\", start over. Rice is cheap and having grains that are easy to shake will save you a ton of time down the road. It should not look edible when you finish.\n\n#Do not overcook the rice.\n\nPut your rice in a colander and rinse it thoroughly. This cools it down so it is easier to work with and also rinses off the starchy residue that was covering the rice. It will help to prevent clumping later. [This is how it should look.](https://i.imgur.com/nLK8gya.jpg)\n\n#**Prep the jars**\n\nPut your rice in a bowl. If you're like me and bought a unnecessarily giant bag of vermiculite when you made your first brf cakes, go ahead and toss in a few handfuls of verm. It will help prevent the inevitable rice clumping you'll see later.\n\nThen load the jars with the mix. Like with grain jars, you want to leave a little room at the top of the jar. Three quarters full is a good guideline. This allows you to shake the rice later on when the mycelium has started colonizing. If you don't leave space, you won't get a good shake and distribute the myc evenly and you might as well have stuck with brf cakes because it will take forever to colonize. \n\nPut the lids on the jars with the disc upside down. Cover with foil like usual. Be sure that the foil covers the entire lid. The foil should be outside of the lid. Loosen half a turn or so.\n\n#**Sterilize**\n\nThis is the beauty of using whole rice. You get all the benefits of brf and grains. \n\nJust like in the PF tek, throw something at the bottom of the pot to raise the jars up. Fill it up with a couple inches of water. Set your jars in, put on the lid, and crank up the heat. Once the water is boiling and the pot is filled with steam, feel free to lower the heat a bit (usually down to med-low) so you do not run out of water and **set a timer for 90 minutes.**\n\n#**Inoculate**\n\nYour 90 minutes is up. The jars have cooled. You have a SAB you made out with a coat hanger and an old tub you found in your garage. Jars and syringe are in the SAB. You have bathed in hand sanitizer. Hell, maybe you even put on a dust mask. Everything is set. \n\n*Pull the foil off a jar.\n\n*Loosen the ring.\n\n*Sterilize your spore syringe needle with a flame\n\n*Crack the jar lid\n\n*Shoot 1mL of spore solution in the jar\n\n*Lid back on tight\n\n*Foil back on. Keep it loose.\n\n*Loosen the lid and foil combo half a turn to allow for gas exchange. Do not remove the foil despite what well-intentioned people might tell you. As long as it isn't taped down, you will have more than enough GE. \n\nWhen shooting the spores, please shoot them all into one spot and do not shake up the rice. You need the spores to find each other and make a happy mycelia family. Spraying them all over the place or shaking up the jars after inoc will only slow down the process.\n\nNow set the jars somewhere and don't fuck with them for a week or two. When you see the myc get to about +25% colonization, tighten the lid and shake the shit out of the jar. Mycelium is hardy stuff. It'll be fine. Shake it until you're confident that the culture has spread evenly throughout the jar. Don't forget to loosen the lid slightly after shaking. It should recover well within 48 hours. Within a week, post shake, you'll be ready to spawn to bulk. Use this spawn for whatever your favorite bulk tek is. Of course mine is [the unmodified.](https://www.shroomery.org/forums/showflat.php/Number/22337800)\n\nGood luck! Mush love and all that. If you have any criticism, please comment and let me know where this can be improved. But remember, this is a broke boi tek, so all suggestions must be as lazy and cheap as possible.\n\n\n11/28/18 Update: Now that this post is archived I just wanted to let any future readers know that you can feel free to shoot me a PM anytime if you have any questions regarding this tek or any other cultivation issues. Don't hit me up on Chat. The app I use doesn't support it.\n\n5/2/19 Update: Hot damn! Has it already been a year? Many people have asked about where to go next with this spawn. Of course I recommend the unmodified mono above but reading it now I believe Bod has changed the write up slightly so I'll paraphrase the next steps here so this will be a more complete tek and not just a /r/restofthefuckingowl tek. I'm sure it will be a little rough at first and I'll improve it over time as I have here.\n\n#**Spawning to Bulk**\n\nSupplies:\n\n*Coco coir\n\n*A tub for fruiting (I recommend a 32qt Sterilite as shown in the Unmodified Mono)\n\n*Container for [Bucket Tek](https://www.shroomery.org/forums/showflat.php/Number/24077162#24077162) (this can be any large container with a lid)\n\nWhen your brown rice spawn jars are fully colonized, then prep your coir. I suggest reading the Bucket Tek linked above. To paraphrase, throw in about 5 quarts of water for each brick (650g) of coir. Bod uses a large 5 gallon cooler but any container large enough for both the water and coir will work. It helps if the container is insulated but I have successfully used a regular bucket from a home improvement store. Boil the water and add it to the coir in this container. Wait overnight or until it is cool enough to handle.\n\nMix the colonized spawn and coir together in your fruiting chamber. It will colonize fastest if you evenly spread and mix the spawn throughout the coir. You can successfully use anywhere from 1:1 to 1:8 ratio of spawn to sub. I like to stay around 1:2 but I don't measure it out exactly. Shoot for a minimum of 3 inches of substrate depth in your fruiting chamber. Any less and it will dry out too quickly and require more maintenance. The spam filter always takes down posts with this link but you should google \"Weebly substrate calculator\" if you want exact calculations. \n\nNow you have a decision to make. Colonize or Fruit. When working with cubensis it doesn't seem to matter. I see no difference in the timeline whether I go into fruiting conditions immediately or wait for 50-80% colonization. If you wait until 100% colonization or until you see pins to fruit, then you are likely delaying your timeline. So you can leave the lid on or flip it to provide FAE immediately, it doesn't seem to matter.\n\nFor those not familiar with the Unmodified Mono linked above, the basic idea here is to skip drilling holes. Flipping the lid upside down will provide enough FAE (fresh air exchange) for healthy fruiting. In some cases cultivators need a bit more FAE because they choose to grow in a closet or some other restrictive area. If necessary you can also wedge the lid up slightly. With the Sterilite tubs this can be achieved easily by raising the latches and resting the lid on them.\n\nAfter flipping the lid the cultivator will need to [monitor surface conditions](https://www.shroomery.org/forums/showflat.php/Number/23999053) until harvest. If excessive aerial mycelium begins to grow, increase FAE. If the surface begins to dry, decrease FAE or mist the surface from a distance as needed. Fanning is never necessary. Use a flashlight to monitor your surface moisture.\n\n#**Harvest**\n\nOne of the best features of an unmodified mono is the ability to float the substrate and make harvesting easy. The details can be found in Bod's [Float Tek.](https://www.shroomery.org/forums/showflat.php/Number/24198162) Basically you fill the tub with water and the substrate will float up over the top of the tub. This means you don't have to bend over and reach in to the tub and tear shit up which is always a pain in the ass. \n\nThe Float Tek will also give you a jumpstart on rehydrating the substrate for a second flush. Leave the substrate in the water for 1 hour per inch of substrate depth. Don't let it soak with the fruits on it for an extended period of time. Psilocybin is water soluble.\n\nCut or twist and pull?\n\nI do both. I like to grab the fruit I want to harvest and twist and pull until I meet resistance. Then I slip the blade in and slice the small amount of myc holding it down. This allows you to harvest the most amount of mushroom material possible while keeping the substrate intact. This cutting happens at the substrate level. It is superior to the twist and pull method because with a majority coir substrate, pulling will damage the myc. Each time you damage the myc you are increasing your risk of contamination. \n\nWhen to harvest?\n\nThe rule of thumb is to harvest before spores drop. There are some theories about psilocybin production stopping when the cap opens, the veil tears, or when the spores start to drop. There is no data to support this. I think it's bullshit. But I do like to harvest before everything gets covered with spores. If only a single veil has dropped, I don't bother. I find it's best to wait until the majority of the fruits are ready and harvest everything at once. That way you get the most weight per flush without making a mess. And harvesting everything at once is best so you can start drying everything immediately.\n\n#**Drying**\n\n[Have a plan to dry BEFORE you get to the harvesting stage.](https://www.reddit.com/r/shrooms/comments/da5pv6/drying_fruits_and_why_youre_a_dummy_if_you_dont) There is nothing worse than waiting and working for months just to have your harvest rot.\n\nHow to dry. Best to worst:\n\n1. Food dehydrator (crank it up and let it go until cracker dry)\n\n2. Poor man's food dehydrator. Toaster oven with the door open and a fan blowing in.\n\n3. On a fan until mostly dry and finished in a desiccant chamber.\n\nIf you do anything else, you're sacrificing unnecessary amounts of potency.\n\n#**Storage**\n\nCracker dry mushrooms should be stored in a sealed container with a large amount of desiccant in darkness. Thanks for writing out this Tek. I've been working with whole brown rice and LCs lately. If going from spores what size jars do you recommend? This is awesome. Was just looking into simple BR teks. Great writeup, excited to test out. do you moisten the vermiculite or just throw it in as it is? approximate percentage of the whole mass?  Bookmarking. Going to give this a shot. Thanks! Is the goal to cook the rice to the point that you'd typically eat it at? Or should it be slightly undercooked by the end of the steam bath or even slightly over cooked? Looking to do my first attempt soon. Am I right in thinking this can be used for monotub? Just about confused as all teks say pc is a must?  My penis envies are colonizing very nicely with this slightly cooked rice substrate. I have one jar that's around 85% fully colonized already (It's been 11 days since inoculating) and the other two are about half way to full colonization. [deleted] I am new and still learning, sorry if this is extremely dumb/obvious.\n\nGoing to use this method instead of buying premade/sterilized corn bags (can't do any gluten grains, I have celiac). \n\nHow much brown rice and what size jar would equate to a 1 lb bag of grain? I am supposed to use 1 quart/pound (are they the same??) for each of my mini tubs. Do I weigh/measure the brown rice before or after cooking? \n\nThanks for any advice!\nTL;DR:\nHow much dry brown rice would I use to equal 6 quart jars of grain spawn? How big should the hole on the lid be? Also, should I put the micropore tape beneath the foil and before the steam bath or do a layer or two of foil and the micropore tape after inoculation? Definitely trying this next! ",
    "Top 10 youtube channels to learn machine learning **1.** [**sentdex**](https://www.youtube.com/user/sentdex)\n\n**2.** [**codebasics**](https://www.youtube.com/channel/UCh9nVJoWXmFb7sLApWGcLPQ)\n\n**3.** [**DeepLearningAI**](https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w)\n\n**4.** [**deeplizard**](https://www.youtube.com/channel/UC4UJ26WkceqONNF5S26OiVw)\n\n**5.** [**Krish Naik**](https://www.youtube.com/user/krishnaik06)\n\n**6.** [**Kilian Weinberger**](https://www.youtube.com/channel/UC7p_I0qxYZP94vhesuLAWNA)\n\n**7.** [**Machine Learning**](https://www.youtube.com/channel/UCP1WIR3Q01S7wo0vxhTp7rg)\n\n**8.** [**Daniel Bourke**](https://www.youtube.com/channel/UCr8O8l5cCX85Oem1d18EezQ)\n\n**9.** [**Hsuan-Tien Lin**](https://www.youtube.com/user/hsuantien)\n\n**10.** [**Python Engineer**](https://www.youtube.com/channel/UCbXgNpp0jedKWcQiULLbDTA) There's a guy called Aladeen Persson(YT channel) who does really good pytorch implementation of papers. You forgot statquest https://youtube.com/c/joshstarmer Abhishek Thakur [https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) Are any of these guys doing their work in R or is it all python. Do I need to give up on R for python. Lmao Number 8 reporting in! \n\nThank you for the mention :)\n\nPlenty more videos to come. Also Standfordonline. Anyone ever go through [https://e2eml.school/blog.html](https://e2eml.school/blog.html) ? Canâ€™t forget Yannic Kilcher! Thanks for this list and thread, i have made some new subs ;)   \n\n\nTwo persons missing from the list imo\n\nJeff Heaton : [https://www.youtube.com/c/HeatonResearch](https://www.youtube.com/c/HeatonResearch)\n\nand ML with Phil: [https://www.youtube.com/c/MachineLearningwithPhil](https://www.youtube.com/c/MachineLearningwithPhil)",
    "Conspiracy Theorist claiming to be rightful King of England reads way too deep into Megamind joke  I'm currently spiraling down this rabbit hole. Thanks a lot. Obviously, the Guns n Roses song accompanying Megamind's entrance means that the uploader is descended from the two houses of Roses, with royal blood from both the House of Lancaster and the House of York, and Megamind is further justifying the uploader's right to rule the United Kingdom and her territories. The most recent vid on his channel has a lot more like this, but it's more recent than 5 months, so. He also claims to be able to use predictive programming to tell the future? I really don't understand what he means Its a shame that when comments are disabled. Schizophrenia is no joke. How can _he_ be the rightful king of England when _I'm_ the rightful king of England? It makes no sense? Wow this just reminded me of a guy I had to deal with when I worked retail years ago. He would come in and stay for hours and talk all about how he was royalty, and the queen wasn't the rightful queen. He spent loads of money though, so the manager just had us deal with it. \n\nThen he tried to return EVERYTHING he bought over the course of a year. I'm talking about multiple loads of garbage bags full of never worn clothing. Started getting aggressive when we wouldn't take the stuff outside of return limits and eventually got banned from the store. \n\nMy heart always sank when I saw him coming. Is that jimmies voice actor? why is this character saying \"there is no queen of england\" anyway? I watched 'The Hidden King' and 2 minutes in he says \"the jews have this prophecy where they must destroy europe before the messiah comes\". He then proceeds to claim he is the messiah and rightful ruler of israel a minute later. What a nutter.",
    "Mabel the avalanche dog doing training  Check out our wiki guide:\n\n[**How to find quality content for this sub**](https://www.reddit.com/r/dogswithjobs/wiki/index#wiki_how_to_find_quality_content_for_this_sub)\n\nFor more information and discussion about search & rescue operations check out **/r/SearchAndRescue**\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dogswithjobs) if you have any questions or concerns.* Are they training at the fortress from Inception? Great video. I love how excited these dogs are when they're working Question that just came to mind - is avalanche snow pretty hard pack or do you post hole through it? Maybe it depends?\n\nEdit: of course there's snow shoes, I'm just curious of the snows consistency Snowbird ski patrol has the cutest dogs change my mind Sounds like she discovered some weird Mickey Mouse / IT hybrid monster. Where is this? I think I might have met Mabel as a puppy but I'm not sure. I met a black and white avalanche dog named Mabel that was a puppy but she might have been a lab, unsure. First the forest rescue dog, now the snow rescue dog, where is the water rescue dog? Jokes aside, that's a really good boy! The first person she â€œsavesâ€ that doesnâ€™t have a toy better be ready to be covered back up. Other dogs: you guys are getting paid to dig holes!?",
    "The entire class was like this  the dude on the right got some long stems *It's Showtime* Ah that's hot, that's real hot I was always the one who would look the other way.\n\nBut today i will flex the whole way if some one ask. no one can get that sexy, sorry [i love lego star wars 3](https://www.reddit.com/r/legostarwars/comments/l8wqkl/the_only_cheat_code_i_used_was_the_one_for_savage/?utm_source=share&utm_medium=ios_app&utm_name=iossmf) [The teacher](https://img1.starwars-holonet.com/holonet/dictionnaire/photos/org_esp_vuvrien.jpg) u/repostsleuthbot Trooper 3447 does *not* skip leg day. Check out the Top post: All The Time from r/starwarsnsfw",
    "[P][OC] 3 years ago, we made the music video Jean-Pierre using neural style transfert, optical flow, and Deep dream. Today we release \"Inbreed For Thalassa\", with auto-morphing, using Generative Adversarial Network, deep-dreaming and glitchs.  Ok, enough internet for today. sir your neural network is probably high on drugs Well that was horrifying Honestly great work. can you make something little more uhm.. happier next time? Deliciously uncomfortable. That was awesome r/microdosing gone wrong Is there any paper or git repo for this ? Holy mother of mayhem I love it. If I ever got into game development it'd be to make a horror adventure game based on neural nightmares like this. Just watching this video makes me nauesous, it's wonderful.",
    "[D] What is the reference style in Schmidhuber's blog post and why aren't we using them everywhere? Admittedly not directly related to ML but more about academia in general, so please delete if it's not meant to be here.\n\nI've been wondering about this for a while since I quite like the reference style in [Schmidhuber's post](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html), for example:\n\n* Artificial Curiosity [\\[AC90\\]](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#AC90)[\\[AC90b\\]](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#AC90b)\n* Predictability Minimization[\\[PM0-2\\]](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#PM0)[\\[AC20\\]](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#AC20)\n\nI  think the basic idea is you curated the short-hand reference in your paper, this make discussing the related works through out the entire  paper super clear and easy to follow, even if you're reading on a more  flexible format such as html, let alone pdf. The nearest thing I see to  this style is people explicitly naming their paper with an acronym, so  that will be referenced later like this for example: \"In BERT \\[12\\],  ...\".\n\nAside from the cryptic \"\\[12\\]\"  style reference, the \"*LastName et. al*.\" style is very verbose and in  modern context, isn't helpful at all. This is especially true for papers  coming from authors of South/East Asia origin.\n\n&#x200B;\n\nhttps://preview.redd.it/tz5raf5zwrn61.jpg?width=556&format=pjpg&auto=webp&s=9d11ccbda91a06efc3ce78dd5b0d4450479eb248\n\nSo I want to ask if you know what this style is formally known as, and is there  any reason why we don't adopt it more broadly? Also, what is your  favorite reference style? Your four-character hashes^([c5497acdbb9ca9b3d84fdc4d87d947c399988e5974aec655407c268fb96fa5e9e1eb9f7667daae2c32754b67e38b0d177beba9ccafd70a7ef52eda5165b17c4c]) are not secure. Full SHA-512 citations or bust! The main advantage of referencing with numbers is that it is very easy to find back the ref in the bibliography. It also has the advantage to take very few space for multi-ref (e.g. [12, 14-16]).\n\nHowever I do agree that citing with only [12] is confusing. So, I only use it when I want to make a reference without too mich explanation (for example to provide additional material on a subject). However, I don't think [AB90] style is less confusing. If you have a lot of citations it becomes nearly as hard to remember them, and if they have a similar titles it becomes funky.\n\nFor a citation, I usually use \"Name et al. [12]\". It is very verbose, but at least I am sure everything is there. If i have to cite the same paper a lot of times, I introduce an abbreviation early on.\n\nEdit: typo Why not read electronically and hyperlink your references? Hover your mouse over and get the full title, year, and authors in the tooltip window that pops up. A lot of journals do this already.\n\nThis just seems like too much work and an anachronism from an era of paper. Ahh, finally something which I was thinking for a while that those \"\\[12\\]\" or \"LastName et. al.\" are pretty useless when speed reading.\n\nThe Schimdhubar-style refs are pretty good in general. Some problems include the fact that not all paper titles/contents have an easy abbreviation. Also multiple abbreviations may collide. The only reasons why Schmidhuber uses this style to distinguish between:\n\nSchmidhuber et al. 1992, Schmidhuber 1992, Schmidhuber 1992, and Schmidhuber 1992 Oh, I thought AC was the author's initials at first. I didn't realize they were organized by subject. I definitely like that.\n\nBut I don't like that in that post, half of them are by subject and half are by author after all. IMO do them all by subject or all by author - and if they're by author you might as well just use the numerical version. > [R2] Reddit/ML, 2019. J. Schmidhuber really had GANs in 1990.\n\nWe did it, Reddit. \n\nI am now also curious about which article is referenced in [R1]. I don't know, but I agree we should follow suit. For the life of me I cannot understand why not ALL digital papers and books have actual working links between the citation and the bibliography reference and vice-versa. Yes, the back button exists but it is less convenient. Less than 5% of the publications I've read have that nifty feature. I like the name version. It helps me recognize what work they are talking about. I'll admit when I was new or when I'm reading a subject I'm less familiar with then it doesn't help, but if it's in my area then I know exactly what paper they are referencing.",
    "How to Deal with Difficult People on Software Projects  >  that morale can be quickly repaired by asking them to do a presentation on the new technology.\n\nRealising that this would pretty much work on me and shut me up... This is brilliantly executed (the aesthetics are beautiful). However, it doesn't seem too insightful :/ More of a game of spot yourself if anything The scope creeper hahahah what PM isn't this. Actually my boss too... king of scope creep Hard idealist here.\n\nThe project will be done when I'm personally satisfied! THIS IS ALL ABOUT ME PEOPLE. > The Extreme Underestimator, The Idealist, The Technology Enamored\n\nI feel so attacked right now... OMG I'm dealing with the 'Meeting Scheduler' right now. We currently have seven scheduled status meetings a workweek. Yes, there are two workdays with two status calls. Huh...well, there's something new to feed my impostor syndrome So thats basically zodiac signs for people working in the technology industry ? Dang yâ€™all got QA?",
    "Venn diagram from binary variables? \\[Solved\\]  \nHi  \nI have a df of three binary dummy variables, for each observation 1/0 shows whether I have sensor data on heart rate, breathing, and/or activity (e.g. table below).  I'd like to create a Venn diagram showing how the number and proportion of combinations of observations. I've explored *ggvenn* and *venn.diagram*, but realise my data isn't in a suitable format for these commands.Any pointers please?  \nThx, Joe\n\n&#x200B;\n\n|Heart|Breathing|Activity|\n|:-|:-|:-|\n|1|0|0|\n|0|1|1|\n|1|0|1|\n\n&#x200B; Your data are not suitable for `ggvenn`? Looking at the example on [this github page](https://github.com/yanlinlin82/ggvenn) it seems that they are. If 0's and 1's don't work, then switch them to TRUEs and FALSEs using, e.g. `dataframe$Heart <- dataframe$Heart==1` Thanks v. much u/Statman12  I had failed to put my variable names in speech marks before.  This worked like a charm.  Much appreciated. Great to hear it worked! And I'm happy for the pointer about `ggvenn`. Would have been nice during my time as a professor!",
    "6 Month Study Guide For ML Interviews I saw this study guide that looks good if you have a machine learning interview coming up. \n\n[https://towardsdatascience.com/how-to-get-a-machine-learning-job-in-6-months-5aaa61b13af2](https://towardsdatascience.com/how-to-get-a-machine-learning-job-in-6-months-5aaa61b13af2) Holy heck. I'm just a lurker here, but is this really what people go through to get a ML job? I'm a Machine Learning Engineer and I write similar clickbaity articles so I don't blame the OP, but I feel the need to make two points;\n\n1) This is for interviewing and not so much on how to do your job. I would say this is still fairly limited; a ML Engineer needs to know a little bit on a broad range of topics. \n\n2) Machine Learning Engineering is a practical job. You need to know how to do a lot of stuff and knowing how to do said stuff won't come from doing tutorials. You really need a background as a programmer or a data scientist and work experience. Most other ML Engineers I know were already at medior level before they started calling themselves ML Engineers.\n\nPersonally I shy away from any company that is known for leetcoding but thats just me being stubborn. Thatâ€™s nuts but am not surprised. The interviews are intense. Wow that was a really nice summary.\nWhat are you all's thoughts on reading a book for computer science knowledge tho? I've always been conflicted about whether it's more efficient to just read a comprehensive book or look up courses or guides online and do more hands on coding. Obviously doing both is ideal, but if we had to make a choice, do people recommend read books like the article mentions? I would definitely add elements of statistical learning or Chris bishop book on theory \nNot surprising at all you need good coding swe skills to implement, experiment and deploy models.\nYou need good theory understanding to know how to improve or why itâ€™s failing\nAnd how to design your system, data pipeline, a good model that doesnâ€™t deliver value is worthless Only had a brief look for the moment but if you want in on Silicon valley and the big bucks it's extremely competitive. These companies are paying for the best of the best, they have the power to pick and choose as they are the limited demand for what looks like an oversupply. \n\nWhat is not in oversupply is what they are paying for, the 1% of ML experts that understand modelling, architecture, software development and have good interpersonal skills. I'd bet in most cases people only 2 or 3 of these, let alone being an expert in all 4 Looking at this - Thereâ€™s everything under the sun in ML interviews here. This is for getting ANY ml job, but in reality, you only need to know a portion of this, abs thatâ€™ll be the job interview you donâ€™t fail. [removed] i self-study ML and DS and would like to work in MLE, so what you say that i should first work as a data engineer/analyst/scientist before getting into the MLE? I'm coming over to DS/ML from e-learning, and books are just one kind of tool you can use to teach. Like every other methods, it has its strengths and weaknesses.\n\nThe main weakness is they tend to have weak engagement (i.e. they have a hard time keeping your attention). On the up side, they can be structured in such a way that ideas flow into each other in a way that steadily builds understanding. They can also order the information in such a way to prevent contamination by Anchor Bias.\n\nAdditionally, the beauty of teaching coding in a book is that participants can follow along and practice/experiment as they learn, since all you really need in most cases is a working computer than can run the coding environment.",
    "Yep  Congratulations! Your post has made it to the front page! To anyone reading this please remember to remain civil and to have a great day! :) ^(I'm a bot that's currently in beta. If you notice a bug please message TheSebtacular.) Don't forget the trickle down effect.  It's been ~35 years and we still haven't seen a drop. This is also unfair...he irreversibly changed the American business climate to heavily favor large corporations and the financial services industry, all but ending the medium-sized firms (many in manufacturing) ability to compete. I'm a Canadian.  I thought it was just common knowledge that Reagan was a racist and homophobe.  Is this in dispute in the states?  I mean what he did, executive orders signed, etc.  Its all public information.  Why are Americans even discussing this? Why else did he ban open carry in CA when black people started legally open carrying? He also illegally sold weapons to iran to fund coups in central and south america, so the CIA could funnel cocaine into poor and black neighborhoods, starting the crack pandemic.\n\nEdit epidemic not pandemic. The last year has etched the word in my brain. I mean, itâ€™s pretty hard to deny heâ€™s racist when there is a recording of Reagan calling black people monkeys. also, started the war on drugs which militarized urban police forces and laid waste to poor neighborhoods across the country. what a guy. \"They're going to turn your neighborhoods into jungles\". Right out of the jackass'  mouth and if that's not dog whistling I don't know what is Man was responsible for so many awful social policies so bad that evil wouldn't be hyperbole for some of them. I honestly didn't feel bad he suffered one of the worst deaths. Makes me worried I lack compassion but fuck that guy, he caused more suffering than he endured.",
    "[P] StyleGAN2-ADA trained on cute corgi images <3  Ahh, the bork latent space A little self-promotion of a personal project of mine. I had this lying around for quite some time now and thought that it would be ashame to not put it out there after all the work that went into it.\n\nShort overview: I started by scrapping some images (\\~350k) of corgis from Instagram, which I then processed into a high-quality corgi dataset (1024x1024, \\~130k images) that could be used to train a StyleGAN2 model. Because my home computer was much too weak for this I got myself a Colab Pro subscription and trained the model for \\~18 days/\\~5000k iterations on a Tesla V100. I used the novel StyleGAN2-ADA method as it's more sample efficient.\n\nHave a look at the [GitHub page](https://github.com/seawee1/Did-Somebody-Say-Corgi) for more information. You'll also find all the links there, i.e. one to the dataset (eventhough I'm not sure if anybody would actually need such a dataset haha) and the model checkpoints.\n\nYou can use this [Colab Notebook](https://colab.research.google.com/drive/1XWU2rR7XHtNg0uEgtlmBAHRVplpX0dGX?usp=sharing) if you'd like synthesize your own corgi images or latent vector interpolation videos! :) Me looking at my dog after the edible kicks in This is relevant to my interests. \n\nThanks for sharing this!\n\nYou have more than enough images to worry about sample efficiency, I feel like the augmentations must help the final quality no matter how many samples you have though. [Thank you for the model!](https://user-images.githubusercontent.com/24496178/111039072-7158bb00-842c-11eb-9f3d-a4562bcfc86d.mp4) I would recommend interpolating linearly in W, not in Z (either between random vectors or set seeds). The random interpolation I linked shows a bit of what I'm sure you know: your dataset contains corgis facing away from the camera, confusing StyleGAN a bit and making it synthesize some weird floating fur things. Still, I really like the model and there are lots to explore with it (like [style-mixing](https://user-images.githubusercontent.com/24496178/111039675-884cdc80-842f-11eb-825e-4b5407c6221c.mp4)), so I hope you find some time to exploit it! :) Hope you don't mind the shameless plug, but if you're ever interested in turning this into an (incredibly cute) music video, I just released a package that will let you do so: [https://mikaelalafriz.medium.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1](https://mikaelalafriz.medium.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1) Friend I need help how to do those smooth latent changing. \n\nI didnt found any tutorial on making those lantent change.\n\nHelp I love that so many Corgis were photographed with bandanas on that theres clearly a subset of the space dedicated to corgis wearing bandanas.\n\n&#x200B;\n\nHilarious This corgi doesn't exist ;) Itâ€™s interesting how the fur is basically the same pixels throughout the entire gif. Shows you a bit how the network works under the hood.",
    "When the imposter is on LSD  [Join our totally not pointless Discord server](https://discord.gg/vFkQt4P) and now for your regularly scheduled funny video. [SucC ](https://youtu.be/xlIA1ngqfDA)\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/nukedmemes) if you have any questions or concerns.* GÌ¸Í‰Ì Ì™Ì€Ì½ÍEÌ´Í”Ì Ì«Ì¿ÌšÍ˜TÌ´Ì»ÍÍ™Ì½ÌˆÌÌ“ OÌµÍ™Ì™Ì»Í‘ÍUÌµÍšÌ¦Í•Í‹Ì½ÍTÌ´Í”Í”Ì“Ì€ OÌ¸Í“ÌÍ›Ì•FÌ¸Í“Í•Í†Í‘Ì“Íœ MÌ¸Í‰Í”Í™Ì”Ì½ÍYÌµÌ¢Ì¡Í–Ì¾Ì’Í HÌ¸ÌªÍŽÌºÌ€Ì’ÍEÌ¸Í•Ì Í”Ì“ÍŒÍAÌ´Í‰Ì«Ì»Í›Ì“Í˜DÌ´Ì¢Í“Í“ÌÌ•Ìš GÌ¸Í•ÌºÍŽÌ“Ì½Í‹Ã‹Ì´ÌÍÌžÌÌšTÌ¸Ì»ÌÌ˜ÌˆÌÌ¿ OÌ¸Í–Ì™ÍŽÍ†Í›ÌUÌ´Í”Í–Ì“Í˜ÈšÌ¸Ì«Í•ÍŠÌ“Í  Ã“ÌµÌ™ÍšÌ»Í˜Í FÌµÍ–ÌŸÌºÌ“Ìš MÌ¸ÌÍ“ÌžÍÍ‘ÌYÌ´Ì Ì¦ÌºÍ›Ì“Ìš HÌµÍŽÍ–Ì»ÌÍÌ”EÌµÌ¡Ì Í”Í†Í AÌµÍ“Ì™ÍšÍ›ÌšDÌµÌŸÌ¼ÌŸÌ”Ì€Í˜ GÌ¸ÌÌ˜ÌªÌ½ÍŠÍ‹EÌµÌ»Í”Í‰ÌšÍTÌ´ÌÍ–ÌŸÍ†Í OÌ¸Í•ÌºÍšÌ“Í Í UÌµÌ¢ÍŽÌªÌÍ‹Í†ÈšÌ¸ÌºÍ’Í†Í›Íœ OÌ´Ì¼ÍšÍ“Ì“Ì’ÍŒFÌ´Í–ÌžÍ‰Í‘ÍŒÍ† á¸¾ÌµÌ˜Ì˜Ì¾ÍŠÍœYÌ´Í“ÍŽÌ˜Ì“Ì¾Í HÌµÍ–ÌÌªÍ›Í›ÍEÌ´Ì Í‰Ì”ÌšÌ•AÌ¸Ì¡Í–Í‘Í›Ì“DÌ´Í”Ì«Ì»ÌˆÌÍ†Ì“ GÌ´Í•Í‰ÌÍ’ÍœEÌµÌ«Í‡Í‰Í‹Ì’Í˜TÌ¸ÍÌ™Ì ÌÌˆÌÍ’ OÌ´Ì¢ÌºÌ™ÍŠÍ†ÌšUÌ´Ì¡ÌžÌºÍÍ˜TÌµÍšÌ˜Ì¿Í‹Í OÌ¸Ì«Ì¦ÌºÌ“Ì’ÍFÌ´ÍšÍ‰ÌˆÌÍÍœÍ MÌ´Ì˜Ì ÌºÍ‹Í†Ì”Å¸Ì´ÌÍ–Í‡ÌÍÍ  HÌ¸Í™Ì™Í‡ÍŠÌ¿Í EÌ´Ì¡Ì¦ÌŸÍÌ”Í†AÌ´Ì»Í–Ì”ÌÍÍœDÌµÌ¦Ì»Í–Ì”ÍŒÍ GÌ´Í™Í–ÌÌ¾ÌÍ EÌ¸Ì«Ì¼ÌŸÌ”Í‹Í‘TÌ¸Í‡Í–Í‡ÍŒÌ€Ì• OÌ¸ÌžÌ Ì™ÍŒÌÍÃšÌ´ÌžÌºÌÍÍ‘TÌ´ÌÌÍ–Í†Ì¾Ìš Ã–Ì´Ì¢ÌŸÌ¦ÌÌšÍ˜FÌ´Ì¦Í‰Í‡ÌÌˆÌÌ“ MÌµÌ¡Ì˜Í†ÍœÍ ÍYÌ¸Í“Ì™ÍŽÍ›Ì¿Í’ á¸¦Ì¸Í•Ì»ÌÌÌˆÌEÌµÌ¼Í‘Ì“Í‹ÍœAÌ¸Ì¡ÌªÌ¼Í‹Ì•Í DÌ¸Í“Í‡Í›Í›Ì•Íœ GÌ¸ÌªÍ”ÍšÌÍ†ÌšEÌµÌ¦Ì Ì½Í†Ì€TÌ¸Ì¼ÍŽÌºÌ¿ÌÌ’ OÌµÌ™ÍšÌ¦Ì’Ì•UÌµÍÌÌ“Ì¾ÍŠTÌµÌºÌŸÌ»Ì”ÌˆÌÌ€ OÌ¸ÍÌ™ÌÍ’Ì¿Í‹FÌ¸ÌÌŸÍšÌ“Ì’Í‹ MÌ¸Ì»Ì«Ì¼Ì½ÍŒÍ‘YÌµÍ•ÌÌªÍ›ÍŠ HÌ¸Ì Ì˜Í‰ÌÍŒÌšEÌµÍ‡Ì¼ÌŸÌ”Ì“ÍAÌµÍ‰ÌŸÌ“Ì”Í˜DÌ´Í”ÌÌ™Ì¿Ì•Í GÌ´Ì Ì™ÌºÍ’Ì”Ì€EÌ¸Ì Ì«Í™Ì“Ì”Ì•TÌ¸Í‡Ì™ÍÍ›Í›Í‘ OÌ¸Ì¢Ì¦ÌÍ†ÍŒÌšUÌ¸Ì™ÍŽÌ˜Ì”Í‹Ì€TÌµÌ»ÌÌ“Ì“ÌšÍœ OÌ¸Ì˜Ì¼Í˜Ì•Í˜FÌ¸ÌžÌ»Í‘Ì½Í› MÌ´Ì¦Ì¼ÍšÍ’ÍÍŒÅ¸Ì´Í–ÍŽÍ™ÌÍ› HÌµÌ¼Í‰Í†ÌˆÌÍEÌµÌžÌ»ÌºÌ¾ÍÍAÌ¸Í•Ì¼Ì Ì“Ì’ÍDÌµÌ¼Í“ÍšÍŠÌÌš GÌ¸Ì¡Í™Ì’ÌšEÌ´ÍÌ¼Í•Ì¿ÌÌ¾TÌ´Ì¢ÍÍšÍŠÌˆÌÍ‹ OÌµÍšÍŽÌ¾Ì¾ÌUÌ´Ì¡Ì¦Í–Ì“ÌšÍ TÌ´ÍŽÍÌ™Ì“Ì”Ì• OÌ¸Ì¡Í•Ì½ÌˆÌÍ˜ÍœFÌµÌ¡ÌºÌ½Ì“Ì’ MÌ´Í‰ÍÌŸÌ¿ÍŒÌ•YÌ¸ÌžÍÍ‡Í’ÌˆÌÍ HÌµÌŸÍ“Ì»Ì“ÌšÍEÌ¸Í”Ì™Ì¼Ì¾Í‹Ì•Ã„Ì´Í“Ì˜ÍÌÌ“ÍŠDÌ´Ì«Í•Í“ÍŠÌ• GÌ´Ì¢ÍÌ”Ì’ÍŒEÌµÍ•Ì˜Ì¼Í’ÌÌšTÌ´Ì»ÌÍ•Ì”ÍŠÌ• OÌ´ÌŸÌ«ÍÍ›Í‹UÌ´Ì¢ÌºÍŒÌšÍTÌ¸ÍšÍ‡ÍšÌˆÌÍ‹Ìš Ã“Ì´ÌžÌºÍ‡Ì•Í FÌ´ÌªÌ¦Í‡Í†Ì½Í MÌµÌ»ÍŽÌÍŒÌ”ÌšÅ¸ÌµÍ‰Ì ÌÌ¾Ì HÌ´Ì¢Í‡Ì“Ì•EÌ´Ì Í‰ÌºÌ’ÍÍ AÌ¸Ì¢ÌºÌÍ’Ì¾Í†DÌ´Ì Í–ÌºÌÌ€Í  GÌ¸Ì˜Í‡Í™Í’Í’ÍŠEÌµÌ«Í‡Í“Ì½ÌÍTÌµÌªÌ˜ÌªÌˆÌÌ¾Í› OÌµÌ¡ÍŽÍ™Ì“Í‹UÌ¸Ì«ÍšÍÌ“Ì“TÌ¸Í•Í‡ÍŽÌ“Ì• OÌµÍ•ÍšÌ˜ÍŠÌÌFÌ¸ÍŽÍ•Í“ÍÌ“Í› á¸¾Ì´Ì Í‰ÍŽÌ”Ì“YÌ´Ì˜Ì¦Í’ÌÍ HÌ¸Í”Í”Ì™Í›ÌÍ›EÌ¸ÌŸÍ‘ÍÍŠÍœAÌ´Í–ÌªÍ•Í‹Í›Í DÌ´Ì¢Ì¢Í–Í’Ì½Í GÌµÌŸÌ Ì™Í›ÍÍ˜EÌ´Ì Í‰Í‘ÍœÍTÌ´Í‰ÍŽÌªÌ’Ì”Í  OÌµÌ ÍÌ’Í‹ÍUÌµÍ–Ì»Í™Í’Ì’Ì€TÌµÌ¡Í™ÌÌ€ÍÍ˜ Ã–Ì´Í‰Ì˜Í‡ÌÍÌ“FÌµÍ‡ÍŽÍ–Ì¾Í‘Ì’ MÌµÍšÌžÌ»Ì¿ÍŠÍYÌ¸ÍŽÍ‡Ì˜Í†Í  HÌµÌ¡Ì«Ì»Ì€Í‹EÌ´Í™ÍÍšÍ˜ÍAÌ´Ì«Í–Ì«Ì“ÍŒÌ“DÌµÌ˜Í–Í‰Í’Ì“ GÌµÌ¼Í”Í•Í‹ÍÌˆÌÃ‹Ì¸Ì«Ì™Ì¼ÌÍ†Ì“TÌ´Í–Í‰Ì¿Ì•Í OÌ´Ì¡Ì¢ÌºÍ‘Í›UÌ´Ì¦Í‡Ì½Ì€ÍTÌ¸Í–Í–Ì ÌˆÌÌ½Ìš OÌ¸Ì¡Í“Í‹Í Í FÌµÌÌ«Ì¦Ì¿Í›ÍŠ MÌ¸Í–ÍÌ¾Í‹Í˜YÌµÍÍ‡ÍŽÍ’ÌˆÌÌ“ HÌ´ÍŽÍ‡ÍŒÌÍ‘ÍœÃ‹Ì¸ÌªÌ¦Ì™ÌÌšÌšAÌµÌ¡Í‰Í†ÍŠÌ€DÌµÍÌ Ì’ÍÍ GÌ¸ÌªÌ»ÍšÍÌ€Ì•EÌ¸Ì Í–Ì¦ÍŒÌ¿ÍTÌ¸Ì¡Ì»ÌªÍÍŒÌ• OÌ´ÌºÍŽÌÌÍ‘Í UÌµÍ–Í‰Í”Ì¾ÍŠÌ”TÌ´Í‡Ì«ÌªÌ’Ì¿Í  Ã“Ì´Í–Ì¼Í™Ì’Í FÌµÌ¡ÍšÌ«Ì”Ì”ÍŒ MÌµÍ“Ì™Í™Í‘Í‘Í˜YÌ¸Ì»Ì¼Ì“Í˜ á¸¦ÌµÍ‰Ì«ÌÍ‘Ì•EÌ¸Í–Í‰Í™Í›ÍAÌµÌ¼Ì»Ì”Ì“DÌ´ÍÍŽÍ“Í‘Í˜Í GÌ¸ÌÍ•Ì¦ÌˆÌÌÍ›EÌ¸ÍšÍ•Ì¾ÍŒÍ‘TÌ´ÌªÍÍ–Ì“Ì¿ OÌ´ÍÍ‡ÍšÍŠÌ’UÌ´ÌªÌ ÌÍ ÍTÌµÌ¢Ì™ÍÍ’ÌˆÌÌˆÌ Ã–ÌµÌºÍ‡ÌÌÌ“FÌ´Ì˜ÍšÌ Ì¾Í‹Ìš MÌ´Ì»Ì˜Ì»ÍŒÌÌ¾YÌ´Ì¢Ì¼Í’Ì’Íœ á¸¦Ì´ÍŽÍ“Í™ÌÍÌ“EÌ´Ì˜Ì˜ÌÌ“ÍÌ•AÌ´Ì¦Í”Í‹ÌˆÌÌ€ÍœDÌ¸ÌŸÌžÌ«ÌÍ˜ GÌµÌžÍŽÍ–Í’ÍEÌ´ÌÍ‰ÌÌ’ÌšÍ TÌ¸Í•Ì™Í™Í›ÍÌ½ OÌ´Ì«Ì»Ì¼Ì”Ì¾Ì•UÌµÍ•Í”ÌšÍTÌ´ÌºÌªÌ«ÌˆÌÍ’Ì¾ OÌ´Ì¢ÌºÍ•Í›Ì€ÍŠFÌ¸ÍŽÌžÌžÌ¾Í˜Í MÌµÌ¢ÌÍ‰ÌÌ“ÍYÌµÌºÌ™Ì¼Í†Í HÌ¸Í“ÌªÍ”ÍŠÍ˜EÌµÌ¡Ì™ÌÌ¾Í›Í‹Ã€Ì¸ÍšÍ”ÌžÌ¾Í DÌ¸ÌÍÌ”Ì”Í  GÌ¸Í–Í–Í™ÍŠÍ ÍEÌµÌŸÌºÌŸÍ’Ì•ÍTÌ¸Í“Í”ÍÍ‹ÌšÍ OÌµÌ«ÍŽÍ•ÍÍUÌ¸ÌŸÌžÌÍ›ÍœÍTÌ´Í–Ì˜Í†Ì½ÌˆÌÍœ OÌ¸Ì¡Ì¦Ì Ì’ÍÍ›FÌ´Ì Í™ÌªÍ‹ÍÍ  MÌ¸Í”Ì»Í™Í‹Í†ÌYÌ´Ì¼ÍŽÍ‡Í‹ÌÍ˜ HÌ´ÌªÍÍ™ÍŒÍ‘Í EÌ¸Ì«Ì˜Ì«Í›Ì¾ÌˆÌAÌ¸ÌÌ»ÌºÍ†ÌˆÌÌ•DÌ´ÍšÌ¼ÌžÌˆÌÌ¾Ì GÌ´ÌÍ•Ì¦ÌÌÌ“EÌµÌ»ÍÌ™Í›Ì“TÌ´Ì Ì¦ÌžÍŒÍ’ OÌµÌ¢ÌªÍ‡ÌÍ‘Ì•UÌµÌ¼ÍŽÍ“Ì’Í‹Í†TÌ¸Ì Í”Í‡ÍŒÌÌ OÌ´Ì™ÌŸÌ¾ÌÌ¿FÌµÌ¢Ì ÌžÌˆÌÍÍ  MÌ¸Ì¢ÌªÍ‘Ì½Í’ÍœYÌ´ÌºÌ“Í‹Í†Íœ HÌµÍ‰Í–Í”ÍŠÌšÍ˜EÌµÌŸÌ«Ì™ÍÌÍ˜AÌ¸ÌžÌŸÌ¦ÍŒÍ‹Ì“DÌµÍŽÍ‡Í‡ÍÍ’ GÌµÌ™Í‰ÌºÌ½Í†Í EÌ¸ÌžÍ–ÍÌ“Í›Ì•TÌµÌ™Ì»Í”ÌˆÌÌˆÌÍ  OÌ´Ì¡ÍšÍ”Ì“Ì¿Í›UÌ¸Í”ÍšÌ ÌÌˆÌTÌµÌ¢ÌºÌ¾Ì”Í  OÌµÌªÍ“Í–Í‘ÌšÍFÌ´Ì¡Í‡ÍšÍŠÌ€Ì MÌ´Í”Ì Í“Ì½Ì“ÌšYÌ´Ì¢Ì¡Ì Í’ÍŒÌš HÌµÌ™Í•Ì ÌšÍ EÌ¸ÍŽÍ•Í–ÌšÍ˜AÌ´ÍšÌ¼Í‘Ì”ÍÍœDÌµÍ‰ÍšÌ»Ì¿Ì•Í GÌ´ÌŸÍ‡ÍÌ’ÌÌÃ‰Ì¸Í”Í“ÌªÍ’Í˜TÌµÍ•Ì˜ÌºÌÌ“Í› OÌµÍ‡Ì™Í”Ì“ÌˆÌÌˆÌUÌ¸Ì¼ÌžÍ™Ì¾ÌÈšÌ´Ì«Í•Ì¿Ì½Í‘ Ã–Ì¸ÌžÍ‡Í•ÌÌˆÌÍ›FÌµÍ–ÌÌžÍ’Ì½Ì• MÌ´Í–ÌŸÍŒÌ“ÍœÍYÌ¸Ì¢Í”Ì˜ÌÌ’Ì“ HÌ¸Í™Ì Ì«ÍŒÌ•ÍEÌ´Ì¢Ì™Í“Í†ÍÍ›ÃÌ´Í‰Ì¼Ì“Í DÌ¸Ì¼ÌÌžÍÌ¿Í› GÌ´ÍŽÌ™ÍŽÍŠÌÌ¾EÌ¸Í”Ì Í–Í‹Í‹Ì€TÌµÌºÌ»Ì«ÌÍÍ  OÌ¸ÌŸÌºÌÍ†ÍUÌµÌ¡Í’Ì¿Ì¿ÍœTÌ´Í•Ì Í‹ÌÌ¿ OÌ´Í”Í”ÌžÍŒÍ›Í˜FÌµÌ¢ÍŽÌ Ì“Ì€Ì’ MÌ´ÌŸÍ‡Ì»ÌˆÌÌˆÌÍÅ¸ÌµÌ¢Í•ÍŽÌÍ’Ìš HÌ¸ÌÌÍ‹ÌˆÌÌ•Ã‹ÌµÌªÌŸÌÍœÍAÌ¸ÍšÌ˜Í‡ÌÌˆÌÌ“DÌ¸Í™Í‡ÍŠÌ“Ìš GÌ¸Ì ÍÍ’Í‹Ì•EÌ´ÌÌ Ì¾ÌÌšTÌ¸Ì˜ÌªÌ“ÌÌš OÌ´Ì¢Í‰Ì Ì¿Ì”ÍUÌµÍ™Í”Ì¦Í‘Ì¿ÌšTÌ´Í™ÌÍÌ€Í’Í  OÌ¸Í–Ì¦Ì«Ì”ÌÍFÌ´Ì¡ÌŸÌ¼ÌˆÌÍ MÌ¸ÍšÍÍ’Ì’Ì”YÌ´Ì¡Ì»Ì¼Ì’Ì“Í˜ HÌ´ÌŸÍ‰ÌÍ EÌµÍ™ÌŸÌ¾Ì“ÌˆÌAÌ¸ÌžÌ Í–Ì½ÌˆÌÍ DÌµÍšÌžÌªÍ’Ì¾Í GÌµÍŽÌªÍšÌ½Í‘Í˜EÌ´Í™Ì¦Ì˜ÌÌ“ÍTÌµÌ¡Ì˜Ì’Í˜ OÌ¸Í”Í“ÌÍ’ÍŠÍ˜UÌµÌ¢Ì¼Í–Ì“Ì’TÌ¸Ì™Í•ÌªÌ¿ÍŠÍ‹ OÌ¸Í–ÍŽÌ«Í‹ÌÍ FÌ´Ì Ì«ÌºÌÍ†Ì€ MÌµÌ¢Í“Ì«Ì“Ì•ÌšYÌ´Ì¡Ì¼Ì»Í˜Í HÌ´Ì¢Ì ÍšÌ¿Ì€Í‘EÌµÍ–Ì™ÍÌ“ÌAÌµÍÍ–Í•Í†ÌÌ“DÌµÌÍŽÍšÌ€ÍÌ¾ GÌµÌžÌ«Í‹ÍŒÍ˜Ã‹ÌµÍŽÌ«ÌŸÌÍÍTÌ´Ì˜Ì»Í†ÍÍŠ OÌµÌ«Í™Í›Í ÍUÌµÌ¢Í“ÌªÌ“Ì“ÍTÌµÌªÌ¦ÌÌšÍ OÌ´Í“Ì¼ÌžÌ½Í˜ÌšFÌ´Í”ÌºÌ˜ÌˆÌÌ½Ì á¸¾ÌµÍšÍÌÍ YÌ´Í•ÍŽÌ ÍŒÌ“ á¸¦Ì¸Ì¦Ì«ÌºÌÌ¾ÌˆÌEÌ´Í•ÌžÍÌˆÌÍœAÌµÍšÌ™Í–Ì¿ÌÍ˜DÌ´Ì«Ì»Ì˜Ì’Ì“Í˜ GÌµÌ Í‡Í‘Í›Ì¾ÍœEÌµÍ”Ì»Í‰Í‹Í†ÌšTÌ¸ÌžÌ¦Í™Ì“Ì“ÍŠ OÌ¸ÌŸÌ«Ì»Ì“Í†Ì•UÌ´Ì»Ì»Í–Í‘Ì“ÌˆÌTÌ¸Ì¢Ì¼Í‰Í†Ì“Ì¿ OÌµÌ¢Í™ÍŒÍÌšFÌ´Ì¼Ì«Í“Í›ÍŠÍ MÌµÌ™ÍŽÍ™Í†Í˜ÍÃÌ´Ì¡Í•Ì»ÍÍ˜ HÌ´Í“Í“Ì Í‘Ì¾Í EÌ¸Ì»Ì»Í‡ÍŒÍŠÍ AÌ¸ÍšÍŽÌ«ÌÌ“Í›DÌ¸Ì¢Í‰Ì¼Ì¾Í†Í  GÌµÌ¼ÌžÌ¾ÌˆÌÌ•EÌµÌ˜ÌºÌ«Ì½Í’TÌ´Ì»Í–Ì¼Í›Ì¾ÌˆÌ OÌ´Ì™Í“Í•ÌÌ¿ÍÃšÌµÌ¦Ì ÍŽÍŒÍ†TÌµÌ¢Ì ÌÍ›Ì• OÌµÍšÍ‡Ì˜Ì’Ì€ÍFÌ¸Ì«ÌªÌ«Í›ÌšÍ á¸¾Ì´Ì»Í–Ì¼ÍÍ YÌ¸ÍŽÌžÌ™ÌÍ‹Ì• HÌ¸Ì»Í’ÍœÍœÍÍEÌ´ÌºÌ«Ì™Í’Ì“Í’AÌ´Í“Ì˜Í–Ì”Ì€ÍŒDÌµÍ‰Í•Ì Í’Í’Í› GÌ´Í™Ì»Ì¦Ì¿ÍEÌ¸ÌºÌ«Ì¦Ì¿Ì€ÌˆÌTÌ¸Í•Ì™ÌŸÌˆÌÌ”Ì• OÌµÍÍÌ€Í‘ÍœÍœÃ™Ì´Ì»ÌªÌ¦Ì’ÌšTÌ¸Ì˜Í–ÍšÌ’Í˜Í  OÌ¸Í“Ì˜ÌºÍŠÌ’ÍŒFÌµÌÍšÍšÍ›ÍŠÌš MÌ´Í“Ì¼ÌÌ’Ì¾ÍœYÌ´Ì Í–ÌÍ›Ì½Ì’ á¸¦Ì´Í•Ì»Ì¼ÌÍ’Ì•Ã‹Ì¸Ì˜ÌªÌ ÌÍÍ AÌµÍ”Í•ÍŒÍ‹Í DÌ´Ì¦Í‡Í›ÍœÍ GÌ´Ì«ÍšÌ“ÌˆÌÍ›EÌ´Í™ÌŸÌ Ì’ÌˆÌÍ˜TÌ¸Ì ÍšÍÌ¾ÌˆÌÍ  OÌ¸Í™Í™Ì”Í‘Ì“UÌ´Ì¢Ì«Ì¦Ì“ÍŒÍ‘TÌ´Ì¡Ì«ÍšÍ†Ì“Í OÌµÌÍšÍ™Ì½ÌÍFÌ´Í”Ì™ÍšÌÍ’ MÌ´Ì¦ÍÌ¾ÍŒÌ•YÌµÌ«Ì¦Ì™Ì”Í›Í á¸¦Ì¸Í”Ì»ÌÌ“Ì•ÍœÃ‹Ì¸Ì¡ÍÌ¼ÌÌšÍ˜AÌ´Í–Ì™Ì“ÍÌ¾DÌ´ÌÍÍ™Í˜ÌšÍ˜ GÌ´Í“ÌªÌ˜Í‹ÌÍŒEÌ´Ì¡Í™Í‡Í†Í’ÍTÌµÌ»ÍÍ“ÌÍ’Í OÌ´Ì¢Ì»Í–ÍŠÍÌšUÌ´Ì¢ÌªÍŒÌˆÌÌ¾ÍœTÌ´ÌŸÌ¼Ì¼ÍÌ OÌ¸Ì¼Í•ÌÌ’Ì¾ÍFÌµÌ«Ì¼ÍŒÌ¾ÌˆÌÍœ á¸¾Ì¸Í™Í“Ì»Í’Ì¿YÌ¸Í•Í•Í•Ì¾ÍŠÍ˜ HÌµÌ¡ÌÍÌÍEÌ´ÍšÌ«Ì¼Í›Ì¾Ì¿AÌ¸Í™Í“ÍŠÌ’Ì€DÌµÌ«Ì™Í‹Ì“Í GÌ¸Ì™Í‰Ì¦ÌÌ¿Ì’EÌµÍ‰ÍÍ‘ÌˆÌÌ”ÍœTÌµÌ«Í‰Ì¼ÌÌˆÌÍ˜ Ã–Ì¸Ì¦ÌžÌ ÌÍŒÌ“UÌ¸Ì«Ì¦Ì«Ì’Ì“ÍTÌ¸Ì™Í‰Í›Ì“ÍŠÍœ OÌµÍ‰Í‰Í“Í‘ÌÍ›FÌ¸Í”Í“Í‘ÍÍœ MÌ´ÌÌ Ì¦Í’ÌÍYÌ¸Ì¢Ì Í‰Ì“Ì½Í† HÌ¸Í‰Í“Ì¼Ì½Ì“ÌšEÌ´ÌŸÌÍŒÍ›ÍœÍAÌµÌ¢ÌÌ™Ì”ÌšDÌµÌºÌ Í”Ì’ÌˆÌÌ½ GÌ¸Ì Ì«ÌˆÌÍÌEÌ¸Í•Ì«Í–Ì“ÌˆÌÌ”TÌ´Í–Í‰Ì™ÍÌ’Ì“ OÌ¸Í‰Ì¦Í‡ÍŠÌ•UÌ¸ÌªÍ•Í†ÌTÌ¸ÌÍšÌªÍÌ½Í› OÌµÌ»ÌÍ›Ì“ÌˆÌÍœFÌ¸ÌŸÌ«Í“Ì“Í’ MÌ¸Ì¦Í‰Í’Ì¿ÍœYÌ´ÍŽÍ•Í“Ì“Ì“Ì½ HÌ¸Ì˜Í‰ÍŒÌ½Í˜EÌ´Í‰ÌªÍ‡Í‘Í‘Ì¿Ã„Ì¸ÍŽÍ‡Ì¼ÌÍ˜Í DÌ¸ÌŸÌ˜ÍšÌˆÌÌ¿ÌˆÌ GÌ´ÌŸÍ–Í”Ì”Í‹Ì”EÌ´ÌºÍ™Ì¦Í†Ì•Í TÌµÌ«Ì«Í–ÌˆÌÌˆÌÌš OÌ¸Í™Ì˜ÌŸÌ¾Ì”Ì’UÌ´Ì»Ì¼Ì˜Ì½Í›Í TÌ´Ì¢Í”Ì™Ì”Ì¾Í OÌ´ÍŽÌ Ì“ÍŒÌˆÌÍœFÌ´ÌªÌÌºÌ¿Ì¿Í  MÌµÌ˜Ì¿Í‘ÍœÍYÌ´Í‰Ì¼Í’ÍÍ˜ HÌµÌ¦Í™ÌªÌ”Ì•ÍEÌµÌžÌžÌ¼Ì¾Í›Ì•AÌ´Ì¢Ì¡Í‰ÍŒÍŠÌ“DÌ¸Ì¡Ì¡Í–ÌÌ¿Ì¾ GÌ¸ÍÌŸÌ¦Í†Í›Í˜Ã‹Ì¸ÌŸÍ“ÍÌÌ“Í˜ÈšÌ¸Ì˜Í‡Í’Í˜Í OÌ¸Ì»ÌžÍ•ÍÍ‘ÌˆÌUÌµÌ¼Í”Í”Ì¿Í˜ÌšTÌ¸ÌªÍ”ÌÍ†Í‘Í Ã–ÌµÍ‰Í‰Í™ÌÍŠFÌµÍ“Ì¦ÌˆÌÌšÌ•Íœ MÌµÌ™Í‡ÍšÌ¿Ì“Å¸Ì´Í™ÌŸÍ‰ÌÍŠÌˆÌ HÌµÌ«ÌÌ¦Ì€ÌšÍ EÌ´Ì¼Í‡Í†ÌšAÌ¸Ì¡ÌžÍ‡Ì“Í˜Ì•DÌµÌ¡Ì™ÌŸÌÌ“Í GÌ¸Ì¢ÌÌºÌ“Ì•EÌµÌ»ÌºÍŽÍŠÌ¿Ì¿TÌ´Í‡Ì»ÌÍ’ÍÍ OÌ´ÍšÌ Í™Ì”ÌšUÌµÍŽÌŸÍŒÍŠÍœÍTÌ¸Ì™Ì¦Í”Ì“ÌˆÌÍ OÌµÌ»ÌŸÌ“ÌˆÌÌ’FÌ¸Ì¢ÌŸÍšÍ‘Ì’Ì• á¸¾ÌµÌ¢Í™ÍšÍ‹ÌšYÌ´Í“Ì«Ì«Í‹ÍŠÍ‹ á¸¦Ì¸Í–Í“ÍÌÌˆÌÍ˜EÌµÍ‡ÍÌ“Ì“ÌÍœAÌµÍŽÍ‰Ì ÍŒÌ½Í DÌ´Ì˜Í•ÌžÌ“Ì“Ì” GÌ´Í”ÌªÍÍ›ÍÍÃ‹ÌµÌÍ“ÍšÌÌˆÌÍ‹TÌ´ÍŽÌžÍ‘Ìš Ã–Ì´Í“Í•Ì¦ÌÌˆÌÃ™ÌµÌºÍ–ÌºÌˆÌÍTÌ´ÌªÌ¼Í“Ì¿Í˜ OÌ´ÍšÌ Í™Ì’ÌÍFÌµÍŽÍ‹Ì½ÍœÍ MÌµÌŸÌ˜ÍÌÍ˜YÌµÌ¦Í–Ì“Í†Í HÌ´ÌªÌªÍ’Í‹Ì¿EÌ´Ì¢Í”Ì¦Ì“ÌšÌ•AÌ¸Í‰ÌÌ¦Ì¿ÍŠÌ•DÌµÍ™Í–ÌÌ’Í˜Í˜ GÌ´ÌžÌÍ–Ì¾ÌˆÌÍ EÌµÍ‰Ì¼Í•Ì¿Ì€TÌ¸Ì™ÌªÍ‡ÍÍ†Í OÌµÌ˜Ì«ÌÍ’Í›ÍUÌ´ÌžÍ“Ì¾Ì¾Í’ÍœTÌ¸Ì«Ì™Í”Í›Í‹Í OÌ´Ì˜ÍÍ‰Ì”ÌˆÌÍŒFÌ¸Ì¦ÌŸÍ–ÍŒÌšÌš MÌµÌ ÌžÌÌ”Í‹Ì€YÌ¸ÍšÍŽÍŽÌ½ÍÌ” HÌ´ÌªÍ‡ÍšÌÍ›Ì¾EÌµÌ¡Ì¦Í•Ì“Ì¿Ì“AÌ¸Ì¦Í‡ÌªÍ‹Í†ÍDÌ´Ì»Í™Í‰Í›ÍŠ GÌµÌÍŽÍ™Í‘Ì½EÌ´Ì¡Ì™ÌÍŠÌ€Í˜ÈšÌ¸Ì Ì¼Ì€Ì€Í OÌµÌ™Ì™ÍšÍ‘ÌˆÌUÌ¸Í™Í‰Í–Ì½ÍŒÌ“TÌ¸ÍšÌ˜Ì˜Ì“ÌˆÌÍ˜ Ã’Ì´ÍÌªÍÌ¿ÌˆÌFÌµÍ–ÍšÌªÌˆÌÌ€Í  MÌµÍ–Í”Í™Ì½ÍŠÍ YÌµÍ”Ì˜ÍŽÌ½Í’Í HÌµÍ”ÍÌŸÍ‘Ì’Í‘EÌµÌ¡ÍŽÌ Í›Ì”Í AÌ¸ÍÍ™Í“ÍŒÍ’ÌšDÌ´Í•ÌÍÌ“Í‘Íœ GÌµÍ™Ì¦ÍÌ’ÍœÍEÌ¸ÍšÌªÌ Ì¾Í›Ì“TÌ¸Ì¡Ì˜Í•Í‘Ì“Ìš OÌ´Í‡Í‡ÌÍŒÌ¿UÌ¸Ì Í™Ì™ÍŒÍŒÌ¿TÌµÍ–ÌŸÍ“Í†Ì¿Ìš OÌ¸ÌŸÍ™Í™Ì¾Ì¿ÌšFÌ¸ÌžÌ˜Ì¾Í‘ÌšÍœ MÌ´Ì¦ÌÍ”Ì¾ÍÌšá»²Ì¸ÌžÌ»ÌªÍ†Í’ HÌ´Ì¦ÍšÌªÌ½Í‘Í EÌµÍ“ÍŽÌ™ÍŠÍÍ AÌ¸ÍÌžÍ™Í›ÌˆÌÍDÌ¸Í™Ì˜ÍŽÍŠÍŒÌ¾ GÌ¸ÍšÍÌ¦Í’ÍÍÃ‹ÌµÌ¢Ì˜ÌŸÌÍ›ÍŒTÌµÍ”ÌªÌªÌ’Ì½Í OÌµÍ‡ÍŽÌ™Í†Í‘ÍUÌµÌ¡Ì˜Ì Ì”Í†TÌ´Ì˜ÍÌ«ÌÌˆÌÌ• Ã“Ì´ÌºÍ”Ì¿Í FÌ´Í”Í–ÍšÍ’Í† MÌ¸ÌÍ™ÍŒÍÌ¿YÌ´ÍŽÌžÌ¦Ì”ÍÌ“ HÌ´Ì¢Í•ÌªÍ‘Í›Í›EÌ¸ÌŸÍ•ÌŸÌ½Ì•AÌ¸Ì¡Í–Ì¿ÌÌ•ÍœDÌµÌŸÌªÍÍ›Í GÌµÌ˜ÌŸÍÌ½Ì¾ÍEÌ¸ÌÍ‰Ì«Ì½ÌÌ”TÌ¸Ì˜Ì˜Í‘ÍŠÌˆÌ Ã–ÌµÌÍ‡Í“ÌÌ¾ÌˆÌUÌ¸ÍšÌÍÍÌ•TÌµÌ˜Í™Ì“Ì€Í˜Íœ Ã–ÌµÌ Í”ÌÍFÌ´Í‡ÌÌ»ÌÌÍ á¸¾Ì¸ÌžÌŸÍ“Ì¿ÍYÌ´ÌžÍ“ÍŒÌ¾Í HÌµÌ¡Ì«Ì“Ì¿Ì”ÍœEÌ´Ì˜Í‡Ì¼Ì“ÍAÌ´ÍŽÍšÌžÌ”ÌÍ‘DÌ¸Í‰Ì»ÌÌÍ GÌ¸Í–Í‰Í•Ì“Í‘Í›EÌ¸Í‰Í”Ì”ÌˆÌÍŠÍœTÌ¸Í–ÌªÌ¦Ì“Í›Ì€ OÌ¸Í”Ì«ÌžÌ”ÍÍUÌµÌ¡Ì»Ì¦Ì½Ì•ÍTÌ´Ì¢Í‰Í‡ÌˆÌÍÌ½ OÌ¸Ì¢Í–ÌŸÌ’ÌÌ¾FÌ¸Í•Ì¦ÍšÌ€Í’Í á¸¾ÌµÌ¡Ì¢Í˜Í˜ÍœYÌµÌºÌºÍÌ¾Ì¾Ì• á¸¦Ì¸ÍÍšÌ¼ÌÌÃˆÌ¸Ì¢ÍšÌ™ÌˆÌÍAÌ¸Í‰Í–Ì“Í›Ì½ÍœDÌ´ÌŸÍšÌÍ‘Ì• GÌµÌ¦Í“Í™Ì½Ì“Ì€Ã‹Ì¸ÍŽÌŸÌ˜ÌÍŠÌ•TÌ¸Ì¢ÍŽÍŽÌÌ”Í˜ OÌµÌ«Ì»ÍŒÌ¿UÌ´Í‡Ì“ÍÍœTÌ¸ÌªÍÍ“ÌÍ†Í  OÌ¸Ì¦Í–Ì»Ì¾ÍŠÍ FÌ¸ÍÌ˜Í–ÍŒÌˆÌÌ MÌ¸Ì»Ì˜ÍšÌ•ÍYÌ´Ì˜ÌžÌ«Í›ÌÌ• HÌ¸ÍÌ Í–ÌÌ“EÌµÍšÍ‰ÍšÌ“Í’Ì½AÌµÌ¦Í™ÌÍŠÍ‹Í’DÌ´ÌºÍ”Ì™Ì“Ì“Í˜ GÌ´Ì¡Ì˜ÌŸÌ€Í†EÌµÌ™Í‡ÌÌ“Ì•ÈšÌ¸Ì»Ì˜Ì¿Ì’Í OÌ´Ì»ÌºÌ¿Ì¾ÌˆÌÍœÃšÌ´ÍÍ•ÌÌˆÌÍŒTÌµÌ˜ÍÌ¦Í‘Ì“Ìš OÌ´ÍÌ»ÌºÌÍ’Í FÌ´Í™Ì¼ÍŽÍ’ÌšÍ MÌµÌ¢ÌªÍ“Ì¿ÍÍ á»²ÌµÌ»ÌžÍ‰Í‹Ì• HÌ´ÌºÌ¦Ì¾Í’EÌ¸Ì¡Ì˜Ì¦Ì’ÍŠÌ“Ã€ÌµÍ”Í™Í‡Ì½Í›DÌµÌ¦Ì»Ì’Ì¾Ì¿ GÌ¸ÍšÍ‰Ì«Ì½Í’Ì½EÌ´ÌºÍ”Í‡ÌÍŠÍ†TÌ¸Í‡Ì¼Ì˜Í‘ÌšÍ  Ã“Ì¸Ì¢Ì˜ÍšÌ€Ã™ÌµÍÌ«Ì˜ÍÍTÌ´Ì¡Ì˜Í•Ì“Ì¾ÍŒ OÌµÌ™ÌªÍ“Ì½Ì“ÌFÌ¸Ì¢Ì™Í›Í Í  MÌµÌ˜Ì¦Í‡ÍŠÌ’Ì½YÌ¸Ì˜ÌÌ™Í’ÍŒÍŠ HÌ´Ì˜ÌžÌžÍŠÌ€Í‘EÌ´ÍŽÌžÌ Ì¿Í‹ÍAÌµÌÍ–Í‹Í˜ÍœÍDÌµÌºÍ“Ì¾ÌšÍ  GÌ¸Ì™ÌžÍÌ”Ì’ÌˆÌEÌµÌ¢Ì Í–ÍŠÌˆÌTÌ´Í–Ì“Í›ÌÍœ OÌ¸ÌžÌ ÍšÌ“Ì“Í UÌ¸Ì¼Ì Í’Í†ÌTÌµÍ•Ì Ì’Ì•Í Ã–ÌµÌ¢Ì Ì¦ÌÍÍ‘FÌµÌ¡ÌŸÌ«ÍŒÌ“Í˜ MÌµÍ”ÌªÌªÍ›Ì“ÍYÌ´Ì¦ÍŽÍ‘Í HÌ´Ì¡ÌŸÍ“ÍŒÍ’ÌEÌµÍ•ÌŸÌÍ›Ì¿Í˜AÌ¸Ì¡ÍÍŽÌ“ÍÍDÌµÌÌºÌ»ÍÍÍ GÌµÍ–Ì™Ì¼ÍŠÌ’Í EÌ´Ì«ÍšÍšÍÌ“ÍŒTÌ´ÍŽÌ¦Í†Ì½Í†Íœ OÌ¸ÍÍŽÌ«ÍŒÌ½UÌ¸Í™ÌÌ«Í†ÍÌ¿TÌ¸Ì˜ÍŽÌ¾Ì•Í  OÌ´Í™Ì¼ÌŸÍŒÌ•ÍFÌµÍ–Ì™Ì€ÍŒÌˆÌÍœ MÌ´ÌžÌ™ÌºÌÌ“Í›YÌ´ÌªÌÍšÌ¿Ì½Ì• HÌ¸Í–Í“Ì¦ÍŒÍŠEÌ¸Ì¢Í”Í’ÌAÌ¸Ì¢Í•Í•Ì½Ì•DÌµÍ‰Ì¼ÌºÍÌ€Í’ Ç´Ì¸Ì¡Í“Ì¦ÍÌ”Ã‰Ì¸Í–ÍŽÍ‡Ì“TÌ¸Ì˜Ì™Ì™ÌˆÌÌ“Í OÌ´Ì™Í”Í•Í›Í‘Ì¾UÌ¸ÍŽÌŸÌ¿ÍŠÍTÌ´ÍÌžÌžÌ¾Í‹ÍŒ OÌµÍÌºÍšÍ›ÍŒFÌµÌªÌ¼ÌžÌ€Ì“Í MÌ´Ì«Ì˜ÌŸÌ“Í›ÍÅ¸ÌµÍ•Ì¦Ì»ÌÍ›Í  HÌµÌ¼Í”ÍŠÌˆÌÍ ÃˆÌ¸Ì¡Í‰ÌºÌˆÌÌ•AÌ´Í•Í”Í”Í‹ÌÍ DÌ¸ÌŸÌªÌŸÌˆÌÌ“Ìš GÌµÌ»Ì»Ì“Í‹Ì•ÍœEÌ´Í™ÌºÍ‘Í˜ÍÈšÌ´ÍšÌ˜Ì½Í‘ OÌ´ÍÍŽÍÍŠÌ“ÍUÌµÍŽÍÍ›ÍÌ“TÌµÌ™Ì»ÍŽÌ¾Ì¾Í Ã–ÌµÌ™ÌªÌŸÌÌ“ÍFÌµÌ˜ÌÍ”Ì½Í˜Í MÌµÌ¦Ì»Ì¿Ì’ÍŒYÌ´Ì¢Ì»Í›ÍœÍ Í HÌ¸Ì¢ÌÌ»Ì€ÍÌˆÌEÌµÍ•Í‡ÌÍ’ÌÌ¿AÌ¸Í™Ì¼Í’ÍŒÍ DÌµÌ»Í”Í•Í’Ìš GÌ´ÌºÍ•Ì’ÍŒÍ EÌ´ÌžÍ•Í•ÍÌ¾ÍTÌ¸Í‡ÌªÍ™ÌˆÌÌ¾ÍŒ OÌ¸ÌºÌªÌ¦Ì“ÌˆÌÌˆÌUÌ¸Ì¡Ì»ÌžÌÌ“TÌµÍ‰ÌŸÍÌ“Í›Ì• OÌ¸Í‡ÍŽÌ˜Ì½ÍÍFÌ¸Í‡Í‡Ì»ÍŒÌˆÌÍ‹ MÌ¸Í‰ÌŸÍ”Ì¿Í›Ì€YÌµÍ™Í–Ì“ÌˆÌÌšÍœ HÌ¸Í‰Í“Í•Ì“ÍÍÃ‹Ì´Ì™Í™ÌÌ”Í†AÌ¸Ì™Ì«Ì™ÍŒÍ˜ÍDÌ´Ì™ÌŸÌŸÌ“Í›Í˜ GÌ¸ÌÌ Í–Í‘Ì€Ì”EÌµÍšÍŽÍ–Ì¾Í TÌ¸Ì˜Ì«ÌžÍ†ÌÌ” OÌµÍ‰ÍŽÍšÍŒÍ‘Í†UÌµÍ‰ÍŒÌ½Ì¿ÍœTÌ¸Ì¡Í–Ì»Ì“Ì•Í OÌµÌ¡ÌªÌªÌ“ÌˆÌFÌ¸Ì¦Í‡Ì»Ì“Ì’Í  MÌ´Í™ÌºÌ˜ÍÌ’Å¸Ì¸Ì»ÍšÍŽÌÍŒÌˆÌ á¸¦ÌµÌ ÍŽÍ‰ÌÌ¿Ì¾EÌµÍ“ÍÍ”ÍÍ‹Ì€Ã„Ì´Ì˜Ì¦ÌÌ”ÍœÍ DÌ¸Ì¢Í–ÌªÍ‹ÌšÍ  GÌ¸Í‡Í”Ì¼Ì“Í’Í‹EÌµÌ™Ì ÍŽÌ“Ì•TÌµÍŽÌ»Ì«Í‘Í’Í˜ OÌµÍ‰ÍšÌ™Í›Ì’ÍÇ—Ì´Ì¢Ì¡Ì«ÍŒÍTÌ¸Ì¡Í•ÌžÌ¿Í›Í˜ Ã’ÌµÍ‰Í‡Í–Ì¿Í˜FÌ¸Ì¦ÍÍÌˆÌÍ’Í  MÌ´Í™Í™Ì˜Ì€Í˜ÍYÌ¸Ì˜Í–Ì¼Ì¿ÍŒÍ HÌ¸ÌžÍšÍ•Ì“Í’ÍÃ‹ÌµÌ˜ÌºÌŸÌÍÍ‘Ã€ÌµÌ¡Í“Ì»ÌˆÌÍDÌ¸Ì»Í‡ÍŽÌˆÌÌ”Í˜ GÌ¸Í™Í™Ì™Ì¿Ì½Í†EÌ¸Í•Ì˜Í†Í†Ì•ÍœTÌ´ÌªÍ–Í•ÍŠÍ›Í† OÌµÌ«ÌžÌžÍ Í ÃšÌ¸ÍšÌºÌŸÍ‘ÍTÌ¸Í–ÍÍ‰Í‹Í‹ OÌ¸ÍšÌ™ÍŠÌ’ÍFÌ´Ì«ÍŽÍŠÍ MÌµÌ¡Í•ÌªÍŠÌšYÌ´Ì¦ÌžÌªÌ“ÍŠÌˆÌ HÌ¸Ì¢Í’Ì½ÍœÍEÌµÌ¡Ì¼ÍÍ‘Ì¿Ì¾AÌµÍ“ÌŸÌŸÌ“Ì½Í˜DÌµÌŸÌ»Í”Í›Ì½Ì GÌ¸ÌÍŽÌ¦ÍÍ†ÃˆÌµÌ¡ÍŽÌ¼Ì½Ì¿TÌ¸ÌŸÍ”Ì Ì“Ì“Í˜ OÌ´Ì¢Ì¡Ì Ì’Í’Ì€UÌ´Ì¡Í‡Í™Í‹Ì”ÍŒTÌµÍÌžÍ•Í›ÌÍŒ OÌ´Ì«ÌŸÍ‡Í†Ì½ÍFÌµÍ”Í‡Ì’ÌÍ‹ MÌµÌ¢Í•Ì¦Í‘ÌˆÌÍ˜YÌ¸ÌŸÍ•Ì½ÌÌ•Íœ HÌµÌ¡Ì¦ÍŽÌÍ’Ì•EÌ¸ÌžÌ«Í‡ÍŠÍ›AÌ´Ì™Í“ÍÍ‘ÌÌ½DÌµÍ”ÍšÌ½ÌÌˆÌ GÌµÌ¡Í•ÌºÌ’ÌˆÌÍEÌµÍŽÍšÍ†Ì½Í‹ÍœTÌ´ÍšÍŽÍŽÌˆÌÍÌ€ Ã“ÌµÍÍ‡Ì«Í†Í›UÌµÌ¡Í™ÍŽÍÌˆÌÌšTÌµÌÌ ÍÌ“Ì” OÌµÍ•ÌªÍÍÍ’Ì”FÌ´ÌºÍ‡Ì«Í†ÌšÍ MÌµÌ™Ì«Ì»ÍÌ€Íá»²Ì´Ì»Í–Í‡ÍÌ¿ HÌ¸Ì¦Í“Ì«Ì¾Ì¿EÌ´Ì¢Í“Ì™Í‹Ì¿Ì•Ã„Ì´ÍÌŸÌÌ“Ì½DÌµÌ™Ì Ì¼Ì“ÍŒÌ½ GÌ´Í‡ÍÌžÍŒÍÌšEÌ¸Ì¡Í”Í™Í‘Ì“ÌšTÌµÌžÌªÍŽÌ¿Ì¿Í‹ OÌ´Ì¡Í“ÌªÍŒÍÍ Ç—ÌµÌ¢ÌªÍ•ÍŒÍ†TÌ¸Ì¡ÌÍ–Ì“Ì’Í˜ Ã–Ì¸Ì™Ì˜ÌÌˆÌÍFÌ¸Í•Í–ÌªÌ“Ì• MÌµÌ¢Í”ÌÍ’ÌˆÌÌ“ÃÌµÌ¡Ì˜Í› HÌµÌ¼ÌºÍšÌ•Í Ã‰Ì´Ì¼Í‰Í•Ì€Í‘AÌµÌ˜Ì¼Í”ÍŒÌ’ÍŠDÌ´ÌÌŸÍ™ÌÍ›Ì GÌ¸Í”ÍŽÍ’Ì½ÍEÌ´Ì¢ÌžÌÍ›Í˜ÍœTÌ´Ì˜Í‰Ì ÌÌ“Í˜ OÌ´Í“Ì˜Ì˜ÍÌ“Í’UÌ¸ÌŸÍ™ÍÍÍ TÌ´Ì«ÍÌŸÍ‹ÍÍ› OÌµÌ¡Ì™Í“Ì“Í›Í˜FÌ¸ÍšÍ‡Ì¦ÌˆÌÍŒÌˆÌ MÌ¸Ì¼Í™Ì¦Ì¾Í›Í YÌ´ÌŸÌ¼Í‰Ì½Ì”ÌˆÌ HÌ´Ì˜Í“Í“ÍŠÍÍ†EÌ´ÍŽÌ¦Ì¼ÍŠÍAÌ´ÌªÍ‡Í™Í†Ì“ÍDÌ¸Í“Ì¼Í”Ì¿Í Í  Ç´ÌµÍ™ÍÌ»Ì“EÌµÍŽÌžÌ Í†Ì“ÍTÌ´Ì¢ÌªÌªÌˆÌÍŒÌ¾ OÌ´Í•Ì«ÍÌ€Ì•ÍœUÌ´Ì¢Í•Í“Ì“ÌˆÌÍŠTÌµÌ¡Ì¡ÌªÍÍ‹ OÌ¸Í“Í“Í†Í‹ÌˆÌÍœFÌ´ÍšÌÍ†ÌˆÌÌš MÌµÌ«Í‡Ì¼Í†Ì•YÌµÌ¢Ì¢Í‡ÍÍŠÍ† HÌµÌ¢Í“Ì¾ÌÌšÍœEÌµÌ Ì¼ÌŸÍŠÌ“Ì“AÌµÍ‡Í‡ÍŠÍ›ÍŒÍœDÌ¸Ì¡Í”Ì¿Í‹Ì¿ GÌµÌ¡Í‡Ì»Ì¾Ì’Í‹EÌµÌ¦Í‰Í‰Í‹Ì’Í‘TÌ¸Ì¢Ì Ì™Ì’Ì”ÍŒ OÌµÌ™Ì ÍÍÌˆÌÌ”UÌµÍ–Ì˜ÍÍÍTÌ¸Ì˜Ì™ÌŸÍ‹Ì½Í† OÌµÌ¡ÍŽÍ‰Ì¾Ì½ÌˆÌFÌ¸Ì¢Ì¢Ì¡ÍÍ›Í MÌµÌªÌ™Í‰Í†Í†YÌµÌ¡ÍšÌ“ÌÍ HÌµÌ¦Í•Í‡ÍŠÌ•ÍÃ‹ÌµÌ¢ÌºÌ«ÌÍ‘Í˜AÌ´Ì˜Ì¦Í‡ÍŠÌ’ÍDÌ¸Í–Í‰Í“Ì“Í˜Í GÌ¸Ì«Í‡Í“Ì”Ì¾ÌˆÌEÌ´ÍÌ™Ì»Ì“ÍŒÌTÌ´Ì«Í‰ÌˆÌÌ’ÍŒ OÌ´Ì¼Í‡Í˜Í ÍUÌ¸Í‰Í“ÌŸÌÍ‹Ì•TÌµÌ¢ÌªÍ–Ì•ÍÍ OÌ´ÌªÌ«Ì“Í‹ÌˆÌFÌ´Í‰Ì ÍšÍ†ÍŠÌ’ MÌµÌ«Í‰Í–Í’ÌÌšYÌµÌ˜Í™Ì˜Ì¿Ì HÌ´Ì¡ÍŽÍ‡Ì€ÌˆÌÌšÃˆÌ´Í‰Í‡Ì½Ì€ÍœAÌ´Í‰Í‡Ì Ì¾Ì“Í DÌ´ÍŽÌŸÌ¦Ì“Ì“Í GÌµÍ™ÌÌ½Ì“Í‘EÌµÌŸÌÌ¦Í›ÍŠÍŒTÌ´Í•ÌºÌ˜ÍŒÍÌ½ OÌµÌ¢Í‡Í”Ì’Í‹ÍUÌ´Í™ÌžÌ’ÍÍÍœTÌ¸ÌŸÌ»Ì¦Ì’Í‹Ì OÌ¸Í™ÌºÌ™Í‹Í‘ÌšFÌµÍ–Í‰ÌºÌ¾ÌˆÌÌˆÌ MÌµÌ¢ÌªÌ™ÍŒÌ“Ì½YÌµÌ¡ÌºÌ«Í‘Ì•Í HÌ´Í‡Ì Í‰Í†Ì¾ÍEÌµÌ¡Ì¡ÌžÍ’Ì½Ì¿AÌµÌ¼ÍšÍ‡Ì’Ì“Ì“DÌ¸Ì Í‰Í‰ÍŒÌÌˆÌ GÌ´Ì¢Ì»ÌºÍÍÃ‹Ì´Í™Í”Í™ÌÌ”ÍTÌµÍ‡Ì˜Í”Ì”Í‹Í Ã–ÌµÌ¡ÌºÍ‡ÌÌ“ÍŒÃ™Ì¸Í”Ì™Í•ÌÌšTÌµÍ‰Ì¼Ì ÍÌ“Ì¿ OÌ´ÌªÌŸÍ•Ì’Í†ÍFÌµÌ˜Ì˜ÌÌÌ•Í MÌ¸Ì¼Ì«Í›Ì”ÌˆÌÃÌµÍšÍ‡Í‡Í†Ì HÌ´ÍšÍ“ÍÍ†ÍÌšEÌ´Ì¢ÌªÍ”Ì“Í ÍAÌ´ÌÌ¦Í‡Í˜Í DÌ´Ì ÌŸÍ’Ì”ÍŒ Ç´Ì¸Ì»Í’Ì•ÍœÃ‰Ì¸ÌªÍ™Ì˜Ì¿Í TÌµÌ¡ÌªÍÍ‹Ì“Í Ã’ÌµÌÌ¼Ì ÍÍUÌ¸ÍÌ“Ì½ÌšÍœTÌ´Ì Ì˜Í›ÌšÌš OÌ´Ì¼Ì«Ì™Í‘ÌÍ›FÌ´Í™Í‰ÍÌ•Í  MÌ¸Ì ÍŽÌºÌ“Ì¾Í˜YÌµÍ‰Í–Ì”Í›ÍœÍ  HÌ¸Í™Í•Ì»Í‹Í‹ÌˆÌEÌµÍšÍ•ÌžÌÍ†Í‘AÌµÌºÍšÍ‘ÌÍDÌ´Í™ÍÌªÌ’Í‹Ì GÌ´Ì™Í–Ì¼Ì€Ì”ÌˆÌÃ‹Ì¸Í•ÍšÍ”ÌÌ“Í›TÌµÌ™ÌºÌˆÌÍ‘Í˜ OÌ¸ÍÌ»ÌžÌ½ÍŒÍ†UÌ´Ì¦Ì¼ÌºÌ“ÌˆÌTÌ¸Ì¡Ì˜Ì“Ì€Í˜ OÌ´Ì ÌºÍšÌ½Ì’ÍFÌ´ÍÍ‡Í™Ì’Í MÌ¸ÌŸÍ“ÌžÍ›Ì•ÃÌ¸ÌÍÌ™ÍÍ HÌ¸Í“Ì Ì Ì”ÍŒEÌ¸ÍšÌ«Í”Í†Ì•ÍAÌ´Ì¡Í“Í™Í›ÍŠÌšDÌ¸Í‰Ì¦Ì“ÌÌ¿ GÌ´ÍÌ˜ÌžÍÍ†Í˜Ã‹Ì´Ì¼Í™Í™ÌÍTÌ´Í–Ì˜Í™ÌˆÌÍŒÌ’ OÌ¸Ì ÍÌ˜ÌÌˆÌÍ‘ÃšÌ´ÌžÌºÌªÍŒÍ TÌ´ÌžÌŸÍ‹ÍÍŒ OÌµÌ¼ÌºÌ¾Ì’FÌµÌ¢Ì»ÌžÍŒÌ€ÍŠ MÌ¸Ì¡Í‰Ì’ÌÌ“ÍœYÌµÌ¦ÍšÌ“Í‘Ì“Íœ HÌµÍ•Í•Ì˜Ì“ÍŠÍ‘EÌ´ÌºÍ”Í“Í’Í†AÌ¸Í‰Í•Ì Ì¾ÌšÌšDÌµÍ“Ì¼Ì”ÍŒÌ¿Íœ GÌ¸Ì¡Í™Ì»ÍŠÌ¾Í˜EÌ´Ì¢Í•ÌžÍŒÍÌˆÌTÌ¸Í“Í‰ÌºÍÌ’Ì“ OÌ´ÌªÍšÌžÌ¾Ì“ÍUÌ¸ÍÍ™ÌŸÍŒÌ’TÌµÍ‰ÍÌŸÌˆÌÌšÍ  OÌ¸Ì¡Ì¦Í“ÌÌ¿ÌFÌ´ÌžÌªÍ’Ì¿Ì¾Íœ MÌ´Ì¢Í‡Í†Ì’Í˜YÌ´Ì˜ÌŸÍŠÌ¾Ì HÌ¸Ì˜Í”ÌŸÍÍ†ÌšEÌ´Í–Í–Ì«ÍÍ’ÍAÌ´Ì˜ÌŸÌžÍ‹Ì½Í›DÌ´ÍšÍ“Ì¿Ì•Íœ GÌ¸Í‰ÌŸÌ˜Ì¾Í›Ì”EÌ¸ÌÌ¼ÌÌ¾ÌˆÌÌ€TÌµÍšÍ‡Í–Ì€Ì“Í OÌ´Ì¡Í“ÍšÌ“ÌˆÌÍUÌ´ÍŽÍŽÌ¦Í†Í‹ÍTÌ¸ÌžÌªÍ“ÌÌ’Í  OÌµÍšÌ»Í‹Ì¿ÍÍœFÌµÍ“ÌºÌ˜Ì¾Í’Í MÌµÍŽÌ™Ì¦Ì¾Ì”Ì’YÌµÌ¢Í™Í•ÌÌˆÌÍ’ HÌ´Í‡ÍŽÌ¦Ì“Í†Ì’EÌ´ÌžÍ•Ì¦Ì’Ì½Í›AÌ¸Ì¡Í‰Ì«Ì¿ÍŠDÌµÌ¢Í‰Í‘Ì”Í‘ GÌµÍŽÍ”Ì«Í›Ì½ÍEÌµÌ¡ÌªÍ‰Ì¿Ì”ÌˆÌTÌ´Ì¡Ì Ì˜Í›Ì OÌ¸Í–ÌÍ™Ì”Ì’Í˜UÌ´Ì ÌªÍ–Ì”Ì€ÌˆÌTÌ¸ÍšÌ¦ÌªÍ›Í˜Í OÌ´Ì¢ÍÍ™ÍŒÌ“ÌšFÌ´Ì™ÌŸÌˆÌÌÍ˜Íœ MÌ¸Í™ÍŽÍ™ÌˆÌÌ’Ì½ÃÌ¸Í–Ì¦Ì¦ÌˆÌÍ˜ HÌµÌ¡Ì¼Í›ÍŠÌšÍœEÌ¸Í–Ì Ì˜Ì¿ÍŒÍ›AÌµÌºÍ–Ì˜ÌÌ¿Ì•DÌ¸Ì¼ÍÍ†ÌÍœ GÌ¸Ì™Í–ÌžÌÌ¿Ì’EÌ´ÌžÌªÍ“Í’Í‘ÍÈšÌ¸ÌžÌ ÍÍ˜Ì• OÌ´ÌªÌ¼Í–Í‹Í’Ì’Ç—ÌµÍšÍÍ‹ÍœÍ TÌµÌ«Ì™ÍŠÌ’Í˜ OÌµÌ¡Í‡ÍšÍ›ÍÍ FÌµÌŸÌ¦ÌÌ”Ì€ MÌµÌ™ÍÌ¦Í‘Ì“ÍYÌ¸Ì˜Í‡Ì«Ì¿Í†Ì½ HÌ¸Ì»Í™Í–ÌÍ’Í˜EÌ¸Ì¼ÌŸÍ’ÍŒÌAÌµÌ¡Ì»ÌÌ“Í Í DÌµÍÌžÍšÍÍ GÌµÌ¢Ì¡ÍŠÍŠÍœÍ EÌ´ÌªÌºÍ•Ì“Í˜Í TÌµÍÍšÍ™Í‘Ì¿Í‘ OÌ¸Ì Í–ÍÌ¿Ì“Í˜UÌµÍ–ÌÍ‹ÌÌšTÌ¸Ì¢Í‰Í‡ÌÌ OÌ¸Ì«Í–ÍŠÌ€ÍœFÌµÌºÌžÌ«Í’Ì MÌµÍ”Í‡Ì«Í‹Í YÌ´Ì«Í‰Ì“Ì• á¸¦ÌµÍ”ÍÌÍ˜Ì•EÌµÌ™ÍŽÌ•ÍœÍ Í AÌµÌŸÍÍ’ÌˆÌÍ˜DÌ¸Ì¢Í“Í‹ÍŠÌ½Íœ GÌ´Ì¦Ì¼Ì¿Í›Í†ÍœEÌ´ÌªÍŽÍ”Ì¿ÌˆÌÌšTÌµÌ»ÌÌÌˆÌÍ  OÌ´Í‰ÌÍ“Ì¿ÍÍUÌ¸ÌºÌ»Ì“ÍŠÍœTÌ¸Í‡ÌŸÍÌ“Ì½ÍŒ Ã“ÌµÌªÌªÌÌ“Ì¿FÌ¸Í–Ì¼ÌªÌ¿Ì“Ì• MÌµÌªÌ«Ì˜Ì“Ì”ÌYÌµÌ»ÌžÌÌÍÌˆÌ HÌµÌ¡Í”Í“Ì’Í Í EÌ¸Í”ÌŸÌ™Í’Í AÌ¸Í”Ì Í‘ÍŠÍœÍDÌ´ÌºÌªÌ»Ì½Ì’ÌˆÌ GÌµÍŽÍ•ÍšÍ›Í’EÌµÌ¼Í‡Ì’Í›Ì”ÍœÈšÌµÌ¢Í‰Í’Ì“ OÌ´Ì¡ÌŸÌºÌ”ÌÌšUÌµÌ»Í–Ì»ÍÌ“ÌˆÌTÌµÌŸÌÍ–Í†Í’Ì OÌ´Ì¡ÌŸÌ¼ÍŒÌÍFÌ¸Í•ÌžÌ™Ì“Í  MÌ´Ì«ÍÌ ÍŠÌ”Í˜YÌ´Ì˜Ì¼Í•Ì¾Ì”Ì’ HÌ´Ì¢Ì Í•Í‘Ì•ÍÃ‹Ì¸Ì¡Ì™ÍŽÌÌšÍÃ„Ì´Í‡Ì«Ì»ÌÍÍDÌ´Í”Í†Í›ÍœÍ  GÌ¸Ì«Í“Ì“ÌˆÌEÌ¸Í‡Ì»Ì»Ì’Ì¾Í‹TÌ¸ÍšÍšÌˆÌÌ¾Ì“ OÌ¸Í•ÌªÍ‹Ì“ÍœÍ UÌ¸Í‡ÍŽÌ Ì“Í‘ÌšTÌ´Ì¡ÌžÌ˜Ì”ÌÌˆÌ OÌ´Ì¢ÌÌŸÌ“ÍŒÍFÌµÌºÍ•Ì˜ÌˆÌÌ•Ìš MÌµÌ Í•Ì¼Ì½Ì¿ÌšYÌµÌ¼ÌªÍ’Ì“Í á¸¦ÌµÍ™Í™ÌªÌÍÌ•EÌ¸Í‡ÌÌ’ÌÌ¾AÌµÌ¢ÍŽÍ“Ì”ÌšDÌ¸ÌºÍŽÍ™Ì”Í›Ì¾ GÌ´Í™Í•ÍŠÍœÍ EÌµÍ‰Ì»Ì¦Í›Í˜ÍÈšÌµÌ»Í‰Í†ÍŒÌ€ OÌ´Í™Í•ÍŽÍ’Ì“ÍUÌ´Í“Ì¼Í“Í‘Ì“Ì’TÌ´ÌºÍ“Í‡Í†ÌÍŠ Ã“Ì´ÌªÌ ÍŽÍÌšFÌµÌ¢Ì¡Ì¡Ì¿Ì”ÌˆÌ á¸¾ÌµÍŽÍ‰Ì»ÍYÌµÌ¢Ì¼ÍÌ•Íœ HÌ¸Ì¡Í–ÌªÍŠÍ‘EÌ´Ì¢Ì™Ì¦Ì½ÌAÌ´Í”Ì»Ì¿Ì•DÌµÌ«Í“Ì¿ÌÍŠ GÌ¸ÌªÌ»ÌÍ’ÌEÌ´Ì¡Ì¢Í‡ÍŒÌ¿Í†TÌ´ÌÍŽÌˆÌÌÌ“ OÌ´Ì¢Ì«ÌªÍ†Ì“ÌUÌ´ÌÌ˜Ì˜Ì¾Ì“Ì¿TÌ´Í‡Í”Í˜Ìš Ã’Ì´Ì»Ì˜ÌŸÌ”Í›FÌ¸Ì¢ÌžÌªÌÌÍ  MÌµÌÍ•ÌªÍ’ÍÌ’YÌ¸Í•Í”Ì™Ì“Í†Í˜ HÌ´Ì™Ì ÌºÌ“Í‘ÍŒEÌµÌ¢Ì»Ì¦Ì¾Ì•AÌ¸Í“Ì»Ì™ÍŠÍ‘Í†DÌ¸Ì˜ÌŸÌÍŠÌ• GÌµÌÌÍ™ÍÌ’Í›EÌµÍ‡Ì¼Ì˜Í‘Í‹ÌšTÌ¸ÌŸÌ¦Í‡ÌˆÌÌ“ Ã–Ì¸Ì˜Í‰ÍšÌÌ€Í˜UÌ¸Ì»Ì Í–Í‹ÍŒÌTÌ¸Ì»Í“Ì»Ì€Ì¾Ì½ Ã’Ì¸ÌºÍ–ÌŸÍ†Ì¿FÌ¸Ì¢Ì»ÌªÍ’Ì“Í MÌµÍ•Í™Í™ÌÍ†Í†YÌ¸Í‡ÌžÌ™Ì“Ì•Ì• HÌ´Í™Ì¼Í›Ì”Ì¾EÌ´Ì«Ì¼Ì¦Ì¾ÌÍ‹AÌ´Ì¢Ì¢Í–Í†ÍŒÍDÌ¸Í•Í™Ì»Ì¿Ì¾Í GÌµÌ™Í”Í‰Ì½ÍŒÍ˜Ã‹Ì¸Ì¢Ì¦ÌÌ“Ì€TÌ¸Ì¼ÍÌ Í‹ÍÍ  OÌµÌ¼Ì«ÍŽÍŠÍŒÌ•UÌµÌŸÍ•Ì»Ì½ÌˆÌÌ•TÌ¸ÌžÌºÌªÍ‹Ì½Ì’ OÌ¸Ì¢Í™Ì«Í‹ÌÌ½FÌµÌ Ì˜Í•ÌÌˆÌÌ¿ MÌ¸Ì Í‰ÍšÍ‹Í‘ÍYÌ¸Ì¢Í‡Í•ÍŒÌ½Í HÌ´ÍšÌ™ÌªÍ’ÌÍ†EÌµÍ•Ì¦Í•ÍŒÍŒÌ”AÌ´Ì¦Ì™Ì¦Ì¾ÍŒÍDÌ¸Ì˜ÍÌ€ÌˆÌÍ GÌ¸Í–ÌŸÌˆÌÌ¿ÍœÍ EÌµÌ˜Í‰Í’ÌˆÌÌ¾TÌµÍ–Ì»Í‡ÌÌ’Ì¿ OÌµÌžÌ»Ì¾Ì“ÍœÍÇ—ÌµÌ¡ÍÌÌÍ˜TÌµÍ‰Ì¼Í™Í’ÍŒÌ• Ã“Ì´Ì™Ì™ÍœÍ ÍFÌ¸Í™Í‡ÌÍ‹Í†Í  MÌµÍ”Ì™Ì»Ì”Í†Ì½YÌµÌ¡Í”Ì™Ì“Í’ HÌ¸ÍšÌžÌªÍ†ÍŒÌ•EÌ´ÍŽÌŸÍ‹ÌˆÌÍAÌ´ÌÌÌºÌ’ÌˆÌÍDÌ¸Í‡ÌŸÍšÍÌšÌ• Æ¯Ì´Ì›Ì­Í‡Ì–Í”ÍˆÌŸÌÍ“Ì¼ÌÌ“Í‚Í‹Í—ÌˆÌ“ÍŠÍ‹Í˜ÍÍÍ SÌµÌ«Ì²ÍŽÌ¬Ì¯Ì¦Ì«Ì»Ì»ÍÍŽÌŠÍ‚ÍŠÍŠÌ‡Ì’Ì…ÌšÍ!Ì¸ÍšÍÌ„Í‹ÌŽÍÍ›ÌÍ›ÌŽÍ˜!Ì¶Ì¯Ì¦Ì–Ì–Ì€ÍÍ—Í !ÌµÌ«Í•Ì³Ì¯Ì¤Ì˜Ì¥Í‡Ì€ÍŒÍ—ÌÌ€Ì‚Í’Ì•!Ì´ÌºÍ‰Ì­Ì£ÌŸÌ²ÌžÍŽÌœÌ‡Í›Ì“Ì‘Ì€Ì‡Ì¿Ì‚ÍÍ… Ì·Í™Ì¯Í”Í†ÌÌ‘Ì‰Ì¾ÌŽÌˆÌ½Ì…Ì…Í Ì¶Ì®ÍšÍ‰Ì±Ì™Ì¥Í‰Ì„Í‹Ì‰ÍŠÌ…ÌÌÍ‹Ì‚Ì‹Ì’ÍÍ Í…â£¿ÌµÌœÌˆÍ›Ì‚Ì’Ì“Ì’Í˜ÍÍ â£¿Ì·Ì§Ì±Ì¯Ì‘Í˜ÍÍâ£¿Ì·Ì¬Ì¥Ì¬Í†Í‹Íâ£¿Ì¶Ì¡ÌŸÌ¯Ì¦Ì¼Í“Ì˜Í”Ì‘Í›ÌÌŒÌ¿Ì‹Ì‚Í’ÍŒÌšÌšÍâ£¿Ì´Ì¨Ì§Ì¼Ì¦Ì²Ì¥Ì¤ÍŽÌÌŽÌ¿ÌÌÍ†Í’Ì€Í—Í˜â£¿ÌµÌ˜Ì—Ì¥Ì±ÌÍ‚Í›Ì“Ì¾ÍœÍÍâ£¿Ì´Ì–ÌžÌ±ÌÌ¬Í‘Í›Í—ÌŽÍÌ½Ì€Í—ÌŽÌ•Í˜ÍÍ â£¿Ì·Ì¯Í‡ÌœÌŸÌŸÌ®Ì©Ì±Ì³ÌÌ®Ì©Í“ÌÌŒÌÍ‹ÍŠÌ•â ŸÌµÌ™ÌžÌ³Ì«Í‰Í‰Ì¦Ì³Ì¤Ì¬Ì¬ÍŠÌÌ¿Ì†Ìâ ‹Ì´Ì¢ÍšÍ‰ÌÌ³Ì™ÍˆÍ“Ì Ì¦Ì­Í™Ì–ÌŽÌÌÍ—Í’Í‘Í‘Ì“Í‹Ì”ÌˆÌÍœâ Ì¶Í™Ì—Í“Ì¬Ì¾Í†ÍÌ‡ÍÌÌ“Ì¾â „ÌµÍˆÌ«Ì»ÌªÌ—Ì±Ì Ì¥ÍˆÍÍÍŒÌ€ÌÌ…Ì‡Ì…Ì‹Ì“Ì…Í‚ÍŠÌ€â „ÌµÌ Í–ÌÌ±Ì—Ì‡Í†Ì‡Ì‚Ì”Ì“Ìšâ „Ì·Ì¥Í”Í–Ì°Ì£Í‚ÌˆÌÌƒÌˆÍ’Ì‹ÍŠÍ›Ì…Ì•Íâ „ÌµÌ¤Ì¬Ì–Ì®Í–Ì³Ì»Ì»Ì»ÍŽÌŠÌ‹Ì“Í‘Í‚ÌˆÌÌ‘ÍÍ Íâ „Ì·Ì§Ì¡Ì®Í“Ì°Í“Ì©Ì™Ì¤Í‰Ì Í“Í‡Ì¦Ì¯ÌˆÌ•â „Ì¸Í‡ÌºÌ«Ì‰ÌˆÌÌƒÌ‚ÌÌ”ÌƒÌŒÌ‰Í˜Íâ „Ì¸Ì¨Ì§ÍˆÌºÍ“Ì¯ÍšÌÌ˜Í™ÌÌ»ÌºÌ—Í™Ì”ÌŽÌ’ÍÌ‘ÌÌšâ „Ì´Ì–Ì¬Ì•â ™Ì¸Ì¢Í“Ì»Ì¥Ì£Í‘ÍœÍ…Í…â¢¿Ì·ÌÍœâ£¿Ì¸Ì¢Ì¡Í™Ì¹Ì©ÍÌ±Ì Ì³Ì«Ì€Í‹Ì…Ì’ÌˆÌÌÌ‘Í…â£¿Ì¶Ì¼Ì™Ì—Ì¤Ì¹Í•Ì”Ì”Ì½ÌÌ€Ì‚Í‹Ì¾Í—Ì„Í‘Ì‡Ì“Ìšâ£¿ÌµÌ«ÌªÌ‚ÌÌ½ÌÍ˜â£¿Ì·Ì°ÍŽÌ¬ÌªÍšÌ€ÌÍœâ£¿Ì·Ì¨ÍÍ‰ÍšÍšÌ²ÌˆÌÌ“Ì‡ÍÌŽÌ‚Í‘Ì€ÌŽÌ•ÍÍâ£¿Ì¶ÌžÌÌ‰Ì‚â£¿Ì·Ì§Ì›Ì‘Ì‹ÌˆÌÌÌƒÌŽÍ’Ì†ÌÌ†Íâ£¿Ì´Ì§Ì—Í–Í™ÌºÌªÍ”ÍŽÌ¯Ì“Ì€Ì“Ì¾ÌÌÌÌ€Ì¾Í›Ì”ÌÌ‚Í… Ì·Ì›ÍšÌ°ÍŒÌ‡ÌƒÍ‚Ì‰Í†Ìšâ£¿Ì¶Ì›Ì¯ÍŽÌ³Ì»Ì ÌÌ¦Ì˜Ì°Ì€Ì”ÌŽÍŒÌˆÌÌ¾ÌÌ“ÍŠÍ‹ÌšÍœÍÍ…â£¿Ì¸Ì¢ÌŸÍ”Ì¼ÍÍ–ÌÌ³Í‘ÌÍÌ‚Ì¾ÌÌ’Í‘Ì€ÍÍ…â£¿ÌµÌ®Ì­Í‡Ì¯Ì–ÍÌªÌ±ÌœÌºÌ€Í‘Í—ÌˆÌÌÍ˜ÍœÍ â£¿ÌµÍ‡ÌŸÍ•Ì³ÍŽÌ»ÌŸÌ¼ÍˆÌ¥Í‰Ì°ÌŠÌ”ÌÍŒÌ½Ì½Í’Ìâ£¿Ì´Ì¡Ì£ÍÌÌŸÌœÌ²Í‹Ì¾ÍœÍÍ â£¿ÌµÍ‰ÍŽÌ¥ÌžÍˆÌ¹Ì²Í™ÍˆÌ®Ì³Ì¬Ì“Í‹Ì‰Í’Ì”ÌšÍ˜Ì•â¡ŸÌ´ÍŽÍ”Ì©Ì˜ÍŽÍšÌ¬Ì©Ì³Ì¯Ì„Ì¿ÍŠÍ›Í‘ÍŠÍœÍœâ Ì´Í“Ì«Ì—ÌˆÌÍŒÍÌ“ÍŒÍ â „Ì·Ì¡Í’ÍÌƒâ „Ì¶Ì¨Ì¢Ì¡Í‡ÌœÌ“ÌÌ…Í‘ÌˆÌâ „Ì·Ì§Ì—Ì«Ì¬Ì®Ì¬Ì‹ÌƒÌ†Ì½Ì€Ì‘Ì½Í‚Ì•â „Ì¶Í”Ì°Ì–Í‚Ì„ÌÌ€Ì‚â£ Ì´Ì–ÌŒÌšÌ•â£¤Ì´Ì¨Ì§ÍŽÍ™Ì™Ì–Ì£Í“Ì—ÌºÌ¹Í‰Ì˜Í–ÌªÍÌ’Ì‡Í‚Ì¿Í‘Ì€Ì¿Í—â£´Ì¸Ì±Ì—Ì©ÌŸÍ“Í™ÍŒÍ‘ÌŒÌƒâ£¶Ì´Ì›Ì¼Ì”ÌŽÌŽÌ‹ÍŠÍŒÌ“Ì•Í Íâ£¶Ì¶Ì³ÌŸÍ“ÍšÌ«ÌªÌ»ÌŸÍŽÌ–ÌÌœÍ‡Ì«Ì„Í†ÌˆÌÌˆÌÍ†ÌÌŽÌƒÌÌ€Íœâ£¶Ì´Ì›Ì¯Í‚Ì‘Ì„Ì¿Ì‹Í â£¶ÌµÍÍ“Í“Ì™Ì£Ì®Ì™Ì™Í™Í‚Ì‰ÌÌ‰ÌÌ”Ì•â£¤Ì·Ì¨Ì¨Ì³Ì²Í•ÌÌ­Ì£ÌˆÌÍŒÌ“Ì’Ì€Ì“Ì€â¡€Ì¶Ì¡ÌœÌ±Ì®Í–ÍÌ¦Ì®Ì©Í™Í”Í‡Ì®Ì£ÌÌ¿ÍŠÍ‹ÌÌÌ•ÍÍ…â ˆÌ¸Ì«ÍÌ…Ì¿ÌÍÌ½Ì„ÌÍ‘ÌÌ“ÌŠÌšÍ˜Í˜â ™Ì´Í”Ì°Ì¥Í•Í–Ì£Ì™ÍÌ¬ÍŠâ¢¿Ì´Ì§Ì¡Ì¨Ì¬ÌªÌ¤Ì¼Í“Ì¥ÌžÌ¦Ì„Ì‘Ì“â£¿Ì¸Ì¢Í•ÌªÌ²Ì¤Ì«Ì«Ì­Ì¤Ì˜Ì¼Ì¤Ì¼Í—ÌˆÌÌ“Ì…Ì“ÌˆÌÌ†Í‘ÌšÍœâ£¿Ì¸Ì®Ì«Ì Í”Ì—Ì—Ì˜Ì˜Ì®ÌœÌ–Ì“Í…Í…â£¿ÌµÌ¬ÌžÌ£Ì­Í™Ì¤Ì±Ì‚ÌŒÍ’ÌÌ’Ì’ÍŒÍ˜â£¿ÌµÌ›ÍÌ±Ì±Í”Ì‰Í’ÌˆÌÌ¿Ì€Ì¾Ì’Ì¾ÌˆÌÍ†Ì‹ÍŒÌƒÍâ£¿ÌµÌ§ÌºÌ¯Ì—Ì¼Ì—Ì˜ÍŽÌ°Í›Ì’Í—ÍÍ Ì¸Ì Ì­Í•ÌÌ€Ì„Ì‘Ì‘ÌƒÌ¾Í‚Í˜â£¿ÌµÌ¹Ì¹Í‰Ì¥ÌžÌ¯Í‡Ì¹ÍˆÍ–Ì£ÍÌ±ÌºÍˆÌ‰ÍŒÌ’Í‹â£¿Ì¸Ì¨Ì¢Ì›Ì­Ì¤Ì­Ì­Ì˜Í”ÌªÌ¬Í”Í“Ì—Í•ÌˆÌ‚â£¿ÌµÌ¨ÍŽÌ—Í”Ì¦Ì°Ì¼Í“Ì¯Ì–Ì–Í•ÌºÌ—ÌºÌ”Ì¾Ì„Ìšâ£¿Ì¶Ì¥Ì˜Ì¬ÍšÌŒÌÌšâ£¿Ì´Ì¢Ì¬Í‰Ì˜Ì¹Ì³ÍšÌ¯Ì³Ì—Ì Ì®Ì»Ì±Ì€Ì€Ì“Í—Ì†Ì‰Ì‚ÍŠÍâ¡ŸÌ¸Ì¡Ì›Í”Ì˜Ì³ÍˆÌ–Í”ÍˆÍˆÍ–ÍŠÌŽÌÌ”Ì†ÌÍ‹ÌÍ‹Í Í Íâ „Ì´ÍšÌ°Ì³ÌœÌ¬Í“Ì±Ì—ÍšÌ²ÍšÌ”Ì‚ÌŒÌˆÍÌ€ÌÌŽÌ¿ÍŒÌ‘Ì•Íâ „Ì¸Ì¢Ì›Ì›Ì¥Ì²Ì˜Ì†Ì“Í‚Ì¿Ì¿ÌŽÍŠÌƒÌŒÌˆÌÍÍ…â „ÌµÌœÌ¼Ì…Í‚Ì…Ì‘ÌŠÌ“Ì‘ÌŽÍœâ „ÌµÌ¡Ì¨Ì›Ì°Ì­ÍŽÌ¥Ì—Ì–Ì—Ì¬Í–ÌÌˆÌÌ¾ÍœÍœâ „Ì¸Ì›Ì˜Í‰ÍˆÍ‹Í†Ì”ÌˆÌÌ‚â£¸ÌµÌ›Ì¦ÍˆÍ‰Ì‡ÌˆÍ‚ÌŽÌ¿ÌšÍ Íâ£¿Ì´ÌºÍŽÌ²Ì©Í™ÌœÌ»ÌœÌ³Ì€Íœâ£¿Ì¶Ì¨Ì§Ì›ÌœÌ«Ì£Í‡Ì¯ÌŸÌ½Ì“Ì…Ì‚â£¿Ì¶Ì¢Ì»Ì°ÍÌŽÍ—Ì€Í â£¿Ì¶Ì¢Ì¢Ì¢Ì›Ì›ÌªÍšÌ¯Ì±Ì Ì¥Ì±Ì³ÍˆÌ¼ÌˆÌ€Ì‹ÌŠÌ€Ì‚ÌˆÌ…ÍÍ â£¿Ì·Ì§Ì›Ì©Ì©Í‰ÌºÌ–Ì¥ÌÌ–ÌŸÌ£Í‚ÌˆÌŠÌÍ†ÍŒÌ¾ÍÌ‘Ì‹Ì’ÌÌ‘ÍŠÍœâ£¿Ì¶Ì¥Ì¥Ì£Í•Ì®Ì…ÍÍ‘ÍÌ¿ÌÌŠÌ“ÌƒÍ›Ìšâ£¿Ì¶Ì»Ì Í–ÌžÌ¹Í‹Ì…Ì¿ÍŒÌÍ›ÍŒÍÍŒÍ‚Í˜Í â£¿Ì·Ì§Ì¼Í™Ì–Ì™Ì€Ì‚Ì‰Í â£¿Ì¸Ì¦Ì¼Ì«Ì ÍÌ£Ì…Ì€Í…â£†Ì¸Ì¢Ì¢Ì²ÌºÌ£Ì¤Ì²Ì³ÌžÌ²ÍšÌ»Ì¦ÌŠÌˆÌÌ¿Ì€Ì“Í‚ÌÌ‘â „Ì¸Ì¨Ì»Ì­Ì¤Ì©Ì®ÍˆÌ»Ì˜Ì³ÌœÌƒÌ‡Ì½Ì½ÌˆÌÍ’Í‚ÌŒÌ¿ÍÍ…â ˆÌ´Ì›Ì¯Ì—Ì²ÍšÌ¥Ì±ÌºÍ™Ì˜ÍŽÍŽÍ–Ì¿Ì¿Í’Í‚Ì”ÌˆÌÍ‚Í’â£¿Ì¸Ì›ÌÍ”ÌÍ†ÌˆÌÌ”ÌˆÌˆÌÌ‚Í—Ì€â£¿ÌµÌ§Ì¢ÌŸÍ“ÌªÌ¦Ì°Í™Ì°Ì¤Í”Ì¥ÌªÍ“Ì¥Ì‚Ì…Ì†Í‹Í˜Í˜â£¿Ì¶ÌŸÌ¾ÌƒÍ’Ì€Í’â£¿Ì¸Ì¨Ì©Ì³ÍšÌ»Í‡Ì•ÍœÍ…â£¿Ì¸ÌºÌ¼ÌÌ”ÌŠÌÍÌŽÌ‘ÌŽÍ—Ì„ Ì·ÌºÌ€Ì„Ì†ÍÌÌÍ›Ì½ÌŽÌˆÌÌ•â£¿Ì·ÌžÌ™Ì­ÌžÌœÌ–Í™Í”ÌÌœÌ©ÌÌ®ÍšÍ—ÍŠÌ¾â£¿ÌµÌ³ÍŽÌ»Í”Ì—ÌÌªÌªÍÌ„ÌÌÌ½Ì‡Í‘Ì“ÍœÍÍâ£¿Ì¶Ì¡Ì¢Ì›Ì«Ì—Ì­Ì™Í“Ì¤Ì±Í“Ì©ÍÌºÍ“Ì¿Ì‡ÌÍ›ÌŠÌŒÍ‚Í˜ÍÍ â£¿ÌµÌ¢ÍšÌºÌ¦ÍˆÌ²Í“Ì³Í‡Í’ÌÌ†ÍÌ“ÌˆÌÌÌˆÌÌƒÌÍÌÌˆÌÍâ£¿Ì¸Ì®Ì™Í™Í“Í‡Í“Ì¼ÌŸÌ³Ì¼Í†ÍŒÍ—ÍŒÌ‘ÌÍ—Ì½Ì¾ÌŒÌ¿Íâ ÌµÍ”Ì˜Ì˜Ì³Ì©Ì“ÌˆÍ†Ì“ÌÌˆÌÍ‹Ì†ÌšÌšÍ…â „Ì¸Ì¼ÍˆÌŠÍ›Ì•ÍÍ…â „Ì·ÌžÌ»Ì»Í™Ì¾ÌƒÍœÍ…â „Ì¶Ì§Ì¬ÍÌ¬Ì°Ì–ÍšÌºÌ®Í“Ì¼Í–ÌÍ”Ìšâ¢€Ì¸Í“Ì™Ì²Ì¬Ì°Ì¤Ì³Ì£Ì™ÌœÌ˜ÍŽÌ¯Ì„ÌŒÌ¾Ìƒâ£´Ì´Ì¨Ì¨Í”Ì£Ì®Ì¼Í“Í‰Ì¼Ì¹Í˜â£¿ÌµÌ§Ì¬ÍˆÌ¤Í‡Ì¥Ì˜ÌŸÍÍŽÌ½ÌÌ“ÌŠÌÍÌ‹Ì‹Ì‹Ì“Ì¿Í˜ÍÍ…â£¿Ì¶Ì§Ì§Ì Ì™Ì™Ì®ÍšÌ­Í‰Ì„â£¿Ì¸Ì±Ì³ÌºÌ£Ì˜Í‰Ì¼Ì˜Í‰Í‡Ì“ÌŽÌ†Ì¿ÍÌ”ÌƒÌÌ€ÌŽÌ‚â£¿Ì·Ì§Í‰ÍšÍšÍ‰ÍšÌœÍ‰Ì³Ì±Ì«ÌŸÌ•â£¿Ì·Ì¨Í‰Ì¬ÌŸÌ¼Í‡Ì¯Ì™Ì°Ì«Ì©Ì†ÌÌƒÌˆÍŒÌ‡ÍŠÌÌÌ•Í Íâ£¿ÌµÌ¢Í‡Ì¥Í‡Ì«Ì¦Ì»Ì½Í’ÍŒÌ½ÍœÍ…â£¿Ì¸Ì¯Ì®Ì–Í‡ÍˆÍˆÌ²Í™Ì‡ÌˆÌÌŽÍ‚Í†ÍœÍÍ…â£¿Ì¸Ì°Ì©Ì˜Ì±Ì¹ÌÌ²ÍŽÌ—ÌªÌ˜Ì™Ì¼Ì¯ÍŒÌ‚ÍÌ‰Ì”Ì½ÍŒÌƒâ£¿ÌµÍ™Ì©Í”Ì ÌºÌ«ÌŸÌ Ì¾Ì†Ì€Ì‰ÍŠÌ„ÍŠÌÌ…ÌÌÍœâ£¿Ì·Ì¢Ì§Ì§Í•Ì™Ì ÌºÍ™Ì³Í”ÍˆÍ‰Ì¾Ì½Ì’ÌˆÌÌ‰Ì€Ì“Ì„Ì“Í›Ì“Í†ÌšÍœÍœÍœÍÍâ£¿Ì¸Ì«Í–Ì³Ì³ÌŸÌ¯Ì®Ì²Í™Ì»Ì£Ì¬Í•ÌˆÌÌŒÌ†Ì•ÍÍ…â „Ì·Ì¯Ì³Ì–ÍÌ™Ì­Ì¼Í–ÍÌÌ‘ÌÌˆÌÌÌˆÌÍœâ „Ì¶Ì£Ì²ÌªÌ“ÍŠÍ â¢ºÌ·Ì¨Ì¥Ì™ÌžÌ³ÍˆÍÌ­Í™Í“ÌŸÌœÌ²Í”ÌŒÌ‰Í‹ÌŠÌ’ÌŒÍÌ“â£¿Ì¸Ì§Ì§Ì›Ì³Í“ÍˆÌžÍˆÌ—Ì¹Í”Í™Ì¬ÌªÍ–Ì¹Í›Ì¾Í‹Ì…Í†ÌÍ‹ÌˆÌÍ‹Ì‹ÌšÍ ÍÍ â£¿Ì¶ÌŸÌ²Ì¯ÌˆÌÌ‘Ì’Ì€Ì‘ÌˆÌÌƒÌˆÌÌÌ•Í˜Íâ£¿ÌµÌ¢Ì¥Ì¦ÌªÌ³ÌœÍ“ÍÌ‹Í—Ì‹Ì‹ÍŒÌÌšâ£¿Ì´ÌÍ–Í‚Ì‰ÍŠÌ†ÌˆÌÌ“ÌˆÌÌ‘Í†Ì¿ Ì´Ì¡Ì£Ì«Ì¯Ì—Ì£ÍŽÌ¼Í‡Ì²Ì»Ì«Ì—ÍÌÌ€Ì“Ì€Í‹Í‹ÌˆÌÌšÍÍ…â£¿Ì·Ì¢Ì°Ì±Ì Ì³Ì©ÍŽÌƒÌ‹Ì…ÌÌÌÌÌ†Ì†ÌŠÍ˜â£¿Ì´Ì¢Ì–Ì³Ì˜ÌœÍˆÌ«Ì°Ì­Í“ÌžÌªÌ®Ì°Ì³ÍÍŒÌ‡Í›ÍŠÌÍŒÌÍŠÌ„Í—ÌˆÌÌšÍ˜â£¿Ì¸Ì›Ì³Í•Í“Ì¦ÌªÍ™Í–Í†Ì†Í›Í—Í—Ì‹ÌŠÍÍ‘Í—Ì‘Í Í â£¿Ì·Ì›Ì¹Ì½Í—Í—Í†ÌˆÌÌ‡Í‘ÍŒÌ“Ì‹Ìšâ£¿Ì´Ì¢Í–Ì±Ì“Ì¿Ì¿Ì“Íâ¡„Ì·Ì¬Ì˜Ì“Ì‰Ì‰Í’ÍŠÍ â „Ì´Ì¯Í’Í†ÌÌ†Ì“Ì¾ÌÌ‹Ì’Í‚ÌšÍ â „ÌµÌ¨Ì¯ÌŸÌ±Ì¦Ì»Ì²Ì²Ì£Ì“ÌŠÌ€ÌŒÌ’Í›ÍœÍâ „Ì¸Ì¡Ì¨Í‡ÍšÍÌªÍ–Í–Ì¹Ì¬ÍÌˆÌÌÌˆÌ‡Í‘ÌˆÌÌˆÌÌˆÌÌ€ÌÌ•Ì•ÍÍ…â ™Ì·ÍÌ¯ÌˆÌÌŽÌÌŒÍ†ÍŒÍŒÌÌ¾ÍŒÍ†ÌšÌšÍ Íâ »Ì¶Ì¦Ì±ÌƒÍâ ¿Ì¸Ì³Í“ÌŒÌ€â£¿Ì´Ì›Ì›ÍšÌ²Ì¬Ì½Ì‘Ì‡ÌÌÍ˜Ì•ÌšÍœâ£¿ÌµÌ¡Ì—ÌªÍŽÌ©Ì¹Ì–ÌœÌ©ÌŸÌ–ÍŠÌÌˆÌ“Í‹Íâ£¿ÌµÌ¤Ì­Ì¯Ì©Ì«Ì–Ì¦Ì¯Í†Í’Ì”ÌÌ†Í›ÌÌ„Ì‘ÌŒÌ•ÍÍÍÍ â£¿Ì´Í•Ì³Ì¼ÌžÌ±Ì£Ì®ÌÌ Ì½Ì„Í†Í˜Í â ¿Ì¶Í”Ì¼Ì¯ÌÌ‚ÌˆÌÍœâ ¿Ì¶ÍŽÌ¹ÍÌ³Ì®Ì‰â ›Ì·Ì¢Ì£Ì°ÍˆÌ£Í‰ÌˆÌŠÍ‘Ì†Ì“â ›ÌµÌ¨Ì¨Ì¢ÍÌªÌžÌÌ°Ì¥Ì°Ì¯Ì¹Ì°ÌƒÌ½Ì‘Í‚Ì„ÌˆÌÍ›ÌÌŒÌ½Í›Ì…Íâ »ÌµÌ§Í™ÌªÍšÌ ÌÍ–ÍÌ»Ì ÌˆÌ‘ÌŒÌ½Ì½ÌŽÍ‹Í Í â£¿Ì¸ÌžÌ˜Í‡Ì°Ì†ÌÍ†â¡„Ì´Ì«Ì©Ì¼ÌºÌ±ÍšÌ»Ì‰â „ÌµÌ¡Í–Í”Ì¾â£¾ÌµÌ²Ì±ÌÌˆÌÌ¾ÌŽÌ‹ÌšÍâ£¿Ì·Ì›Ì­ÌºÌ Ì¼ÌÍ‰Ì­Ì©ÌªÍŽÌƒÌ‰Í…â£¿ÌµÌ¡ÌžÌŸÍ™Í–ÍŽÌ³Ì©Ì¹Ì«Í‡Ì…Ì‚â£¿ÌµÌ¨Ì±Ì°Ì©Ì©Ì©ÍÌ¬ÌˆÌÍ†Í‹Ì”Ì…Í‹ÍÌŠÍ‹ÌÌ•Í â£¿Ì·Ì¢Ì¹Ì¬Ì Í•Ì£Ì©Ì—Ì‘Í›ÌÍ—Ì‹Ì‰Í—ÍŒÌˆÌÌˆÌƒÍ  Ì´Ì«Í“ÌÌ¤Ì¼Í™ÍˆÌ»Í–ÌžÌ±Í›ÌŽÌÌˆÌÌŽÍ’Ì‰ÌˆÌ„Ì•Ì•Íâ£¿Ì´Ì¡Ì§Í”Í”Ì¦ÌžÌ³Í–Ì¬Ì¬Ì³Ì±Í–Ì˜Ì¿ÌÌˆÌ¿ÌˆÌÌ€Ì‘Ì‹Ì†ÍŠÍ‚Íâ£¿Ì¶Ì¨Ì©Ì©Ì£Ì™ÌÌ©Ì±Í“Í“ÍˆÌªÌÌÌˆÌˆÌÌŠÌ”ÌˆÌÌˆÌÌŠÌ‡Ì†Ì½Ì€ÌƒÍœâ£¿ÌµÌ¢Ì¯Ì–Í”ÌÍŒÌƒÌÍ‹ÌšÍÍâ£¿Ì¸Í•Í”Ì‹ÌƒÌ‹Ì€â£¿Ì¸ÌŸÌœÌÍŠâ¡‡Ì·Ì¦Ì®ÌÌ˜ÍšÌÌ Ì©Ì–ÌŒâ „Ì¶Ì­ÌœÌžÍŠÌˆÌÌ‡Ì‰Í›Íâ „Ì´Ì›Ì™Ì™Ì²ÌƒÌ„ÌÍÍÍâ Ì´Ì¡Í‰ÌœÍŽÌ¤ÌŽÌ„Í—Ì‡ÌˆÌÌ”ÌÍŠÌ•Í Í  Ì¸Ì¡ÌºÌ‘ÌŠÍŠÌ‹Ì”Ì“Ì¾Í‘Ì‘Ì“Ì€ÌˆÌÌšÌ•Íœâ­•Ì´Ì Ì…Ì‡Í†ÌÌ‰ÌÍ‚Ì• Ì¶Ì›Ì–Í•Ì¤ÌŸÍŽÌ‡ÍŠÍ‘ÍÍŠÌ„Ì„Ì’Ì„â „Ì¶ÌŸÌŸÍ™Í‚Ì‰ÌÌ€Í†Ì“Ì¿Í‹Ì‡ÌÍ˜ÍÍÍ Í â¢¹ÌµÌ¢ÍŽÌ¦Ì¯ÌŽÌ…ÌŠÌˆÌÌ¿Í‚Í‘Í˜Í â£¿Ì·Ì°Í‰ÍˆÌªÌ»ÍÌªÍ‡Í•Ì—Í•Í•ÌªÌÌ¿Ì…ÍÍ…â¡—Ì´Ì¡Ì¢Ì³Ì‚ÌˆÍ†ÌŠÍ‘ÌŒÌ”ÌÍ†Ì€ÌŽÍ—Ì‚Ì½Ìšâ „ÌµÌ­Ì—ÍˆÍ™Ìš Ì´Í”ÌŸÌ–Ì«Ì˜Ì°Ì–Ì¥Ì Ì˜Ì¤Ì€ÍœÍ…â­•Ì·Ì¬Ì»Ì±Ì®ÌŸÌ Í‹ÌˆÍ‚ÌŠÌ€Í ÌµÌ¢Ì§Ì¼ÍšÍ‡Ì¬Ì»Ì¦Ì­Ì Ì˜Ì¯ÍÌ”Ì„Ì”Ì“Ì†ÌŠÌ“Ì’ÍÌ‘Ì€ÌˆÌÌ½ÍœÍâ¢„ÌµÌ¡ÍÌ¬ÍÌ»Ì¥Ì²Ì™Í“ÍŽÌ™Ì©ÍˆÌŠÌ…ÌŠÌŒÍÍ…â¡€Ì¶Ì§ÍšÌ°Í–Ì¹ÍšÌ©Ì¥Ì—Ì®ÌºÌ»Í–Ì‚Í›ÌˆÌÍ‹Ì¿Ì½Ì‹ÌÌƒÌŒÌ¿ÍÍÍ…â£¾Ì´Ì¼Ì—Ì²Í™Ìâ¢€Ì´ÍŽÌªÌœÌ€ÌŠÌ¾Ì‹Í˜â£¿Ì´Ì›ÌªÍˆÌžÍ–Ì˜Ì˜Ì¥Ì¼Ì¥ÍÌ¥Ì ÌƒÌƒÍ‘Í›Ì‰Í—Ì¿Í‘ÍŠÌ½Ì‡Ì•Í â£¿ÌµÌ›Ì¯ÍÌ€Í’Ì¿Ì‡ÌˆÍÌ“Í‚Ì•Í˜Ì•Í ÍÍâ£¿Ì¶Ì›Ì¼Í•Ì³ÍŽÌ®Ì‡ÌŠÌ¾ÍŒÌÍŠÍ‹Ì”ÌŠÌÌ‘ÌšÌšÍâ£¿Ì·Ì±Ì«ÌœÌ†Ì’Í›Ì…Í—Ì¾Í‹Ì½Ì†Í›ÍÍâ£¿Ì·Ì¢Ì¹ÌºÌ²Ì‘ÌÌ½ÌˆÌÌ‰ÌˆÌÌ“Í†ÌÍÍœâ£¿Ì¸Ì¨Ì±ÍšÌºÌ–Ì¼Í‰Ì–Ì²Ì¯ÍŽÌ–Í™Í•Í†ÌÍÍ… Ì·Ì¨ÍšÍ•Ì¯Ì™ÌžÌ¦Í–Ì²ÌžÌ­Ì»Ì‰Ì“ÌƒÌ†Ì…ÌˆÌÌÍŠâ£¿ÌµÌ§ÌªÌ®Ì²Ì–Ì¯ÌÌ³ÍÌ³Ì ÌˆÌÌŒÌ‡ÌÌ€Ì†ÌƒÍ›Ì‹ÌŒÌÌˆÌÌ†Ì„Ì“ÍœÍ…â£¿Ì´Ì§Ì ÍˆÌ˜ÍÍ‡Ì–ÌœÌŽÌˆÌÍ‚Í‘Ì‚ÍÌ¾ÌÌˆÌŠâ£¿Ì¸Ì¨Ì¢Ì›Ì¹Í‡Ì¦Ì»Ì¼Ì¦Ì²ÌˆÌÌˆÌÌˆÌÍ†Ì“ÍÍ…â£¿Ì´Ì¨ÌÌŽâ£¿Ì·Ì§Í–Ì­Ì½Í’ÌÌ’ÌˆÌÍ—Ì€Ì”â¡‡Ì´Ì¡Ì»Ì—Ì©Í–Ì£Ì²ÌÌ­ÍÌ°Ì‹ÌŽÌ‡Ì“Í‚ÌˆÌÌ€ÌŒÍ’ÌÌŠÌ•Í˜ÍœÍÍâ ˜Ì·Ì§Ì²Ì³Ì²ÍˆÌ³Ì¤Í•ÌžÌŒÌÌ€Ì€Ì€Í’Í’Í‹ÌÌ‹ÌÌ…Í˜â „ÌµÍšÌœÌ˜Ì¼Ì¼Ì¹Ì­Ì®Ì»Ì†ÍÌšÍ˜â „Ì´ÌÌ¥Í”Ì«Í”Í‘ÌŠÍ›Ì‹Í—Ì†Ì”Í˜â „Ì¸Ì£Ì­Ì±Í™ÍˆÌŸÍŒÌÍŒâ¢€Ì¶Ì›ÍšÌœÍ‰ÌœÌ¤Ì¼Ì»Ì¼Ì’ÌŠÍ›ÌŠÌŒÌ¾Í‘ÌÍŠÌ‡Ì”Í ÍÍ Í…â¡€Ì´Ì¬ÌžÌªÍ”Í†Ì¿â „Ì¶Í™ÌºÍšÌ¯ÌÌÌÌÌÌ†Ì„ÌÌ‡Ì‹ÌÌ„Ì…Ì“Ì†â£¿Ì·Ì¨Ì¨Ì³Ì©ÍˆÌžÌ¥Ì»Ì°ÌŸÌ¦ÍšÍ‚ÌšÍ…â£¿Ì´Ì¨Ì¬Ì¦Ì°ÌŸÌ¦Í–Ì˜ÌžÌ­ÌœÌ¥Ì‰Ì‡Ì¾ÌŽÌšÍ…â£·Ì¶Ì®Í™ÌºÌ°Ì»Ì¤Ì˜ÌÌŒÌ’Ì“Ì“Ì‰Í‘ÌŽÍ‘Ì‹ÍŒâ£¤Ì·Ì¼Ì¯Ì°Ì–Ì–ÌªÍˆÌ²Ì–Ì¯Ì–Ì¦Ì„ÌŽÌ‰ÌˆÌâ£¤Ì·Ì«Ì¼Ì“Í‚ÌŒÌ¿Í â£¾Ì·Ì˜Ì²Ì‚Ì‡Í˜Íâ£¿Ì¸Ì›Ì°Ì«Ì¼Ì©Ì—Ì¼Ì«ÌºÌ³Ì–Ì—Ì¼Ì„Ì“Ì‘Ì‘Ì”Í—Ì…ÍŒÌ¾Ì¾ÌÍ‚Ì¾ÍœÍœÍ…â£¿Ì¶Ì¢Ì¡Ì²ÍÌ¼Ì–Ì©Ì¦ÍˆÌ‡Í›â£¿Ì·Ì™Ì³ÌŽÌƒÌ‹ÌÌ€Í˜Íâ£§ÌµÌ®Í‡Í–ÌœÌˆÌÌŒÌ“ÌŽÍÌˆÌÌ’ÌÌ‡ÍÌ¿ÌšÍÍ Í…â¢¸Ì¶Ì–Ì¥ÌºÍ–Ì¥Í•Ì®Ì„Ì“ÌŒÍÌ¿Ì”Ì’Ì‡ÌÌ¾Ì½Ì…Í˜Í â£¿Ì¸Ì¨Ì—ÍŽÌ­Í™Ì“ÌˆÌ‘Ì½ÌÌ…Í Í â£¿Ì´Ì¢ÌœÌ¹Ì¦Ì¼Í‡Ì—Ì«Ì‡ÍÌ…ÌÍŒÌŽÍ’Ì„Ì€Ì•â£¿Ì·Ì¨ÌÍ‘Ì’Ì”ÌÌÍ’ÌÌˆÌÌÍ‘Ì…ÌšÍâ£¿Ì¶Ì¡Ì˜ÌªÌ–Ì™Ì–Ì­ÌŸÌÌ«ÌÌ†ÌˆÌÌ‰Ì‹Í˜â£¿ÌµÌ˜Ì¤Í‡Í‡ÌŸÌœÌ‘Ì”Ì‡Ì„ÌŒÌ€ÍŒÌÍŒÍ˜Í…Í… ÌµÌ–ÌÌ…ÌÌ…Í›Ì¾Ì“Íâ£¿Ì´Ì—ÌœÌ—Ì¥Í–Í™Ì©Í‰Í‡Í—Í’ÍŒÌŠÌ’Í—Ì‹Í‹Ì…Ì‚Ì‚Ì¾Ì¾Í˜Íâ£¿Ì´Ì¢Ì§Ì»Ì¤Ì—ÌˆÌÌ…â£¿Ì´Ì§Ì¢Ì¯Ì»Ì°Ì¥Ì˜ÍŽÌ¬ÍšÌ ÌœÍ â£¿ÌµÌ«Í‰Ì¤ÍšÍ™Í‡Ì¼Ì–Ì¥Ì¼ÍŠÍ…â£¿Ì·Ì¨Ì¹Ì³Í‡Ì¯ÍšÌºÍ•Ì±Ì¿ÌŠÍŠÍ’ÌŒÌšÍÍâ¡‡Ì´Í“Í‰Ì°Í”ÍˆÌÌ¤ÌªÌ£ÍÌ¿ÌÌÍ ÍÍâ „Ì´Ì¥Í‚Í˜â£°Ì·Ì˜ÍÌ¼ÍˆÌ¥Ì—ÌœÌŸÍÍ—ÍÍ’Í›Ì½ÌˆÌÌ€ÍŠÌ€Í’ÌÌšÍÍ Í…â£¿Ì´Í•Ìâ¡¿Ì·Ì¢Ì›Ì¦ÍŒÌ‡ÌÌ€ÍŠÌ€ÌŠÌÌ‡Ì”Í˜Ìšâ ŸÌ¸Ì¯ÍšÌ­ÌˆÌÌ’Í’Ì¾ÍŒÌƒÌ€Í‚ÍŒÌ€ÍœÍâ ƒÌ·Ì›Ì›Ì›Ì¥ÍÍŽÌ“Ì“ÌˆÌŠÌ‡ÌˆÌ“Í†Í’Ì‰â „Ì´Í‡ÍÌ»Ì¬Ì”â£¿Ì¸Ì¨Ì¹Í‡Ì»Ì°Í”Í–Ì£Ì«Ì»Ì©Í‘Ì½ÍÌ„ÌˆÌÌŽÌˆÌÌ½Ì¾Í†Ì‹Í â£¿ÌµÌ¡Ì¢Ì˜Ì²Í”Ì»ÌŸÌ°Ì°Ì°Ì˜Ì­Ì°ÍšÌ‘ÌŽÍŠÌˆÍ‹Í—ÌÌ€Ì“Í‘Í‹ÌˆÌÌŒÌ¾Íâ£¿Ì¶ÌžÍ‡Ì¼Í“ÌŒÌ‹ÍŒÌˆÌÍ‹â£¿Ì¸Ì§Ì¥Ì¼Ì©Ì£Í™Ì­Ì®ÌœÌŸÍ•Ì—Ì‡ÌˆÌ†Ì½ÌŒÌŠÍ‘ÌŒÌ’Ì¾Í†Ì½Ì¾ÍÍ â£¿Ì´ÍÌ©Ì±Ì«Ì—Í‡Ì†Ì€Ì’â¡›Ì·ÍˆÌ±ÌÍšÍ˜Íœâ ¿Ì¶ÌªÌ®Ì¦ÍÌ°Ì–Ì¥ÌºÌ“Ì¾Ì‡ÌŽÌŠÌÌ“Íœâ¢¿Ì¶Ì¼Ì°Ì™Ì¿Í›Ì½Í—Ì‰Ì€Ì‰ÌˆÌÌ‘ÍÍâ£¿ÌµÌ™ÌÌ—Ì±Ì±Ì–ÌºÌ©Ì–Ì¹Ì»Ì¼Ì˜Ì¹Ì“Í‚Ì…ÌÌÌ‡Í â£·Ì¸Ì§Ì§Ì¡Í‰ÌºÌ¦Ì£ÍŽÍ™Ì¥Ì¬Ì¾ÌˆÌˆÌˆÌÍœâ£¾Ì¶Ì›ÍÌ±Ì¯Ì—Í•ÍšÌŸÍ™Ì—ÌŽÌ”ÌˆÌÌ‰Ì‰ÍÍÍ…â£¿ÌµÍ•ÍÍ‡Ì£Ì±Í™Í”Í™Ì°ÌÌˆÌÍ…â£¿Ì¶Ì¨Ì¨Ì—ÌžÍ–Ì¦Ì˜Í‰ÌžÌ¥Í‡Ì ÍÍ‰ÌˆÌ‰Ì½ÍŒÌÍÌŽÌÌ¿Í˜â£¿ÌµÌ¡Í‰ÍˆÌ¤ÌªÍ‡Ì³Ì¦Í“Ìâ£¿Ì¸Ì¤ÍÌºÌ©Ì¹Ì£Í‡Ì¯ÍÌÌ’Ì“ÌÌ‘Ì‡Í…â£¿Ì·Ì£Ì™Ì³Ì¯ÌžÍ™ÌœÌ£Ì’ÌÌ“Ì”Ì‰ ÌµÌ§Ì³ÌºÌ±Ì»Ì¬Í‡Ì–Í‰ÍšÌ­Ì¤Ì‘Ì•ÌšÍÍ…Í…â£¿Ì¸Ì¡Ì°Í“ÌŸÌŸÍ•Ì±Ì¦ÌžÍ–ÍšÍ–Ì˜Ì¾ÌÌ”Íœâ£¿Ì¶Í”Ì¹ÌœÌ—ÍÌ¦Ì«Ì“ÍŠÌ½Í‘Ì’Í…â£¿Ì¸Ì¼ÌˆÌÌ‡Ì½Ìâ£¿Ì¸Ì˜Ì—Ì£Ì¦Í•Ì¬Ì±Ì²Ì­Ì¤ÌžÌÌˆÍ‚Ì€ÌŽÍ˜Íâ£¿ÌµÌ¢Ì›ÍšÌ®Ì¥Ì©Ì’ÌÌ„ÌŒÌ¾Ì“ÌŽÍ†Ì…ÍŠâ£¿ÌµÌ¢Ì–Í‹Ì‰Ì…Ì½Ì½Í—Í›Í â¡„Ì´Ì¨Ì¨Ì¯Ì˜Ì¤Ì°Ì™ÍˆÍ‘Ì…Í‘Ì„Ì¿ÌÌ‹ÌšÍ˜â ˆÌ·Ì²Ì¥Ì—Í“Ì¼Ì©ÌŸÌ²Ì¦Ì˜Ì Í•Í‰Í“Ì¿Ì‘Í†Ì•ÍÍ…â ÌµÌ¡Ì¨Ì²Í‡Ì°Ì²Ì–ÌžÍ™ÌƒÍ›ÌÍŒÍ†Ì“Ì•ÌšÍÍ Í…â „Ì´Ì¢ÌœÍŽÍ“Ì¥Ì£Ì¥Í‡Í’Í’ÌŽÍ‘Ì€ÌŠÍ›Í—Ì€ÍÍ—Ì‹ÌŒÌ”Ì‹Íœâ „ÌµÌ¦Ì¹ÌˆÌÌ‚Í—Ì€Ìˆâ „Ì·Ì§ÌªÌ¹Ì°ÍšÌ³Ì±Ì™ÍÌ¼Í”Ì«Ì¥ÌÌÌŠÌ€Í‘Ì¾Ì“Ì•Ì•Íâ „Ì·Ì­Ì°ÍšÍ‰ÌÌ¯Ì­Ì°Ì°Ì¤Ì“Í—Ì‹Ì¾Í‹Ì€Íâ »Ì´Ì›ÌŸÌ»Ì¬Ì—ÌÌÍ‘Ì“Ì€ÌŠÌ‡ÌÌ’Í ÍÍÍ…â ¿ÌµÌ¡Ì¹ÌŸÌ³ÍšÌ—Í‰ÌœÌºÌ¼Ì®Í‹Ì…Ì¿ÌšÍ â¢›Ì´Ì›Ì¯ÌÍÌ™ÌžÍ‰Í’Ì“ÍŠÍ‘Ì‡Í’Ì‘Í‚Í›ÌˆÌÌ„Íâ£¿ÌµÌ–Ì¹ÌÌ‰Ì‰Í â£¿Ì´Ì¨Ì§Ì›Í™ÌœÌŸÌ¿Í›Ì“Ì‰Ì’Í˜Í˜ÍÍâ ¿Ì¸Ì¨Ì¨Ì¨Í“Ì¹ÌœÌ¼Ì£Í•Ì¬Ì»ÍÌ¥Ì“ÌˆÌÍ†Ì½ÍœÍœâ ‚Ì·Ì§Ì¥Ì†Ì”Ì†ÌÍŒÌ•â „ÌµÌ¡ÍšÍ”ÌÌŽâ¢¹ÌµÌ£ÍšÌ®ÌœÍ•Ì¦Ì«ÍˆÌ¹Ì®Ì¤Ì‰â¢¹Ì¶Ì±Ì®Ì—ÌºÌ¥Ì±Í“Í‰Ì¹Í–Í–ÍšÍ•Ì°ÌˆÌÌ’ÌŠÌŠÍŠÍŠÍ—Ì“ÌˆÌÌ‡Ì•Í…â£¿Ì¶Ì›Ì¹ÌºÍ‡Ì³ÍÍ”Ì—Ì¥ÌºÌ®ÌƒÍ‚ÌˆÌÌ…Ì¾Í‘Íâ£¿Ì¶Ì¨ÌªÍ™ÍˆÌ¦ÌŸÍ•Ì„Ì€ÌˆÌÌ½Ì‹ÍÍ›â£¿Ì¸Ì­ÌžÌºÍŽÌÍ•ÌªÌ˜ÌžÌ«Ì™ÌÌ“ÌÍâ£¿Ì¶Ì¨Í‡Ì©Ì Ì­Ì°Ì¥Í–Ì Ì¥Ì’Ì€Ì‚Í’Ì‹Ì“Ì„Í›Ì€Í‘ÌÌ‘Ì“ÍÍâ£¿ÌµÌ¡Ì²Ì¼ÌºÌºÌœÌœÌ˜Ì—ÌœÌ‚Ì”Í‘ÍÌ¾ÌŠÌˆÌÍŒÍŒâ£¿Ì·Ì¡Ì§Ì§Ì›ÍŽÍšÌžÌ¯Ì°Í“ÍšÌÍŠÌ‚ÌŒÌ…ÌÌˆÌÌ“Ì’ÍÌ•ÍœÍ  Ì¸Í“Í†Ìâ£¿Ì·Ì¡Ì˜Ì­Ì¹Ì¥Í“ÌŸÌŸÍ–Ì¿ÌŠÍ‹ÌŽÌ‹Ì‰Íœâ£¿Ì·Ì­ÍÌŸÌœÍ“ÌºÍ™Í™Ì»Ì°Ì—Í‰Ì¦Í–Í’Í’â£¿Ì¶Ì¢Ì¬Ì­Ì­Ì»ÌžÍŠÍŠÌÌâ£¿Ì·Ì²Ì¥Ì£ÌŸÌ¤Ì°Ì–ÍŽÌ–Ì‹Í‹Í‘ÍÍŒÌÌ“Ì¿Ì‰Ì€Í—Ì’Í‹Í‹Ì‚â£¿ÌµÌ›Ì¹Ì©Ì™Í™Í†ÌÌˆÌÌ‰ÌˆÌÌŽâ£¿Ì¶Ì©Ì£Ì®Ì‘ÌˆÌÍÌ€Í‘Í‹Ì‹Ì¾ÌÌšÍ˜â£¿Ì´ÍŒÌˆÌÍ˜Íœâ¡Ì·ÌœÌ™Ì£ÌÍ›Ì¾Ì’Í Í â ÌµÌ¢Ì³Ì©Ì±ÍˆÍ™ÌœÌ±ÌªÌ±Ì‘Ì”ÍŒÌ€Í’Ì”Ì½ÌŠÌƒÌšâ „Ì´Ì¢Ì˜ÌªÌ£Í”Ì Ì¬Í‚ÍŠÌˆÌÌ„ÌÌŠÌˆÌÍ›Ì€ÌˆÍŠÌšÍœÍâ „Ì¸Ì¢Ì¨ÌÌ¹Ì–Ì±ÍŽÌ¬Í•Ì–ÌœÌÌ“Í›Ì„ÌÌ„Ì†Ì¾Ì…ÌˆÌÍŒÍ‚Í…â£ Ì¸ÍšÌ»ÌŸÌ‰Ì„Í‘ÌˆÌÌ‰Ì¿Í‚Ì‡Ì†â£€Ì´Ì¨Ì§Ì—Ì¦Í‰Ì»ÍŽÌ»ÌŸÍ–Ì«Í‡Ì­Ì‰ÌÌ„ÌƒÍ†Ì‹ÌˆÍÍÍ…â£€Ì·Ì¼Ì“Ì‚â£šÌ´Ì¥Ì°Ì±ÍšÍ–ÌœÌ¹ÍˆÌ²ÌŸÌ¥Ì¬Ì¤Ì–Ì½Ì‘ÌÍ›Í‘Ì‘Ì‚ÌŒÍÌ½ÍÍ˜Í Í Í…â£¯ÌµÌ¦Ì©Ì¼Ì—Ì®Ì“Í‘Í†â£µÌ´Í‰Ì³Ì«ÍˆÌ¼ÌžÌ–ÌÌ—Ì¯Ì«Ì¼Ì„Ì“Íœâ£¶Ì·Ì›Ì˜Ì‡Ì…Ì‹â †Ì¶Ì›Ì®ÌžÌŸÌ£Ì­ÌžÌ±Ì¤Ì†ÍŒÌ¿ÍŒÍÍŠÍ‘Ì¿Ì¾Ì¿Í‘Í‹ÌˆÌÍ˜Íœâ£°ÌµÌ¨ÌœÍ‰Ì¹Ì«Ì»Ì¼Ì¹Ì¥Ì­Ì±Ì‚ÌƒÌ‹Ì€â „Ì¶Ì¨Ì¢Ì›Í™Í“Ì»Ì£Ì’ÌŽÌ¾Ì‡Ì…Ì’Í—ÌˆÌÌ‘ÌƒÌ¿ÌšÍœâ žÌ·Ì¨ÌžÌ¬Ì¬ÌÍšÌ™Í™Í‚ÌÌ“Ì‘ÌšÍœÍ…â£¾Ì¸Ì¼ÌªÌ»Ì«Ì¹Ì«Ì™Ì¬ÍŽÍ•Ì€Ì‰ÌÌ…Í‚Í‹ÍŒÌ‚ÍŒÌ€Ì•ÍœÍ…Í…â£¿Ì´Ì›Ì®Ì Í‡Ì¼Ì­Ì£ÌŽÌ€ÌÍ‚Ì¾Í†Í‹Ìšâ£¿Ì¶Ì›ÌªÍŽÌ“Ì¾Í’â£¿Ì¶Ì›Í‚ÌŽÌ“ÌˆÌÌˆÌÌ‰ÍŒÍ—Ì“Í›Ì•Í˜Íœâ£¿ÌµÌ§Ì¡Ì–Ì­Ì Ì—Ì¦Ì©Ì¬Ì Í‡ÌºÌ½Í‚â£¿Ì¸Ì¨Ì¡Ì£Ì—ÌœÌ–ÌœÌ–Ì€Ì‚ÌˆÌÌ¿ÌˆÌ…â£¿Ì¶Ì§Ì¨Ì›Ì Í–Í”Í‘Ì” Ì·Ì¥Í“Ì¦Í‰Í–ÌºÍšÌªÌƒÌ‘Ì‘Ì‘ÌƒÌÍ‹Í…Í…â£¿Ì´Í‰Ì™ÌœÍ“ÍŽÍ•Ì®Ì„Í‹Ìâ£¿Ì·Ì§Ì¨Ì¡Ì¹Ì¬Ì«Ì¯ÌÌ®Ì»ÌžÌžÍ”Ì±Í›ÍŠÍ˜â£¿Ì¶Ì®Ì²Ì°Ìˆâ£¿Ì¶Ì™Ì—Ì±ÌºÍˆÌ²Í”Ì˜Ì¼ÌŸÌÌŒÌÌˆÌˆÌÌ‚Íâ£¿ÌµÌ§Ì›ÌÍ“Ì˜Í‡Ì­ÌÌ“Ì€Í›Ì‡Ì‹Ì†Ì¾Ì¿ÌŠÌšÌšÍÍ…â£¿ÌµÌ›Í•Ì®ÌÌ…Ì“ÌˆÌÍ—ÍÌ•Í â£¿Ì´Ì›ÌÌ„ÍÌˆÌÌ†Í‹Ì‰ÌƒÌƒÍ˜Í˜Íœâ£·Ì¶Ì§Í•ÌªÌ¹Ì£Í”Í“Ì˜Ì¤Ì¯ÌŸÌŸÌŒÌƒÌŒÍ˜â¡„Ì´Ì¡Ì¬Ì¥Ì³Ì˜Ì¦Ì¥Í”Ì¹Ì°Ì£Í–Ì»Ì„ÌŽÍ‘ÌÍ’Ì†â „Ì·Ì§Ì¨Í‰ÌÌ˜Ì Í‰Ì³Ì³Ì¥Í”ÍÍ”ÍšÍˆÌÌŽÌƒÌ†Ì¾ÍŒÌ…ÌÌÌˆÍ˜Í â „Ì·Ì¹Ì½â ˆÌ¸Ì»Ì³Ì˜Ì²Ì¦Ì©Ì—Í“Ì«Ì¦Ì ÌÍŠÌÍ—ÍŠâ ›Ì´Ì¢Ì¥Ì¹ÌœÌ¦ÌžÌ»Í–Ì°ÍˆÌ–Ìâ ¿Ì·Ì§Ì»Ì‚Í’Ì€ÌˆÌÌ‰Ì‚Ì€Ì¿ÌˆÌÌˆÌÌâ ¿Ì¸Ì«ÍŽÌ¯ÌŸÌ˜Ì¤Ì±Í—Í‚Ì€Ì‘Ì’Í’ÌÌŒÌ•Ì•ÍÍ Íâ ¿Ì·Ì¡Ì¢Ì¡Ì¡Í™Ì¯Ì¯Í–Ì¬Ì¦Ì£ÌÌ„Í‹Ì‡ÌŽÌˆÌÌÌ…Ì•Í˜Í â£»Ì¸Ì›Ì£Ì­Ì¾Ì¿Ì‚ÌˆÌÌ‚ÌÍ‘Ì’Í›ÌŽÌšâ¡Ì´Ì¨Ì©ÍŽÌ¼Ì£Í“Ì Í™Ì»Ì—ÌˆÌÌ‚Í›Í˜Í…â¢ Ì·Ì¨ÍÌ‚ÌˆÌÌ†Í†Í˜Í˜ÍœÍ Í â£¿Ì·Ì¡Ì¡Ì˜Ì²Ì«Ì¦ÌªÌ—Ì­Í“ÌÌºÌ‚ÌŠÌˆÌâ£ŽÌ¶Ì¨Í”Ì—Ì°Ì©Ì²ÌŸÍ”Ì¬Í‰Ì–ÌºÌºÍ†â£¾ÌµÌ¡Ì¤Ì¦Ì±Ì¤ÌžÌ«Í•ÌžÌ—ÌÌ…ÌŽÌ‚ÌŽÌ”â£¿Ì·Ì§Ì°Ì Ì³ÍÌ©Ì»Ì£Ì¼Ì£ÌªÌ–Í–Ì³ÌˆÌÍ’Ì‡Ì‘ÍÍ…â£¿Ì·Ì¨Ì¨Ì—Ì¼Ì˜Ì²Ì¼ÌºÌ–Ì Í“ÍÌ±Ì¿ÌƒÌ”ÌˆÌÍ—Ì†ÌƒÍÍ…â£¿Ì¸ÌŸÌ¬Í“Ì¼Ì‹ÌÌ€Í’Í‚ÌŒÍœâ£¿Ì´Ì¡ÌºÌ¥Ì©ÍÍšÌˆÌÌ€Í…â£¿Ì´Ì¢Ì¬ÍŽÌªÌ²Ì¦ÌÍŠÌ“Ì½Í‹ÌÌ¿ÌÍ›Ì†ÌÍâ£¿Ì¶Í™Í‰ÌÌ™Í–Ì˜Ì±Ì¹Í‡Ì¥ÌžÌÍ’â£¿Ì¶Ì¬Ì–ÍˆÌœÌ’ÌˆÌÍ’Ì”Ì„Í’Ì”Ì¾ÌÍ’Ì’Ì•ÍÍ  ÌµÌ¢Ì§Ì±Ì Ì±ÌžÌ±Ì³Ì¯ÌºÌ£ÍÌÍŠÌŒÍ˜Íœâ£¿Ì¸Ì¡Í”Ì Ì­Ì»Í‰Í‡Ì†Í›ÌˆÌÌ€Í†Í—Í—Ìˆâ£¿Ì¸Ì§Ì¬ÌžÌºÌÌÌƒÌâ£¿Ì¸Í‰Ì»Í–Í™Ì ÍŽÍ‡ÌœÍ–Ì˜Ì¥Ì—ÌÌˆÌ¾Í›Ì€Ì‡Ì½Ì‹Ì€Íâ£¿Ì¶Ì§Ì¨ÍˆÍ–Ì¯Ì²Ì«Ì°Ì²Ì»Ì³Ì®Í’Ì€Ì€Í‚Í†Ì€ÌˆÌ¾Íœâ£¿Ì·Í‡Ì¦ÌªÌ²Ì¹Ì–Ì³Ì±ÍŽÍ—Ì…ÌƒÍŠÌ½ÍÌ¾Ì‚Ì“Ì‡ÌŠÌ‚ÌÍ†Íœâ£¿Ì·Ì°Ì©Ì»Ì«Í“Ì°Ì»ÌªÍ‰Ì¼Í‰ÍšÌ—Í‚ÌˆÌÌ„â¡¿Ì¸Ì Ì¼Í‡ÍÍ™Ì³Ì®Ì®ÍŽÍ™ÌÌ°Ì ÍŽÌ®Í’Ì„Í†ÍŒÍ’Ì…ÌšÌ•Íâ ŸÌ´Ì¯Í–Í‰Í™Í†ÌŒÍŒÍ›ÍÌˆÌÌ€Ì€Ì…ÌƒÌƒÌ‹â ›Ì¶Í•Ì£Ì«ÌœÌˆÌÌ‘Í˜â „Ì·Ì¢Ì›Í”Ì¤Í‰Ì¯Ì±ÌœÌ²ÌÌ‡ÌÌ€Ì‰Í…â „ÌµÌ¢ÌžÍ‰Ì‘ÌˆÌÌŽÌ¿Ì‰Ì¾Ì‰Ì¿Í˜Ì•Íœâ „ÌµÌ¥Í“Í™ÌªÌÌÍŒÌÌ¿ÌŠÍ’Ì…Ì”Í˜â „Ì¸Ì¢Ì§Ì§ÍšÌ¹ÌžÌ–Ì²Ì˜ÌžÌ°Ì³Í‹Ì“ÌŽÌˆÌÌˆÌÌ„Í†ÌÌ¾Ì’ÌÌ‰ÌÍÍ â ™ÌµÌ§Ì§Í•Ì˜Í–Ì±Ì¬Ì‡Í—Í—ÍŒÌˆÌÍ‘Ì“ÍÌšÌ•Íœâ£›Ì¶Í–ÌŒÌÌŽÌ…Ì„â£¿Ì´Ì¡Ì«ÍšÌªÌºÌ³Ì¾ÍÌ‰Í‹Í‘Í‹Ì‡Ì”Íâ£¿Ì¸Ì¤Ì‚Ì‰Ì“Ì…ÌÍ†Ì†ÌÌ¾Ì“Ì•â£µÌ´Ì¢ÍˆÍ–Ì°ÍŽÌŸÌºÍŠÌÌÌ“Íâ£¿Ì´Ì¢Ì¡Ì§Í“Ì±Ì¯Ì±Ì°Ì«Ì³Ì®Ì—Ì¼Ì˜Ì±Ì’ÌƒÌˆÌâ¡¿Ì´Ì®Í”Ì«ÍšÍÍ™Ì¾Ì†ÌƒÌŠÌÌ’Ì“ÌƒÌ’ÍœÍœÍ Íâ¢¹Ì¶Ì¡Ì§Ì±Ì³ÍŽÌ¯Ì­Í–Ì°Ì»Ì°Ì°Í‡Ì€ÌŒÌ“Ì½ÌÍÌŽÍ‚ÌÌÍÌ€Ì’Í Í…â¡ŸÌ´Ì©Ì¹Ì«Ì¹ÌÌŽÌ¿Í—Í‚Ì†Ì“Ì€Ì½Í˜ÍœÍÍÍ…â£¿Ì¶Ì¢Ì§Ì¨Ì›Ì›Ì«Í–Ì¦Ì¬ÍÌœÍ‰Ì®ÍšÌ¹Ì¿ÌÌŒÍ‚Ì€Ì€Ì„Ì¿ÍÌÌ•ÍÍ â£¿Ì¶Ì±ÍˆÌœÌžÌ³ÍÌ’Ìƒâ£¿ÌµÌ¹ÍÌ Ì«Í–ÌÍŽÌŸÍ™ÍˆÌ¤Ì£ÍˆÍŒÍ’ÌˆÌ‹ÌÍ’ÌŒÌ•Ì•Íâ£¿ÌµÌ¡Í–Ì£Ì¥Ì¥ÌºÍ•Í™Ì³ÍÌÌ‘Ì‚Ì†ÍœÍ…â£¿Ì¶Ì¨Ì§Í“ÍÌ£Ì‚Í›ÌˆÌÌ‰Ì€Ì„Ì“Ì“Ì‰Ì½ÌÌŒÌƒâ£¿ÌµÌ¤Ì Ì¯Ì™Ì Ì–Ì“Í—â£¿Ì¶Ì–Ì£Ì£Í’Í‚Ì¾ÌŒÍŠÌŽÍ‘Í Ì´Ì Ì¬Í™ÍÌ˜Ì¦Ì¯ÌžÍ‰ÌÌÌ’Ì‘Í—Í’ÌƒÍŒÌšâ£¿Ì¶Ì¡Ì›Ì¥Í™Ì£Ì™Ì³Ì¯ÌºÌ‹ÌˆÌÌ½ÍœÍÍÍ…â ¿Ì¶Ì¡Ì¡Ì¨Í”Ì©Ì°Ì¥Í”ÍšÌ¦Í‰Í–Ì€Í—Íâ ¿Ì¸Ì›ÌºÍ“Í‘Ì’Ì“Í‹Í’Ì‘Ì…Ì„ÌŽÌ‡Í†ÌÌ•â ‹Ì¶Ì³Í‰ÌºÍ›ÌˆÍÍœâ ‰Ì·Ì«ÌŸÍ‹Ì½ÌÌÌˆÌÌ’ÌÌ½Ì‰Í˜Í˜ÌšÍ˜â „ÌµÌ§Í‰Ì¦Í“Í”Ì¥Ì¬ÌÌ’ÍŠÌŽÍ‚Í†ÌŽÌ’Ì€ÌˆÌÌ†Í’ÌŒÌ•Í˜â „ÌµÌ¢ÍŽÌœÌ¯Ì¼ÍÍ™ÍšÌ±Ì¯Í‘Ì…Ì¿Ì€ÍÌ‘ÌšÍâ „ÌµÍ–Ì¯ÌÌ­ÍŽÌ–Í›Ì‘Ì‘Íâ „ÌµÍ“ÌžÌ¦Ì¬ÌŸÌ“ÌÍ‚Ì”ÌŠÍÌÍ˜â „Ì·Ì¡ÌºÌ™Ì—Ì­Ì¾Í â „Ì¸Ì¡Ì¡Ì¢Ì–Ì»Ì¼Ì–Ì»Ì™Ì Í‰Ì­ÌªÌ­Í‘Í‘ÌˆÌÌ‰Ìâ „Ì·Ì¢Ì’Ì‘ÌŒÍ‘Ì€Í‚Ì€Í‹ÌƒÌ†Ì¾â£€Ì¸Ì™Í‹â£ ÌµÌ§Ì›Í”Í“Ì¬Í’Í‚Ì€ÌŠÌˆÍ‘Ì¾Í’Ì‡ÌÌˆÌâ£¾Ì¶Ì›ÌŸÌ—Ì¦Ì¿Í‘ÌŠÍ‚Ì‹Ì’ÌˆÍ’Í˜Í…â£¿Ì´Ì¨Í™Ì¥ÌŸÍ™ÌªÌ™Ì±Ì‘ÌŽÌ¾Íâ£¿Ì¶Ì›ÌºÍ‰Ì¹ÌºÌ™ÌœÍ•Ì­ÍŽÌ‘Ì€ÌˆÌ‡Ì¿Í‹Ì€ÌÌ€Í˜ÍœÍÍÍâ£¿Ì¶Ì©ÌœÌ«ÌŸÌ—Í•Ì¥Ì©Ì¤Ì—ÍšÍ‰Ì“ÌˆÌâ¡ŸÌ·Ì¤ÍˆÌ Í‡ÌªÍÌ¯ÍšÌ³Ì–ÌˆÌÌƒÌ‰Ìâ Ì¶Ì¯Ì–Ì±Ì³ÍŠÍ†Ì“Í†Ì„â ¹Ì¸Ì¼Ì¤ÍˆÌ¿Ì‰ÌÍ…â¡‡ÌµÌ¨Ì¢Ì–Í•Ì—Í“Ì¹Ì™ÌžÍˆÌ”Ì’Ì…ÌÍ†Í’Í˜ÌšÍœÍ â£¸Ì´ÍŽÌÌŸÍ‰Ì‘Ì“Ì…Í›ÌŠÌšÍâ£¿Ì·ÍšÌÌ«Ì¤Í™Ì³Ì®Ì¼Ì¥Ì±ÍšÍ“ÌÌ€Ì‡Í†Ì½Í‹Í˜Íâ£¿Ì·Ì¡Ì¢Ì£Ì–Ì™Ì¹Ì¤Ì«Ì¥Ì²Í‡Í‰Ì»Ì½Ì‘Ì”ÍŠÌÌšâ£¿ÌµÍˆÍˆÌ¥Ì­Ì²ÍšÍ™Ì–Ì®ÍŽÌ“ÌˆÌ‡Í†Ì’Ì‰ÌÍœÍœâ£¿Ì´Ì¢Í•Ì­Ì—ÌžÌ—Ì²Ì—Ì«Ì¼Ì“Ì…Ì“ÌÍ‘Ì‘ÌÌ¿Ì•â£¿Ì¸Ì§ÌºÍŠÌ‡ÍŠÍŠÍ›Ì¿Íâ£¿Ì´ÍŽÍˆÌ­Í–ÌžÌ¹Ì™Ì™ÍÌ¯Ì Ì´Ì¨ÍŽÍ‰Í™Í‡Í™ÌºÌ¤Ì¤Ì—Í“Ì£ÌÌ“Ì¿Ì“Í‹ÌˆÌˆÌÍ Í…â Ì¶Ì Í“ÌœÍ™Í‡ÍˆÌ³Ì¼Ì™Í†ÌŠÍ›ÍŒÍ’Í’ÌƒÌ¿Í—Í’Í—Ì‚Ì‚ÌšÍÍ…â „Ì·Ì§Ì¡Í•Ì­Í™Ì™ÍÌ«Ì»Ì±Í•Ì¿ÌŒÌ€ÌÌ„ÌˆÌÌŠÌŽÌÍŠÍ‚ÍœÍ ÍÍ…â „Ì¶Í‰Ì¥Í‡ÍÌ¥Ì¤Ì«Ì¯Ì¾ÌÌˆÌâ „ÌµÌ¡Ì¬Ì«ÍˆÌŸÍ‰ÌžÌ—Ì˜Ì£Ì«Ì©Ì£Ì—Ì¾ÌÍŠÌ†ÌÌ“ÌŽÌ’ÌÍ‹Ì•Í Íâ „Ì·Ì–ÌœÌ¯Ì Ì»ÌˆÌ…Ì½Í‘ÌŠÍ›Í˜â „Ì·Ì®Ì¼Í†â „Ì¸ÍˆÍŽÌ«Ì°ÌªÌ¦ÌŒÍŒÌ„ÌŠÍÍ—Ì‚Ì“Ì„Ì‰Ì½Í—ÌÌˆÌâ „ÌµÌ®Ì¦ÌÌ¹Ì˜Ì¯Ì‘Ì€ÌƒÌšÌšÍâ „ÌµÌ§Ì­Ì¤ÍˆÍ–Ì­Ì–Ì™ÌÍ–Ì Í–ÌºÍÍ–Ì“ÌÌ€Ì€ÍŠÌšâ „Ì·Ì¢Ì¢Ì¡ÌžÌ»Ì¤ÍšÌ»ÍšÍ–Ì–Ì¯Í”Í‡ÍÌˆÌŒÌŠÍâ „Ì·ÌÌ¦ÍˆÌºÌºÍˆÌºÌˆÌÍÌˆÌ•Íâ „Ì¸Ì›Í™Ì«Í”Ì˜Ì¹Ì³Ì¹Í‡Ì©Ì–Í•Ì˜Ì²Ì«ÌÌ½Ì‚ÌŒÌÌ‰Ì‡ÌˆÌÌŒÍ’ÍŠÌ‚ÍŒÌˆÌâ „Ì¶Ì¨ÍÌ Ì©ÍÌ¯Í—ÌƒÌˆÌÍâ ™Ì¶Ì°Ì–Ì–Í“Í•Í•Í•Ì¹Ì¦ÌÌƒÍ›Ì¾Í‘Í†Ì½Í›Ì„Ì½Ì„Ì€Ì‘ÌÌšÍâ ¿Ì·ÌºÌÌ²Ì¬Ì«Ì±ÌžÍ•Í‡Ì²Ì¼Ì¼Ì†ÍŒÍâ ¿Ì¶Ì§Ì§Ì³Ì Ì Ì˜ÌŸÌ®Ì«Ì€Í›Ì€Ì‘Ì½Ì„Í—ÌŒÍ›Ì†Ì“ÍÍâ ›Ì¶Ì³ÍÌ­Í“ÍÍÌ¥Ì°ÌˆÌˆÌÌŒÌŽÌÌˆÌÌ“ÍŠÌ•Ì•Íâ ‹Ì·Ì¥Ì–Í•Ì¥Ì€ÍÍ›ÌŠÌ‡Ì“Ì„ÌŽÍ˜ÍÍÍ â „Ì´Ì³Ì¾ÌƒÍŒÍâ£¸Ì¶Ì¦ÌªÌ¤ÌÌ²Ì«ÌŸÌ¥Ì¤Ì Í‰Ì‹Ì…Ì„ÌÌÌ’Ì‘ÌˆÌ€Íâ£¦Ì¶Ì¡Ì›Í”ÌÌ»Ì®Ì—Ì‹Ì‚Í›Ì‰Í†ÌÌ“ÌÌÍ â£ Ì¶Ì¼Í–Ì£Ì»ÍÍ”ÌŸÌ¥Ì¬Ì˜ÍšÌ©Ì¹ÌˆÌÌ’Ì‘ÌˆÌÌÌ½ÌŠÌ‰ÌƒÌ•Ì•ÌšÍ Í…â£¿Ì·Ì¡Ì¤ÌœÌ³ÌœÌ«Ì­Ì©ÌŸÌªÍ“Ì¥Ì“ÌÌ¿ÌÌ‚ÌŽâ£¿Ì¶Ì¤Ì±Ì¿Ì“Ì„Ì€Ì¾Ì†Í˜Í˜Íâ£¿Ì¶Ì¡ÌœÌ¥Ì»Ì°ÍšÌ±Ì®ÌœÍ”Ì©Í‚Ì‡ÌƒÍ‚Ì‰Ì¾Ì‹Í‹Ì„Í†Í‚ÌˆÌÍœÍ…â£¿ÌµÌ¢Ì¡Ì°Ì£Ì¥Í–Ì£Í•ÍÌ±Ì³ÌŽÍ‘ÌÌÌ“ÌˆÌÌ„ÍŒÌˆÌ‚Ì€Í˜â£¿Ì¸ÌœÌ©Í”Ì¤Í“ÍŽÌÍ†Ì…Ì‘ÌÍ‘Ì¾Ì½ÌŒÌ‰Ì•ÍœÍ â£¿Ì·Ì¡Ì¨Ì§Ì¤Ì«ÌžÌ¹Ì¬Ì­Ì­Ì¤ÌˆÌÌˆÌ’Í›Í’ÍÍ…â£¿Ì¸Ì¡ÌºÌ©Ì¯Í†Ì€Ì‰Í‘Ì” â €â €â €â¡¯â¡¯â¡¾â â ˜â €â €â €â €â €â €â €â €â €â €â €â €â €â €â¢Šâ ˜â¡®â££â ªâ ¢â¡‘â¡Œ\nâ €â €â €â Ÿâ â ˆâ €â €â €â ¡â €â  â¢ˆâ  â¢â¢ â¢‚â¢”â£â¢„â¡‚â¢”â €â¡â¢‰â ¸â¢¨â¢‘â •â¡Œ\nâ €â €â¡€â â €â €â €â¡€â¢‚â ¡â ˆâ¡”â£•â¢®â£³â¢¯â£¿â£»â£Ÿâ£¯â£¯â¢·â£«â£†â¡‚â €â €â¢â ‘â¡Œ\nâ¢€â  â â ˆâ €â¢€â¢‚â ¢â¡‚â •â¡â£â¢®â£³â¢½â¡½â£¾â£»â£¿â£¯â¡¯â£Ÿâ£žâ¢¾â¢œâ¢†â €â¡€â €â ª\nâ£¬â ‚â €â €â¢€â¢‚â¢ªâ ¨â¢‚â ¥â£ºâ¡ªâ£—â¢—â£½â¢½â¡¯â£¿â£½â£·â¢¿â¡½â¡¾â¡½â£â¢Žâ €â €â €â¢¡\nâ£¿â €â €â €â¢‚â ¢â¢‚â¢¥â¢±â¡¹â£ªâ¢žâ¡µâ£»â¡ªâ¡¯â¡¯â£Ÿâ¡¾â£¿â£»â¡½â£¯â¡»â£ªâ §â ‘â €â â¢\nâ£¿â €â €â €â ¢â¢‘â  â ‘â •â¡â¡Žâ¡—â¡â¡Žâ£žâ¢½â¡¹â£•â¢¯â¢»â ¹â¡¹â¢šâ â¡·â¡½â¡¨â €â €â¢”\nâ£¿â¡¯â €â¢ˆâ ˆâ¢„â ‚â ‚â â €â Œâ  â¢‘â ±â¡±â¡±â¡‘â¢”â â €â¡€â â â â¡¡â¡¹â£ªâ €â €â¢˜\nâ£¿â£½â €â¡€â¡Šâ €â â ¨â ˆâ¡â ‚â¢ˆâ  â¡±â¡½â£·â¡‘â â  â ‘â €â¢‰â¢‡â£¤â¢˜â£ªâ¢½â €â¢Œâ¢Ž\nâ£¿â¢¾â €â¢Œâ Œâ €â¡â ¢â ‚â â¡€â €â¢€â¢³â¢½â£½â¡ºâ£¨â¢„â£‘â¢‰â¢ƒâ¢­â¡²â£•â¡­â£¹â  â¢â¢—\nâ£¿â¡—â €â ¢â ¡â¡±â¡¸â£”â¢µâ¢±â¢¸â ˆâ €â¡ªâ£³â£³â¢¹â¢œâ¡µâ£±â¢±â¡±â£³â¡¹â£µâ£»â¢”â¢…â¢¬â¡·\nâ£·â¡‡â¡‚â ¡â¡‘â¢•â¢•â •â¡‘â ¡â¢‚â¢Šâ¢â¢•â¡â¡®â¡§â¡³â£â¢´â¡â£â ƒâ¡«â¡’â£•â¢â¡®â£·â¡Ÿ\nâ£·â£»â£…â ‘â¢Œâ ¢â â¢â  â ‘â¡â â Œâ¡ªâ ®â¡«â ªâ¡ªâ¡ªâ£ºâ¢¸â °â ¡â  â â¢±â ¨â¡ªâ¡ªâ¡°\nâ£¯â¢·â£Ÿâ£‡â¡‚â¡‚â¡Œâ¡€â €â â¡‚â …â ‚â €â¡‘â¡„â¢‡â ‡â¢â¡¨â¡ â¡â¢â  â¢€â¢ªâ¡â¡œâ¡ªâ¡Š\nâ£¿â¢½â¡¾â¢¹â¡„â •â¡…â¢‡â ‚â ‘â£´â¡¬â£¬â£¬â£†â¢®â£¦â£·â£µâ£·â¡—â¢ƒâ¢®â ±â¡¸â¢°â¢±â¢¸â¢¨â¢Œ\nâ£¯â¢¯â£Ÿâ ¸â£³â¡…â œâ ”â¡Œâ¡â ˆâ »â Ÿâ£¿â¢¿â£¿â£¿â ¿â¡»â£ƒâ ¢â£±â¡³â¡±â¡©â¢¢â £â¡ƒâ ¢â \nâ¡¯â£Ÿâ£žâ¡‡â¡¿â£½â¡ªâ¡˜â¡°â ¨â¢â¢€â ¢â¢¢â¢„â¢¤â£°â ¼â¡¾â¢•â¢•â¡µâ£â Žâ¢Œâ¢ªâ ªâ¡˜â¡Œâ €\nâ¡¯â£³â ¯â šâ¢Šâ ¡â¡‚â¢‚â ¨â Šâ ”â¡‘â ¬â¡¸â£˜â¢¬â¢ªâ£ªâ¡ºâ¡¼â£•â¢¯â¢žâ¢•â¢â Žâ¢»â¢¼â£€â €\nâ â¡‚â ”â¡â¡¢â £â¢€â ¢â €â …â ±â¡â¡±â¡˜â¡”â¡•â¡•â£²â¡¹â£Žâ¡®â¡â¡‘â¢œâ¢¼â¡±â¢©â£—â£¯â£Ÿ\nâ¢€â¢‚â¢‘â €â¡‚â¡ƒâ …â Šâ¢„â¢‘â  â ‘â¢•â¢•â¢â¢®â¢ºâ¢•â¢Ÿâ¢®â¢Šâ¢¢â¢±â¢„â ƒâ£‡â£žâ¢žâ£žâ¢¾\nâ¢€â ¢â¡‘â¡€â¢‚â¢Šâ  â â¡‚â¡â €â …â¡ˆâ ªâ ªâ ªâ £â «â ‘â¡â¢”â •â£œâ£œâ¢¦â¡°â¡Žâ¡¯â¡¾â¡½ â €â €â €â¡¯â¡¯â¡¾â â ˜â €â €â €â €â €â €â €â €â €â €â €â €â €â €â¢Šâ ˜â¡®â££â ªâ ¢â¡‘â¡Œ â €â €â €â Ÿâ â ˆâ €â €â €â ¡â €â  â¢ˆâ  â¢â¢ â¢‚â¢”â£â¢„â¡‚â¢”â €â¡â¢‰â ¸â¢¨â¢‘â •â¡Œ â €â €â¡€â â €â €â €â¡€â¢‚â ¡â ˆâ¡”â£•â¢®â£³â¢¯â£¿â£»â£Ÿâ£¯â£¯â¢·â£«â£†â¡‚â €â €â¢â ‘â¡Œ â¢€â  â â ˆâ €â¢€â¢‚â ¢â¡‚â •â¡â£â¢®â£³â¢½â¡½â£¾â£»â£¿â£¯â¡¯â£Ÿâ£žâ¢¾â¢œâ¢†â €â¡€â €â ª â£¬â ‚â €â €â¢€â¢‚â¢ªâ ¨â¢‚â ¥â£ºâ¡ªâ£—â¢—â£½â¢½â¡¯â£¿â£½â£·â¢¿â¡½â¡¾â¡½â£â¢Žâ €â €â €â¢¡ â£¿â €â €â €â¢‚â ¢â¢‚â¢¥â¢±â¡¹â£ªâ¢žâ¡µâ£»â¡ªâ¡¯â¡¯â£Ÿâ¡¾â£¿â£»â¡½â£¯â¡»â£ªâ §â ‘â €â â¢ â£¿â €â €â €â ¢â¢‘â  â ‘â •â¡â¡Žâ¡—â¡â¡Žâ£žâ¢½â¡¹â£•â¢¯â¢»â ¹â¡¹â¢šâ â¡·â¡½â¡¨â €â €â¢” â£¿â¡¯â €â¢ˆâ ˆâ¢„â ‚â ‚â â €â Œâ  â¢‘â ±â¡±â¡±â¡‘â¢”â â €â¡€â â â â¡¡â¡¹â£ªâ €â €â¢˜ â£¿â£½â €â¡€â¡Šâ €â â ¨â ˆâ¡â ‚â¢ˆâ  â¡±â¡½â£·â¡‘â â  â ‘â €â¢‰â¢‡â£¤â¢˜â£ªâ¢½â €â¢Œâ¢Ž â£¿â¢¾â €â¢Œâ Œâ €â¡â ¢â ‚â â¡€â €â¢€â¢³â¢½â£½â¡ºâ£¨â¢„â£‘â¢‰â¢ƒâ¢­â¡²â£•â¡­â£¹â  â¢â¢— â£¿â¡—â €â ¢â ¡â¡±â¡¸â£”â¢µâ¢±â¢¸â ˆâ €â¡ªâ£³â£³â¢¹â¢œâ¡µâ£±â¢±â¡±â£³â¡¹â£µâ£»â¢”â¢…â¢¬â¡· â£·â¡‡â¡‚â ¡â¡‘â¢•â¢•â •â¡‘â ¡â¢‚â¢Šâ¢â¢•â¡â¡®â¡§â¡³â£â¢´â¡â£â ƒâ¡«â¡’â£•â¢â¡®â£·â¡Ÿ â£·â£»â£…â ‘â¢Œâ ¢â â¢â  â ‘â¡â â Œâ¡ªâ ®â¡«â ªâ¡ªâ¡ªâ£ºâ¢¸â °â ¡â  â â¢±â ¨â¡ªâ¡ªâ¡° â£¯â¢·â£Ÿâ£‡â¡‚â¡‚â¡Œâ¡€â €â â¡‚â …â ‚â €â¡‘â¡„â¢‡â ‡â¢â¡¨â¡ â¡â¢â  â¢€â¢ªâ¡â¡œâ¡ªâ¡Š â£¿â¢½â¡¾â¢¹â¡„â •â¡…â¢‡â ‚â ‘â£´â¡¬â£¬â£¬â£†â¢®â£¦â£·â£µâ£·â¡—â¢ƒâ¢®â ±â¡¸â¢°â¢±â¢¸â¢¨â¢Œ â£¯â¢¯â£Ÿâ ¸â£³â¡…â œâ ”â¡Œâ¡â ˆâ »â Ÿâ£¿â¢¿â£¿â£¿â ¿â¡»â£ƒâ ¢â£±â¡³â¡±â¡©â¢¢â £â¡ƒâ ¢â  â¡¯â£Ÿâ£žâ¡‡â¡¿â£½â¡ªâ¡˜â¡°â ¨â¢â¢€â ¢â¢¢â¢„â¢¤â£°â ¼â¡¾â¢•â¢•â¡µâ£â Žâ¢Œâ¢ªâ ªâ¡˜â¡Œâ € â¡¯â£³â ¯â šâ¢Šâ ¡â¡‚â¢‚â ¨â Šâ ”â¡‘â ¬â¡¸â£˜â¢¬â¢ªâ£ªâ¡ºâ¡¼â£•â¢¯â¢žâ¢•â¢â Žâ¢»â¢¼â£€â € â €â €â €â¡¯â¡¯â¡¾â â ˜â €â €â €â €â €â €â €â €â €â €â €â €â €â €â¢Šâ ˜â¡®â££â ªâ ¢â¡‘â¡Œ â €â €â €â Ÿâ â ˆâ €â €â €â ¡â €â  â¢ˆâ  â¢â¢ â¢‚â¢”â£â¢„â¡‚â¢”â €â¡â¢‰â ¸â¢¨â¢‘â •â¡Œ â €â €â¡€â â €â €â €â¡€â¢‚â ¡â ˆâ¡”â£•â¢®â£³â¢¯â£¿â£»â£Ÿâ£¯â£¯â¢·â£«â£†â¡‚â €â €â¢â ‘â¡Œ â¢€â  â â ˆâ €â¢€â¢‚â ¢â¡‚â •â¡â£â¢®â£³â¢½â¡½â£¾â£»â£¿â£¯â¡¯â£Ÿâ£žâ¢¾â¢œâ¢†â €â¡€â €â ª â£¬â ‚â €â €â¢€â¢‚â¢ªâ ¨â¢‚â ¥â£ºâ¡ªâ£—â¢—â£½â¢½â¡¯â£¿â£½â£·â¢¿â¡½â¡¾â¡½â£â¢Žâ €â €â €â¢¡ â£¿â €â €â €â¢‚â ¢â¢‚â¢¥â¢±â¡¹â£ªâ¢žâ¡µâ£»â¡ªâ¡¯â¡¯â£Ÿâ¡¾â£¿â£»â¡½â£¯â¡»â£ªâ §â ‘â €â â¢ â£¿â €â €â €â ¢â¢‘â  â ‘â •â¡â¡Žâ¡—â¡â¡Žâ£žâ¢½â¡¹â£•â¢¯â¢»â ¹â¡¹â¢šâ â¡·â¡½â¡¨â €â €â¢” â£¿â¡¯â €â¢ˆâ ˆâ¢„â ‚â ‚â â €â Œâ  â¢‘â ±â¡±â¡±â¡‘â¢”â â €â¡€â â â â¡¡â¡¹â£ªâ €â €â¢˜ â£¿â£½â €â¡€â¡Šâ €â â ¨â ˆâ¡â ‚â¢ˆâ  â¡±â¡½â£·â¡‘â â  â ‘â €â¢‰â¢‡â£¤â¢˜â£ªâ¢½â €â¢Œâ¢Ž â£¿â¢¾â €â¢Œâ Œâ €â¡â ¢â ‚â â¡€â €â¢€â¢³â¢½â£½â¡ºâ£¨â¢„â£‘â¢‰â¢ƒâ¢­â¡²â£•â¡­â£¹â  â¢â¢— â£¿â¡—â €â ¢â ¡â¡±â¡¸â£”â¢µâ¢±â¢¸â ˆâ €â¡ªâ£³â£³â¢¹â¢œâ¡µâ£±â¢±â¡±â£³â¡¹â£µâ£»â¢”â¢…â¢¬â¡· â£·â¡‡â¡‚â ¡â¡‘â¢•â¢•â •â¡‘â ¡â¢‚â¢Šâ¢â¢•â¡â¡®â¡§â¡³â£â¢´â¡â£â ƒâ¡«â¡’â£•â¢â¡®â£·â¡Ÿ â£·â£»â£…â ‘â¢Œâ ¢â â¢â  â ‘â¡â â Œâ¡ªâ ®â¡«â ªâ¡ªâ¡ªâ£ºâ¢¸â °â ¡â  â â¢±â ¨â¡ªâ¡ªâ¡° â£¯â¢·â£Ÿâ£‡â¡‚â¡‚â¡Œâ¡€â €â â¡‚â …â ‚â €â¡‘â¡„â¢‡â ‡â¢â¡¨â¡ â¡â¢â  â¢€â¢ªâ¡â¡œâ¡ªâ¡Š â£¿â¢½â¡¾â¢¹â¡„â •â¡…â¢‡â ‚â ‘â£´â¡¬â£¬â£¬â£†â¢®â£¦â£·â£µâ£·â¡—â¢ƒâ¢®â ±â¡¸â¢°â¢±â¢¸â¢¨â¢Œ â£¯â¢¯â£Ÿâ ¸â£³â¡…â œâ ”â¡Œâ¡â ˆâ »â Ÿâ£¿â¢¿â£¿â£¿â ¿â¡»â£ƒâ ¢â£±â¡³â¡±â¡©â¢¢â £â¡ƒâ ¢â  â¡¯â£Ÿâ£žâ¡‡â¡¿â£½â¡ªâ¡˜â¡°â ¨â¢â¢€â ¢â¢¢â¢„â¢¤â£°â ¼â¡¾â¢•â¢•â¡µâ£â Žâ¢Œâ¢ªâ ªâ¡˜â¡Œâ € â¡¯â£³â ¯â šâ¢Šâ ¡â¡‚â¢‚â ¨â Šâ ”â¡‘â ¬â¡¸â£˜â¢¬â¢ªâ£ªâ¡ºâ¡¼â£•â¢¯â¢žâ¢•â¢â Žâ¢»â¢¼â£€â € â â¡‚â ”â¡â¡¢â £â¢€â ¢â €â …â ±â¡â¡±â¡˜â¡”â¡•â¡•â£²â¡¹â£Žâ¡®â¡â¡‘â¢œâ¢¼â¡±â¢©â£—â£¯â£Ÿ â¢€â¢‚â¢‘â €â¡‚â¡ƒâ …â Šâ¢„â¢‘â  â ‘â¢•â¢•â¢â¢®â¢ºâ¢•â¢Ÿâ¢®â¢Šâ¢¢â¢±â¢„â ƒâ£‡â£žâ¢žâ£žâ¢¾ â¢€â ¢â¡‘â¡€â¢‚â¢Šâ  â â¡‚â¡â €â …â¡ˆâ ªâ ªâ ªâ £â «â ‘â¡â¢”â •â£œâ£œâ¢¦â¡°â¡Žâ¡¯â¡¾â¡½ â¢€â¢‚â¢‘â €â¡‚â¡ƒâ …â Šâ¢„â¢‘â  â ‘â¢•â¢•â¢â¢®â¢ºâ¢•â¢Ÿâ¢®â¢Šâ¢¢â¢±â¢„â ƒâ£‡â£žâ¢žâ£žâ¢¾ â¢€â ¢â¡‘â¡€â¢‚â¢Šâ  â â¡‚â¡â €â …â¡ˆâ ªâ ªâ ªâ £â «â ‘â¡â¢”â •â£œâ£œâ¢¦â¡°â¡Žâ¡¯â¡¾â¡½ AMOGUS When the machine elf is sus! O\\_O Amogn susðŸ˜³ I feel bad for my friends who are sensitive to bright colours :( POV: Syd Barrett",
    "As JP as it can get  Kapital jacket\n\nUU tee\n\nUndercover denim\n\nvisvim Grizzly Jacket is fire Okay but I like the mask too tho. Dem jacket ðŸ§¡ðŸ§¡ Americana at its best! Jesus man. Flames. What season/name is the UC denim? haha only thing missing is a goros necklace ðŸ™„ Fire ðŸ”¥ Omg this jacket is lit dude Red Yarns fire",
    "Senior Military Leaders Thrash Tucker Carlson for Mocking Female Service Members  *when you're dying on the battlefield. You're not gonna say \"Give me a straight white Christian medic\", you're gonna be screaming to get a fucking medic because you're fucking dying*\n\n-My dad. [FOX paid their lawyers to prove **in a court of law** Tucker Carlson is full of shit and cannot be relied on to ever tell the truth](https://www.npr.org/2020/09/29/917747123/you-literally-cant-believe-the-facts-tucker-carlson-tells-you-so-say-fox-s-lawye) are conservatives about to pivot to being anti-military? Solution is simple. Let Tucker go hand to hand with any female marine who volunteers to take him on. \n\nLet's see who would keep the country safer. I'd gladly pay to see him get his face rearranged. As a woman doing a typically male-dominated job I canâ€™t tell you how pleased I am that a major institution is taking well fitting clothes and equipment seriously. \n\nIn my current job I can largely buy whatever PPE I like and claim back the cost so I can make sure itâ€™s fit for purpose and fits. In my last job the company took a â€˜one size fits allâ€™ approach and all the PPE was for men. It was too big, got in the way, and in the case of a wet weather coat the zip broke on the the third use. This happened to every woman who wore this coat. Why? Because instead of being a short coat it came down to our knees so when you bent over- the zip popped off. \n\nPPE, uniforms and equipment need to fit for them to be fit for purpose. [removed] The classic â€œinsult someone/something by calling them female!â€, got to love it ðŸ¤¢ I'm just so infuriated by his comments as a Naval Officer. Fighter jets don't care about my gender when I fly! Unlike what some American's think, lethality is not dependent on gender. Such a antiquated way of thinking, and apparently shame on us for wanting better fitting uniforms. Even Fox News says that only morons take Tucker Carlson seriously. The sad part is, there are a lot of morons in America. When I (White Male) went through Officer Candiate School, my Staff Sergeant was female and I would have followed her anywhere.",
    "Description of Rentech's infrastructure a decade ago from old marketing material  Me: I need you to execute arbitrage orders at 10 different exchanges on millisecond latency\n\nMy macbook pro: ðŸ˜‚ I would bet this legacy tech is still there Can it run Crysis? This is what Iâ€™m up against!!!! This was the marketing deck for the long short fund (the fund that had a tough time last year with big redemptions) not the more famous Medallion fund. I remember at the time they had a young fellow (an MIT grad, naturally) run some backtests (with results presented of course in LaTex math font!) for a few months to come up with this long short strategy. I recall in some materials seeing that the backtests started right around the time that earnings surprise data sets started (late 80s) and my conjecture at the time was eps surprise may have had a role.  I don't think many people know what Medallion actually does, although on my humble wordpress I took at stab at a thought experiment that shows how a highly levered high frequency strategy could gets results like they put up! All this to possibly lose billions when retail goes full irrational on a dying retailer.  Jokes aside this kind of infrastructure is incredible.  And probably very expensive to build / upkeep Just upgraded to this beast Threadripper. On 64gb RAM finally. Keen to learn SQL. Going all serious from here think I might treat myself with a $100/mo data sub ðŸ¤¡ ðŸ¤¡ ðŸ¤¡ ðŸ¤¡ ðŸ¤¡ 600 processing core??? Man my laptop has 1. Not for nothing, but even 10 years ago the 6800 Sunfires were still a decade old. Seem like the Minimum Requirements for games on the backside of the cover",
    "Awesome Tricks And Best Practices From Kaggle  [removed] I'm fairly fluent with Pandas, but I did not know about [styling](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html), so that's useful. I'm starting with my data scientist journey and a friend recommended me Kaggle. I feel like this post is gold for understanding the page. Thank you! Nice for configuring global settings in matplotlib Much appreciated Why would you use matplotlib over say plotly? Nothing shittier than having a chart make you second guess some values behind a visualized data point instead of revealing that with a hover. Or have I missed something and seaborn is now interactive? Nice! This was surprisingly useful.  Thanks! For the last one, with Python 3 `raw_input` has been replaced by `input`, and there is no use for the lambdas. You can rewrite it as\n\n    result = map(int, input().split()) Thanks for writing this out.  One other thing: `print` is now a function only, so it will need parentheses.",
    "Unreliable Life? Has anyone tried Conwayâ€™s classic Life algorithm with a stochastic/chaotic element? Basically modifying the rules to include a tiny bit of randomness (simulating quantum vacuum effects, kind of?). Most of the chaos would result in solo pixels appearing randomly that would just die out in the next generation, but occasionally they would interfere with stable structures (gliders and glider guns and so forth), mutating the structures.\n\nWhat new kinds mega structures would emerge that are resilient to mutation, self-replicating and self-repairing?\n\nSeems like someone may have tried this, please share links/clues to any similar efforts. If anyone has a favorite high-performance browser implementation that I could add this functionality to, let me know. I found a Youtube video that shows what it looks like to add randomness to GoL: [https://www.youtube.com/watch?v=4dNwIjJCRz0](https://www.youtube.com/watch?v=4dNwIjJCRz0)\n\nNot sure if it was explored in depth but it could be interesting. [deleted] [deleted] Have a look at this:  \n\n\n[https://softologyblog.wordpress.com/2018/05/12/stochastic-cellular-automata/](https://softologyblog.wordpress.com/2018/05/12/stochastic-cellular-automata/) i feel like the fun of the game of life is in creating â€œlifeâ€ and a random mutation inevitably â€œkillingâ€ them just doesnâ€™t sound very appealing Cool! If it feels like something you want to do, then do it. No pressure from me. That *is* interesting! So much smaller than I expected a resiliant structure to be. Thanks for sharing! Yes! Thatâ€™s definitely exploring the same idea space. The more I look into it, the more I feel like the real problem is that we have no reasonable tools for designing and â€œcompilingâ€ structures that are orders of magnitude more complicated than the big spaceships. Life in Life comes close, but even those structures require perfection in each iteration. I think the place to start may be with the mega-construction tool chain... When I saw the Life implemented in Life video (https://youtu.be/xP5-iIeKXE8) it got me thinking about really large, self-healing, structures. Imagine spaceship glider guns roaming repair corridors, spraying gliders into damaged areas in some massively large structure. Weâ€™d need meta structures and specialized assembly systems to create the start condition.",
    "Learning from my losses in Data Science Comeptitions [removed] new developments - op is a reinforcement learning bot Just from reading this I would bet money that OP is from the Indian subcontinent Great approach to improvement, learning from your loss is what machine learning is all about, isn't it? I gave up on such competitions after one competition where:  \n\\-One of our team's judges was on their phone the entire  presentation (really tall dude in my group could see the phone and they were on IG).  \n\\-We didn't have enough time to finish our presentation despite others getting more than double our time.   \n\n\n\\-One of the finalists had the same idea as us but didn't use any of the actual data provided for modeling, didn't show results, and with none of the slick, interactive, hand coded visuals (D3) for the dataset that we had. They literally made a PP with graphs, and pie charts off google images, added labels and just described the idea.  \n\n\nThat's not to say these competitions are bad, but just be aware that fake accuracy scores (99.8%) from overfitting/leaky validation/very imbalanced data, complex sounding models with long names, and getting assigned the right judge can take you pretty far. Just don't lose. Problem solved Hey this is a random question but are you employed currently? Where do you find the time for your projects? Op your edits are fucking hilarious. Why are you so insecure? Very informative. Thanks Play to win or die. [deleted]",
    "LPT: leave the door on your washing machine open after using it to prevent a moldy, smelly washer. Since this thread is getting a lot of attention I'd like to bring up some other good points that we've discussed in the comments below. [keep in mind these tips also apply to your dishwasher as well including leaving it open to dry out].\n\n1. Run an empty load at least once a month with hot water and bleach or vinegar or with a specialty made washing/dishwasher cleaning fluid.\n\n2. In the bottom of your washing machine there is usually a trap to catch small objects right before the pump. It should be checked and cleaned out at least every couple of months. You'll find all those old socks you lost in there and they're going to be gross as hell.\n\n3. The above goes for your dishwasher as well. There's a trap underneath the jets at the bottom that is made to be disassembled and cleaned. If you've never done it before CAUTION it's gonna be super nasty.\n\nAnd 4. Be careful how much fluid you're putting into your machine, too much can cause the buildup of soap scum/goo. Hello and welcome to r/LifeProTips!\n\nPlease help us decide if this post is a good fit for the subreddit by up or downvoting this comment. \n\nIf you think that this is great advice to improve your life, please upvote. If you think this doesn't help you in any way, please downvote. If you don't care, leave it for the others to decide. The main cause of mold and mildew in your washing machine (especially Front Load) is due to using too much detergent. \n\n2 tablespoons of detergent all you need.\n\nBecause most washing machines are high efficiency, they use less water and too much detergent won't rinse out of the tub leaving a perfect environment for mold and mildew to grow.\n\nSource: I work for a major appliance manufacturer. Yep and leave the door to your dryer closed so your cat doesn't climb in! And also open the drawer where you put the soap in Also be careful with those condensed liquid soaps if you only wash in cold water, I couldn't find the source of my top load washers funky smell until I pulled the drum basket and found out the exterior of it was covered in a gross film of detergent goo that built up over a long time. Well also you need to wash them about once a month. That helps a lot. My manual also says to run it through a \"cleaning cycle\" (no clothing, hot water, deep fill) with a special cleaning detergent you can buy, or they alternatively suggest using bleach.\n\nBleach is much cheaper, just run a bleach load and then another empty load with just water to rinse it out well.\nMold and mildew is a major concern, in tropical climates especially, but doing this once a month seems to eliminate the problem entirely - unless I forget there's a load in the wash for more than 24 hours.\n\nCheck your manual for proper care and cleaning instructions, it's in there. Tl;Dr at bottom\n\nI moved into this house that had a top loading washer in the basement. Last renters were gross juggalos who let dogs and cats pass and shit all over the house. Anyway, my housemate got a new set of sheets, pillowcases, and a quilt for his queen size mattress. Well his dumbass shoved ALL OF IT in the washing machine at once and broke it. A week later I need to do laundry and all he has to say is \"why is it my problem, its the landlords equipment that failed. And no, I haven't contacted him.\"\n\nSo I spend my day taking apart this washing machine. I honestly don't know how I fixed it, I literally just took the whole fucking thing apart and put it back together from a YouTube video step by step trying to identify the problem without actually finding one but mending it anyway so ðŸ¤·â€â™€ï¸. When I removed the inside tumbler from the outer parts that actually holds all the water, it was the absolute grossest collection of dreadlock chunks, cat hair, dog hair, just imagine unplugging the nastiest shower drain ever, and that's what was covering the insides of the plastic waster basin.\n\nTl;Dr - took tumbler out of washer in rented home, gross animal and human hair covered the sides of water basin. Oh wow an actually useful LPT. Usually LPTs are more like â€œif someone does your laundry, make sure to thank them. It will make their day better.â€ Also run your hottest available cycle, with no detergent or anything in there, dont reduce the time of the cycle, let it run through. It will help to clean out your machine.",
    "Airbnb datasets Hello everyone, looking for Airbnb datasets (2019-2021) for major European cities, can anyone help me with this?\nThank you in advance. Hey damjaanko,\n\nI believe a `request` flair might be more appropriate for such post. Please re-consider and change the post flair if needed.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/datasets) if you have any questions or concerns.* [http://insideairbnb.com/](http://insideairbnb.com/) Thank you.\nIs the date compiled indicating the day when it was collected last or specifically referring to that day? I have not used the data a lot, but from what I saw for a couple of listings there is no info about the collection date. There is an archive for each city and they appear to update it monthly.",
    "Public datasets Iâ€™m trying to determine the impact of self efficacy along with other emotions on judgement and decision making using regression analysis. What datasets can I easily obtain that would allow me to measure emotions empirically? I mostly see qualitative studies done on emotion. Any suggestion or feedback is greatly appreciated. Iâ€™m not sure if the combination of data youâ€™re looking for exists, but search for datasets containing the Positive and Negative Affect Schedule (PANAS) scales. The PANAS scales are one of the most widely used and empirically-validated psychological measures of positive and negative emotion. Since itâ€™s been used so much, youâ€™re bound to find some publicly available data linked to it They also give you (continuous) quantitative data for emotion Sounds very promising!! Thank you so much. I appreciate it.",
    "[N] 20 hours of new lectures on Deep Learning and Reinforcement Learning with lots of examples If anyone's interested in a Deep Learning and Reinforcement Learning series, I uploaded 20 hours of lectures on YouTube yesterday. Compared to other lectures, I think this gives quite a broad/compact overview of the fields with lots of minimal examples to build on. Here are the links:\n\n**Deep Learning** ([playlist](https://www.youtube.com/playlist?list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57))  \n*The first five lectures are more theoretical, the second half is more applied.*\n\n* Lecture 1: Introduction. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture1.pdf), [video](https://www.youtube.com/watch?v=s2uXPz3wyCk&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=1))\n* Lecture 2: Mathematical principles and backpropagation. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture2.pdf), [colab](https://colab.research.google.com/gist/cwkx/dfa207c8ceed5999bdad1ec6f637dd47/distributions.ipynb), [video](https://www.youtube.com/watch?v=dfZ0cIQSjm4&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=2))\n* Lecture 3: PyTorch programming: *coding session*. ([colab1](https://colab.research.google.com/gist/cwkx/441e508d3b904413fd3950a09a1d3bd6/classifier.ipynb), [colab2](https://colab.research.google.com/gist/cwkx/3a6eba039aa9f68d0b9d37a02216d385/convnet.ipynb), [video](https://www.youtube.com/watch?v=KiqXWOcz4Z0&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=3)) - minor issues with audio, but it fixes itself later.\n* Lecture 4: Designing models to generalise. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture4.pdf), [video](https://www.youtube.com/watch?v=4vKKj8bkS-E&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=4))\n* Lecture 5: Generative models. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture5.pdf), [desmos](https://www.desmos.com/calculator/2sboqbhler), [colab](https://colab.research.google.com/gist/cwkx/e3ef25d0adb6e2f2bf747ce664bab318/conv-autoencoder.ipynb), [video](https://www.youtube.com/watch?v=hyxlTwvLi-o&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=5))\n* Lecture 6: Adversarial models. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture6.pdf), [colab1](https://colab.research.google.com/gist/cwkx/74e33bc96f94f381bd15032d57e43786/simple-gan.ipynb), [colab2](https://colab.research.google.com/gist/cwkx/348cde3bf11a08c45a69b1873ebb6de3/conditional-gan.ipynb), [colab3](https://colab.research.google.com/gist/cwkx/7f5377ed8414a096180128b487846698/info-gan.ipynb), [colab4](https://colab.research.google.com/gist/cwkx/aece978bc38ba35c2267d91b793a1456/unet.ipynb), [video](https://www.youtube.com/watch?v=JLHyU7AjB4s&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=6))\n* Lecture 7: Energy-based models. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture7.pdf), [colab](https://colab.research.google.com/gist/cwkx/6b2d802e804e908a3ee3d58c1e0e73be/dbm.ipynb), [video](https://www.youtube.com/watch?v=kpulMklVmRU&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=7))\n* Lecture 8: Sequential models: *by* u/samb-t. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture8.pdf), [colab1](https://colab.research.google.com/gist/samb-t/ac6dbd433c618eedcd0442f577697ea3/generative-rnn.ipynb), [colab2](https://colab.research.google.com/gist/samb-t/27cc3217799825975b65326d6e7b377b/transformer-translation.ipynb), [video](https://www.youtube.com/watch?v=pxRnFwNFTOM&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=8))\n* Lecture 9: Flow models and implicit networks. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture9.pdf), [SIREN](https://vsitzmann.github.io/siren/), [GON](https://cwkx.github.io/data/GON/), [video](https://www.youtube.com/watch?v=zRdwh9C5xn4&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=9))\n* Lecture 10: Meta and manifold learning. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/dl-lecture10.pdf), [interview](https://youtu.be/PqbB07n_uQ4?t=444), [video](https://www.youtube.com/watch?v=na1-oIn8Kdo&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57&index=10))\n\n**Reinforcement Learning** ([playlist](https://www.youtube.com/playlist?list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE))  \n*This is based on David Silver's course but targeting younger students within a shorter 50min format (missing the advanced derivations) + more examples and Colab code.*\n\n* Lecture 1: Foundations. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture1.pdf), [video](https://www.youtube.com/watch?v=K67RJH3V7Yw&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=1))\n* Lecture 2: Markov decision processes. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture2.pdf), [colab](https://colab.research.google.com/gist/cwkx/ba6c44031137575d2445901ee90454da/mrp.ipynb), [video](https://www.youtube.com/watch?v=RmOdTQYQqmQ&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=2))\n* Lecture 3: OpenAI gym. ([video](https://www.youtube.com/watch?v=BNSwFURmaCA&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=3))\n* Lecture 4: Dynamic programming. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture4.pdf), [colab](https://colab.research.google.com/gist/cwkx/670c8d44a9a342355a4a883c498dbc9d/dynamic-programming.ipynb), [video](https://www.youtube.com/watch?v=gqC_p2XWpLU&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=4))\n* Lecture 5: Monte Carlo methods. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture5.pdf), [colab](https://colab.research.google.com/gist/cwkx/a5129e8888562d1b4ecb0da611c58ce8/monte-carlo-methods.ipynb), [video](https://www.youtube.com/watch?v=4xfWzLmIccs&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=5))\n* Lecture 6: Temporal-difference methods. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture6.pdf), [colab](https://colab.research.google.com/gist/cwkx/54e2e6d59918a083e47f19404fe275b4/temporal-difference-learning.ipynb), [video](https://www.youtube.com/watch?v=phgI_880uSw&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=6))\n* Lecture 7: Function approximation. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture7.pdf), [code](https://github.com/higgsfield/RL-Adventure), [video](https://www.youtube.com/watch?v=oqmCj95d3Y4&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=7))\n* Lecture 8: Policy gradient methods. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture8.pdf), [code](https://github.com/higgsfield/RL-Adventure-2), [theory](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html), [video](https://www.youtube.com/watch?v=h4HixR0Co6Q&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=8))\n* Lecture 9: Model-based methods. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture9.pdf), [video](https://www.youtube.com/watch?v=aUjuBvqJ8UM&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=9))\n* Lecture 10: Extended methods. ([slides](https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture10.pdf), [atari](https://www.youtube.com/playlist?list=PL34t13IwtOXUNliyyJtoamekLAbqhB9Il), [video](https://www.youtube.com/watch?v=w6rGqprrxp8&list=PLMsTLcO6ettgmyLVrcPvFLYi2Rs-R4JOE&index=10)) Does the series focus primarily on code or theory? This is awesome, thank you! I just ordered Sutton and Barto, so will be great to follow along with. the deep learning slides are sooo good. exactly what they need to be on Awesome thanks for sharing!! Thanks mate ! You are a hero with a cape ! Thank you! :) Thank you for sharing, this is wonderful for beginners What are the prereqs for learning reinforcement learning? Do I have to be really good at most of the DL architectures before learning about RL? Thanks l! Nice, tks",
    "All three of my sour stompers pulled over a half pound each dry of some fire nug in soil. Plant 1 pulled 269.1 day 75. Plant 2 pulled 228 day 89 and Plant 3 pulled 283.5 day 89. Also got like qp of tight trimmings and like 2zips of kief.  What kind of lights and medium Iâ€™m over here growing with a Hasbro Easy Bake Oven, while this guyâ€™s cooking with the OVENATOR 3000. In all seriousness, that HLG 650R is a monster, no wonder youâ€™re pulling that weight! Amazing grow, those buds are looking real frosty. Can you explain your trimming process? Those buds look awesome. Beauty this is one of my favorite strains Fantastic! Nice work You got some green thumbs sir Thatâ€™s fucking awesome did you train them at all or just let them go Looks dank How often did you feed? You voted great results. did u use side lighting?",
    "Implement the KNN algorithm from scratch | Python for Data Science and Machine Learning  Thanks for the video! I already have it saved. :) Thx !!! Thx !!! We just covered this today in class. Lmao what a coincidence I did too :) Why would you build this when you can use the sklearn library? I am not asking it rhetorically I really want to know why Somebody please do advanced stuff. I am tired of scratch build videos of the same things over and over again. [removed] do it yourself Go on",
    "Anything more?  [removed] Fuck finnish linux manual all my homies write everything in stone with other stone Fuck imagination - I just scream directly into the serial bus at 9600 baud. [Rich](https://github.com/willmcgugan/rich) is a  Python based terminal manager that's more bells and whistles than *ncurses*.\n\n[Here](https://drewdevault.com/2019/10/30/Line-printer-shell-hack.html) is a hack to the old line printer terminal days of Linux.\n\n[Suomi man pages](https://mandoc.dev/fi/).\n\nWith linux, there's always a way to scratch that itch. Fuck Manuals, we just imagine a Turing Machine in our brains. OMG I just saw that post mentally using ssh to control others peoples computers and writing directly to there system in machine code Every DE uses a WM Personally I do all the calculations by hand and use coloured pencils to draw the gui This was just 2 posts below you thought it was appropriate https://www.reddit.com/r/unixporn/comments/lmcseh/agetty_ubuntu_mate_from_my_thermal_paper_terminal",
    "In 'Donnie Darko' (2001), Donnie's teacher says a famous linguist once said out of all the combinations of words, \"cellar door\" is the most beautiful. That famous linguist was JRR Tolkien in a 1955 lecture.  Hi! This is our new Moviedetailsmodbot!\n\n---\n\nIf this post fits /r/MovieDetails, **UPVOTE** this comment!!\n\nIf this post does not fit /r/MovieDetails, **DOWNVOTE** This comment!\n\nIf this post breaks the rules, **DOWNVOTE** this comment and **REPORT** the post! I didn't remember that scene, but the power metal band Cellador named themselves that for the same reason, which is how I learned about Tolkien's appreciation for those words. Why is â€œcellar doorâ€ so beautiful? That teacher? Drew Barrymore The first time I saw this scene, I thought the linguist definitely never heard those words coming out of Drew Barrymore's mouth lol Funny that the -dor ending was not uncommon for naming in Tolkienâ€™s world.  He certainly tried it out in a lot of different ways. In a critical scene, Frank, who wears a demented rabbit costume, runs over Donnie's girlfriend in his red Trans Am.\n\n\nhttps://i.imgur.com/6cZW1qZ.png\n\n\n\nIn the film's opening scene Donnie rides his bike into town and passes Frank in the same red Trans Am at the same time the soundtrack lyric \"Killing time\" is played.\n\n\n\n\n\nhttps://youtu.be/76IkuYLoJkE?t=122 Can someone explain this movie to me please Didn't George RR Martin also incorporate this in ASOIAF when Bran Stark hid from Theon in Winterfell? Specifically, the sequence involves the cellar door being stuck when attempting to leave the hiding spot. The movie *Tolkien* develops the word at some length: \n\n [Tolkien Movie Clip - Cellar Door (2019) | Movieclips Coming Soon - YouTube](https://www.youtube.com/watch?v=Vc4yFWI0ObE) \n\nAs this scene begins, Tolkien has already introduced the word and is being \"ruthlessly interrogated\" about its meaning.",
    "How to understand this equation and how is it applied?  I like to figure stuff out like this with a combination of the type theory perspective, and plugging in a few numbers for intuition.\n\nSo to start:\n\nE := set of environments. As an example, let's take the set of stages in world one of super Mario brothers. E := {1-1, ... 1-4}. That means mu (an element of E) would be things like 1-1, or 1-3. There's 4 total with this example.\n\nK := E -> R. Meaning that K is a function taking in elements of E (takes in an environment) and spits out a number of some kind.\n\nLast piece:\nLet's consider 'V' to be a function that takes in a policy (the actions of the intelligence we're judging) and an environment.\n\nFor example, let's consider two policies. One always walks to the left, and is hard coded to jump if there's a hole or an enemy within 20 horizontal pixels. The other is agent 57, or some other trained RL agent. I'll assume high V means the given policy is good, low means it's bad. So V(agent57, 1-1) might be 100, and V(heuristics, 1-4) might be 2, just for some examples.\n\nThat means our summation has 4 terms (one for each level). Complexity only depends on the level apparently. I assume that's for measuring 'easy' levels differently than 'hard' levels. I don't know what kind of values K gives, but if it's a bigger number for harder levels, that means harder levels add less to the final measure. If you get smaller K values for harder levels, then harder levels contribute more. You get all that from the negative exponent. Consider 2^-1 vs 2^0 vs 2^-(-1) for example. K(1-1) (the complexity value of the first level) would cut that level's contribution by half if K(1-1)=1, it'd make no change if K(1-1)=0, and it'd double the contribution if K(1-1)=-1. Hopefully the suggested properties of K are mentioned somewhere.\n\nFinally, to finish our example, you might come up with the values of K for all 4 levels, and for V for both policies and all 4 levels. You can then take those 12 numbers and see what the measure would be in our little example, to get a feel for it.\n\nI haven't done much with reinforcement learning, so I don't know where you'd see this equation practically used, if anywhere. I don't know that it's super important to deeply understand it, it could be just there to kind of gesture vaguely at the ideas I gave above. Unfortunately in AI stuff, you often see half explained equations, and think 'mathematicians would get this, I must be stupid' but that's not it at all. If that above equation is just meant to help with understanding, it could have been done a lot better. Ah well... If you're going to deeply understand an RL equation, the bellman equation's the one to keep an eye out for.\n\nGood luck! What book is this in, if you don't mind my asking? It's just meaningless abuse of mathematical formalism to give an appearance of credibility Imho: using pi as a variable deserves high penalty. In English, it claims that intelligence scales with the capacity to derive value from some sample of complex environments. I suspect value has a supplied/specific definition, because value in the traditional sense is not often considered in these definitions. The focus is usually goal-oriented, and not value-gain-oriented, though there may be some crossover. Learnt this kind of math back in school and am doing ml now and am brushing the dust of equations, going back to books. Lol This is from a video on multi agent learning.\n\nI don't understand why they say resourcefulness=intelligence, I think it's more to it, but resourcefulness is important for sure I would interpret it as the expected value of an agent (pi)  across all environments (mu) of varying complexity. \n\nThe value derived depends on the agent as well as the environment, but the complexity is the same for all agents.\n\nNote that if an agent has a constant value across all environments, the highly complex environments add exponentially less to intelligence than the less complex one, which you might interpret as someone being good at many things, but not extremely good at one thing. \n\nThis seems to get at a concept of â€œgeneral intelligenceâ€ given the harsh complexity penalty.  After all, ML algorithms are already pretty good at complex systems that are small in scope. I presume K is for complexity, say number of parameters, or mu is parameters and K is complexity as depending on number of parameters or other complexity measure. Negative exponent, so more complexity needed to achieve goal means less intelligence. Someone give this guy an award lol. Seriously tho, you explained it really well! Thanks a lot :) Take my poor man's gold ðŸŽ–ï¸ðŸ…ðŸ†ðŸ¥‡",
    "Travelling Salesman Problem - Why is the complexity O(n^2 * 2^n)? Why is the complexity of the tsp() method below O(n^2 * 2^n)? It only iterates n-times and each iteration does 2^n recursive calls, which means the time complexity is O(n * 2^n)?\n\n\t\tpublic class Graph<T> {\n\t\t\n\t\t\tprivate T[] vertices;\n\t\t\tprivate double weights[][];\n\t\t\tprivate Integer[][] prev;\n\t\t\tprivate Double[][] memo;\n\t\t\t\n\t\t\tpublic Graph(T[] vertices, double[][] weights) {\n\t\t\t\tthis.vertices = vertices;\n\t\t\t\tthis.weights = weights;\n\t\t\t\tprev = new Integer[vertices.length][1 << vertices.length];\n\t\t\t    memo = new Double[vertices.length][1 << vertices.length];\n\t\t\t}\n\t\t\t\t\n\t\t\tpublic ArrayList<T> tour(int startNode) {\n\t\t\t\t\n\t\t\t\tArrayList<T> tour = new ArrayList<>();\n\t\t\t\tint state = 1 << startNode;\n\t\t\t\ttsp(startNode, state, startNode);\n\t\t\n\t\t\t\t// Regenerate path\n\t\t\t\tint index = startNode;\n\t\t\t\twhile (true) {\n\t\t\t\t\ttour.add(vertices[index]);\n\t\t\t\t\tInteger nextIndex = prev[index][state];\n\t\t\t\t\tif (nextIndex == null)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tint nextState = state | (1 << nextIndex);\n\t\t\t\t\tstate = nextState;\n\t\t\t\t\tindex = nextIndex;\n\t\t\t\t}\n\t\t\t\ttour.add(vertices[startNode]);\n\t\t\t\treturn tour;\n\t\t\t}\n\t\t\n\t\t\tpublic double distance(int startNode) {\t\t\n\t\t\t\tint state = 1 << startNode;\n\t\t\t\treturn tsp(startNode, state, startNode);\n\t\t\t}\n\t\t\n\t\t\tprivate double tsp(int i, int state, int startNode) {\n\t\t\n\t\t\t\tint v = weights.length;\n\t\t\t\tdouble minDistance = Double.POSITIVE_INFINITY;\n\t\t\n\t\t\t\tif (state == (1 << v) - 1) // if all have been visited add the cost of returning to the first city\n\t\t\t\t\treturn weights[i][startNode];\n\t\t\t\t\n\t\t\t\t// Return cached answer if already computed.\n\t\t\t        if (memo[i][state] != null) \n\t\t\t    \treturn memo[i][state];\n\t\t\n\t\t\t\tint index = -1;\n\t\t\t\tfor (int next = 0; next < v; next++) {\n\t\t\t\t\tif ((state & (1 << next)) != 0) //Skip if the next node has already been visited.\n\t\t\t\t\t\tcontinue;\n\t\t\n\t\t\t\t\tint nextState = state | (1 << next); //mark as visited\n\n\t\t\t\t\tdouble newDistance = weights[i][next] + tsp(next, nextState, startNode);\n\t\t\t\t\tif (newDistance < minDistance) {\n\t\t\t\t\t\tminDistance = newDistance;\n\t\t\t\t\t\tindex = next;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tprev[i][state] = index;\n\t\t\t\treturn memo[i][state] = minDistance;\n\t\t\t}\t\t\t\n\t\t} there are 2^n possible sets of visited nodes, n possible nodes you can be at, and n nodes you can visit from each node. 2^n * n^2 Why exactly are there 2^n possible sets? each node has two possibilities; you've either visited it or you haven't. 2^n.",
    "Resources to understand brownian motion, stochastic calculus etc. for finance? Hey all I'm taking a quantfin course at uni and as you might know, most instructors don't do a stellar job at driving these concepts home. I'm looking for articles, videos, lectures, anything, that can help me build an intuition about the what, how and why of these concepts. Something like what 3blue1brown did for linear algebra.\n\nMuch appreciated You can try watching MIT's playlist on [Topics in mathematics w application in finance](https://youtube.com/playlist?list=PLUl4u3cNGP63ctJIEC1UnZ0btsphnnoHR). Give it a try! You could try Ã˜ksendal's *\"SDEs: An Introduction with Applications\"*, it's pretty intuitive. Some quantfin textbooks also include a few chapters on SDE theory, e.g. BjÃ¶rk's *\"Arbitrage Theory in Continuous Time\"* has a well-written chapter on stochastic calculus.\n\nYou can also try asking your professors for some help during office hours. Maybe they are good professors who just don't have enough time to fully explain everything in class. If you are willing to look at a slide set and are able to understand the math, this setup was popular with my finance students:\n\nhttps://www.palmislandtraders.com/econ136/risk_proxies_2020_part1.pdf\n\nGiven that a Monte Carlo simulation, when properly designed, allows one to simulate Brownian Motion with drift, and even allow for tail events, this related slide set shows that:\n\nhttps://www.palmislandtraders.com/econ136/monte_carlo.pdf\n\nDisclaimer: These were constructed very rapidly during early COVID and have not been carefully checked for errors. [Edit: corrected one of the links] I wrote an article on Geometric Brownian Motion intended as a **gentle introduction to stochastic calculus**, it goes through the whole intuition of why this type of calculus is used and how the GBM actually was thought up (from the population growth formula). Would be great if youâ€™d check it out!\n\n https://medium.com/the-quant-journey/a-gentle-introduction-to-geometric-brownian-motion-in-finance-68c37ba6f828 Not quite 3blue1brown, but QuantPie on YouTube is pretty good.\n\nhttps://youtube.com/c/quantpie Hull's book on Derivatives is a great one as well, in addition to all that has been mentioned above. This is a working book by Prof Greg Lawler from UChicago. Currently working through this book for his Stochastic Calculus course, and it explains the concepts really well!\n\n&#x200B;\n\n[http://www.math.uchicago.edu/\\~lawler/finbook.pdf](http://www.math.uchicago.edu/~lawler/finbook.pdf) There are books on this. Make Microsoft Academic your friend =) There's a video with some books that could be helpful in Dimitri's channel Hui-hsiung kuo; Introduction to stochastic integration.",
    "[R] FinRL: A Deep Reinforcement Learning Library for Quantitative Finance [removed] Is there any course that closely targets  DeepLearning to Finance? I have completed the DeepLearning specialization on Coursera, which was a good introduction to deep learning but I feel it was a bit far from the financial field?.  \n\n\nthanks Do they have any metrics of success using this? Seems like a way to get some light gains then lose all your money if youâ€™re not careful. I see thereâ€™s some good performance, but how would you explain these results? How does the RL agent make money? Does it have better portfolio weights? Or buy more profitable stocks when itâ€™s a bullish market and sell more shitty stocks when the market is going down? How does it handle market volatility? Put it this way, how are you supposed to explain this to your investors if your RL bot loses money? Wondering such an open source project may grow into a giant \"monster\", e.g. many people contribute many functionalties and then become hard to use at all.  What would be the lifecycle? I took a look at the notebooks & the backtesting charts on the noteboocks look like they don't perform well - was there just more hyperparameter tuning that went into the poster versions that aren't in the notebooks on the repository? I am an enthusiastic RL learner, I can't believe people want to use RL in financial trading, this will not work in live trading!! Financial market is not self-driving car or Atari game or Go game!!! Financial market has high volatility, a MDP model is not enough to explain and model it, not mention that the state and action space for an Atari game is limited but for trading, it's INFINITE! The FinRL library is not small, But I am looking forward a simple one for learning and practition.  Would a Lightweight library be interesting? Financial trading is easily broken down in to changes in volume and price. Most trading systems try to predict the directions of the market based on continuing trend curves but other realtime traders also influence the market. Money management should be the main goal of a finance based ML. Why are you buying bots to upvote your stuff? A thought here: don't you guys think the profitability (or potential of profitability) of quant trading goes against the idea of open-source?  How would you justify the rationale behind making a profitable project public (thereby making it less profitable)?",
    "The ultimate blueprint to getting a job in data science EDIT: Iâ€™m on discord to answer your questions: \nhttps://discord.gg/raQ5NjHy\n\nItâ€™s pretty late in the UK (11.30pm, but Iâ€™ll stay up as long as you guys want me to)\n\nOrganisation is Key\n\nIâ€™ve interviewed at Google (and DeepMind), Uber, Facebook, Amazon for roles that lie under the â€œData Scientistâ€ umbrella and this is the typical interview construction theme Iâ€™ve observed:\n\nSoftware Engineering\nApplied Statistics\nMachine Learning\nData Wrangling, Manipulation and Visualisation\n\nNow nobody is expecting some super graduate level competency in all of these topics, but you need to know enough to convince your interviewer that youâ€™re capable of delivering if they offered you the job. How much you need to know depends on the job spec, but in this increasingly competitive market, no knowledge is lost.\n\nI recommend using Notion to organise your job prep. Itâ€™s extremely versatile, and enables you to utilise the Spaced Repetition and Active Recall principles to nail down learning and deploying key topics that come up time and time again in a Data Scientist interview. Ali Abdaal has a great tutorial on note taking with Notion to maximise your learning potential during the interview process.\n\nI used to run through my Notion notes over and over, but in particular, right before my interview. This ensured that key topics and definitions were loaded into my working memory and I didnâ€™t waste precious \ntime â€œummmmmmâ€ing when hit with some question.\n\n2. Software Engineering\nNot all Data Scientist roles will grill you on the time complexity of an algorithm, but all of these roles will expect you to write code. Data Science isnâ€™t one job, but a collection of jobs that attracts talent from a variety of industries, including the software engineering world. As such youâ€™re competing with guys that know the ins and outs of writing efficient code and I would recommend spending at least 1â€“2 hours a day in the lead-up to your interview practicing the following concepts:\n\nArrays\nHash Tables\nLinked Lists\nTwo-Pointer based algorithms\nString algorithms (interviewers LOVE these)\nBinary Search\nDivide and Conquer Algorithms\nSorting Algorithms\nDynamic Programming\nRecursion\n\nDO NOT LEARN THE ALGORITHMS OFF BY HEART. This approach is useless, because the interviewer can question you on any variation of the algorithm and you will be lost. Instead learn the strategy behind how each algorithm works. Learn what computational and spatial complexity are, and learn why they are so fundamental to building efficient code.\n\nLeetCode was my best friend during interview preparation and is well worth the $35 per month in my opinion. Your interviewers only have so many algorithm questions to sample from, and this website covers a host of algorithm concepts including companies that are likely or are known to have asked these questions in the past. Thereâ€™s also a great community who discuss each problem in detail, and helped me during the myriad of â€œstuckâ€ moments I encountered. LeetCode has a â€œliteâ€ version with a smaller question bank if the $35 price tag is too steep, as do HackerRank and geeksforgeeks which are other great resources.\n\nWhat you should do is attempt each question, even if itâ€™s a brute force approach that takes ages to run. Then look at the model solution, and try to figure out what the optimal strategy is. Then read up what the optimal strategy is and try to understand why this is the optimal strategy. Ask yourself questions like â€œwhy is Quicksort O(nÂ²) average time complexity?â€, why do two pointers and one for loop make more sense than three for loops?\n\n3. Applied Statistics\nData science has an implicit dependence on applied statistics, and how implicit that will be depends on the role youâ€™ve applied for. Where do we use applied statistics? It pops up just about anywhere where we need to organise, interpret and derive insights from data.\n\nI studied the following topics intensely during my interviews, and you bet your bottom dollar that I was grilled about each topic:\n\nDescriptive statistics (What distribution does my data follow, what are the modes of the distribution, the expectation, the variance)\nProbability theory (Given my data follows a Binomial distribution, what is the probability of observing 5 paying customers in 10 click-through events)\n\nHypothesis testing (forming the basis of any question on A/B testing, T-tests, anova, chi-squared tests, etc).\n\nRegression (Is the relationship between my variables linear, what are potential sources of bias, what are the assumptions behind the ordinary least squares solution)\n\nBayesian Inference (What are some advantages/disadvantages vs frequentist methods)\n\nIf you think this is a lot of material you are not alone, I was massively overwhelmed with the volume of knowledge expected in these kinds of interviews and the plethora of information on the internet that could help me. Two invaluable resources come to mind when I was revising for interviews.\n\nIntroduction to Probability and Statistics, an open course on everything listed above including questions and an exam to help you test your knowledge.\n\nMachine Learning: A Bayesian and Optimization Perspective by Sergios Theodoridis. This is more a machine learning text than a specific primer on applied statistics, but the linear algebra approaches outlined here really help drive home the key statistical concepts on regression.\n\nThe way youâ€™re going to remember this stuff isnâ€™t through memorisation, you need to solve as many problems as you can get your hands on. Glassdoor is a great repo for the sorts of applied stats questions typically asked in interviews. The most challenging interview I had by far was with G-Research, but I really enjoyed studying for the exam, and their sample exam papers were fantastic resources when it came to testing how far I was getting in my applied statistics revision.\n\n4. Machine Learning\nNow we come to the beast, the buzzword of our millennial era, and a topic so broad that it can be easy to get so lost in revision that you want to give up.\nThe applied statistics part of this study guide will give you a very very strong foundation to get started with machine learning (which is basically just applied applied statistics written in fancy linear algebra), but there are certain key concepts that came up over and over again during my interviews. Here is a (by no means exhaustive) set of concepts organised by topic:\n\nMetrics â€” Classification\nConfusion Matrices, Accuracy, Precision, Recall, Sensitivity\nF1 Score\nTPR, TNR, FPR, FNR\nType I and Type II errors\nAUC-ROC Curves\n\nMetrics â€” Regression\nTotal sum of squares, explained sum of squares, residual sum of squares\nCoefficient of determination and its adjusted form\nAIC and BIC\nAdvantages and disadvantages of RMSE, MSE, MAE, MAPE\n\nBias-Variance Tradeoff, Over/Under-Fitting\nK Nearest Neighbours algorithm and the choice of k in bias-variance trade-off\nRandom Forests\nThe asymptotic property\nCurse of dimensionality\nModel Selection\nK-Fold Cross Validation\nL1 and L2 Regularisation\nBayesian Optimization\n\nSampling\nDealing with class imbalance when training classification models\nSMOTE for generating pseudo observations for an underrepresented class\nClass imbalance in the independent variables\nSampling methods\nSources of sampling bias\nMeasuring Sampling Error\n\nHypothesis Testing\nThis really comes under under applied statistics, but I cannot stress enough the importance of learning about statistical power. Itâ€™s enormously important in A/B testing.\n\nRegression Models\nOrdinary Linear Regression, its assumptions, estimator derivation and limitations are covered in significant detail in the sources cited in the applied statistics section. Other regression models you should be familiar with are:\nDeep Neural Networks for Regression\nRandom Forest Regression\nXGBoost Regression\nTime Series Regression (ARIMA/SARIMA)\nBayesian Linear Regression\nGaussian Process Regression\n\nClustering Algorithms\nK-Means\nHierarchical Clustering\nDirichlet Process Mixture Models\n\nClassification Models\nLogistic Regression (Most important one, revise well)\nMultiple Regression\nXGBoost Classification\nSupport Vector Machines\n\nItâ€™s a lot, but much of the content will be trivial if your applied statistics foundation is strong enough. I would recommend knowing the ins and outs of at least three different classification/regression/clustering methods, because the interviewer could always (and has previously) asked â€œwhat other methods could we have used, what are some advantages/disadvantagesâ€? This is a small subset of the machine learning knowledge in the world, but if you know these important examples, the interviews will flow a lot more smoothly.\n\n5. Data Manipulation and Visualisation\nâ€œWhat are some of the steps for data wrangling and data cleaning before applying machine learning algorithmsâ€?\n\nWe are given a new dataset, the first thing youâ€™ll need to prove is that you can perform an exploratory data analysis (EDA). Before you learn anything realise that there is one path to success in data wrangling: Pandas. The Pandas IDE, when used correctly, is the most powerful tool in a data scientists toolbox. The best way to learn how to use Pandas for data manipulation is to download many, many datasets and learn how to do the following set of tasks as confidently as you making your morning cup of coffee.\n\nOne of my interviews involved downloading a dataset, cleaning it, visualising it, performing feature selection, building and evaluating a model all in one hour. It was a crazy hard task, and I felt overwhelmed at times, but I made sure I had practiced building model pipelines for weeks before actually attempting the interview, so I knew I could find my way if I got lost.\n\nAdvice: The only way to get good at all this is to practice, and the Kaggle community has an incredible wealth of knowledge on mastering EDAs and model pipeline building. I would check out some of the top ranking notebooks on some of the projects out there. Download some example datasets and build your own notebooks, get familiar with the Pandas syntax.\n\nData Organisation\nThere are three sure things in life: death, taxes and getting asked to merge datasets, and perform groupby and apply tasks on said merged datasets. Pandas is INCREDIBLY versatile at this, so please practice practice practice.\n\nData Profiling\nThis involves getting a feel for the â€œmetaâ€ characteristics of the dataset, such as the shape and description of numerical, categorical and date-time features in the data. You should always be seeking to address a set of questions like â€œhow many observations do I haveâ€, â€œwhat does the distribution of each feature look likeâ€, â€œwhat do the features meanâ€. This kind of profiling early on can help you reject non-relevant features from the outset, such as categorical features with thousands of levels (names, unique identifiers) and mean less work for you and your machine later on (work smart, not hard, or something woke like that).\n\nData Visualisation\nHere you are asking yourself â€œwhat does the distribution of my features even look like?â€. A word of advice, if you didnâ€™t learn about boxplots in the applied statistics part of the study guide, then here is where I stress you learn about them, because you need to learn how to identify outliers visually and we can discuss how to deal with them later on. Histograms and kernel density estimation plots are extremely useful tools when looking at properties of the distributions of each feature.\nWe can then ask â€œwhat does the relationship between my features look likeâ€, in which case Python has a package called seaborn containing very nifty tools like pairplot and a visually satisfying heatmap for correlation plots.\nHandling Null Values, Syntax Errors and Duplicate Rows/Columns\nMissing values are a sure thing in any dataset, and arise due to a multitude of different factors, each contributing to bias in their own unique way. There is a whole field of study on how best to deal with missing values (and I once had an interview where I was expected to know individual methods for missing value imputation in much detail). Check out this primer on ways of handling null values.\n\nSyntax errors typically arise when our dataset contains information that has been manually input, such as through a form. This could lead us to erroneously conclude that a categorical feature has many more levels than are actually present, because â€œHotâ€, â€˜hOtâ€, â€œhot/nâ€ are all considered unique levels. Check out this primer on handling dirty text data.\nFinally, duplicate columns are of no use to anyone, and having duplicate rows could lead to overrepresentation bias, so itâ€™s worth dealing with them early on.\n\nStandardisation or Normalisation\nDepending on the dataset youâ€™re working with and the machine learning method you decide to use, it may be useful to standardize or normalize your data so that different scales of different variables donâ€™t negatively impact the performance of your model.\nThereâ€™s a lot here to go through, but honestly it wasnâ€™t as much the â€œmemorise everythingâ€ mentality that helped me insofar as it was the confidence building that learning as much as I could instilled in me. I must have failed so many interviews before the formula â€œclickedâ€ and I realised that all of these things arenâ€™t esoteric concepts that only the elite can master, theyâ€™re just tools that you use to build incredible models and derive insights from data.\n\nBest of luck on your job quest guys, if you need any help at all please let me know and I will answer emails/questions when I can. This is so valuable to me- you have no idea!  \n\n\nIt is also quite depressing seeing this mountain to climb... Even though I am familiar with a lot of this mastering it is a challenge. I do wonder how, where, and when people learn this. Thanks for taking the time to put all of this together. It's also nice of you to offer to answer people's questions. sure.\n\nanother way is to marry rich Nice I got the stats ml part but now here I am thinking that most jobs only really emphasize the Data structures and algorithms part Thank you very much. It was helpful indeed. I have even taken noted from this post in Evernote.\n\nOne thing, you haven't mentioned Sql. Aren't they needed? Almost all the DS related jobs I am seeing in my country has Sql listed as no. 1. And then R/Python and everything else. Great guide, thanks! \n\nHow do you use Notion for spaced repetition? Active recall Iâ€™m assuming you just use toggle blocks? I love Notion as a second brain, but I think Iâ€™m gonna use Anki for studying interview questions if I can bring myself to make the cards. \n\nFYI link for the dirty data primer didnâ€™t embed. How long did this take you to learn? What was your work ethic like studying for interviews? \n\nDid you get a master's degree in CS or Data Science first? I'm curious, although I suspect I know the answer, how useful is knowing R vs. python for this? I ask because a lot of the things mentioned here can be done extraordinarily easily in R, but you're recommending exclusively python. R's ease of use is especially true of the visualization and data wrangling, and anything OLS related. Machine learning is harder in R than in python (sort of, turns out R has a tensorflow package). I'm guessing that the answer is \"everyone uses python, so R knowledge is borderline useless.\" Which would be mildly annoying since I could do a fair chunk of the non-ML stuff in R while half asleep, but I would be googling everything for doing it in python. Not that entire industries need to revolve around my preferences, I'll make do. I just hate going back to square one in my programming ability (which is where I'm at in python). If you're trying to scare me, its working rather well ;p   Even though I've finished a degree in CS, went through a whole lot of that background, and have read multiple books on Machine Learning , taken refresher courses in Linear Algebra and Statistics.. I still don't know what an F-score is ;)  That's what uncle Google is for, right?????  Why must I suffer like this?? why??? Thanks for this pal.",
    "Reddit - r/wallstreetbets post since 2012  Lmfao I knew it This is great. I was looking for something like this. Did you put this together using PRAW? Very relevant right now. I wonder if you can combine it with other datasets to compare the results of the posts. Whats the created\\_utc variable? some kind of datetime I'm taking it? whats the origin (ie whats 0) Only the post. Not the comments This is awesome. Is there one for comments as well? Enjoy it! The data was extracted using the [PushShift API for Reddit](https://pushshift.io/reddit/). Thanks [Watchful1](https://github.com/Watchful1/Sketchpad/blob/master/postDownloader.py) for show me this API. Could you give me an example?",
    "Keras DC-GAN tutorial.  Type out every word yourself instead of just running it. ",
    "Massive multi-turn conversational dataset based on cleaned discord data  This is a long-context, anonymized, clean, multi-turn and single-turn conversational dataset based on discord data scraped from a large variety of severs, big and small.\n\nThe raw data for this version contained 51,826,268 messages  \n5103788 (regex) + 696161 (toxic)/51826268, or 0.11% of the messages were removed  \n**The dataset's final size is 46,026,319 messages across 456810 conversations**, which is reduced from 33.06 GB of raw json data to 968.87 MB\n\n[https://www.kaggle.com/jef1056/discord-data](https://www.kaggle.com/jef1056/discord-data) [deleted] Hey, first of all, this is awesome and just what I've been looking for. Much appreciated!\n\nIs there any chance you'll be offering this data in smaller chunks, split up by the type of content? Right not it's not clear what types of discord servers are included and I would like to be able to pick and choose. Yes, but for privacy purposes and due to agreements with some server owners, I won't be releasing it publicly; you can send me a request describing your use case and scope at contact@j-fan.ml Splitting up the data currently isn't in the plans yet; if someone (or you) could create a classifier (NOTE: please, please optimize it, the amount of data to process here is not trivial) to split the data into the relevant groups, go ahead and create a branch and pull request to [https://github.com/JEF1056/clean-discord](https://github.com/JEF1056/clean-discord) and hopefully I can do that for the next release, which is slated toward the end of the year. I can provide small snippets of some of the raw JSON data so you can understand how it's formatted.\n\nAs stated in my reply above, due to some agreements with server owners, I cannot redistribute all the original files, and many of the owners have required me to use only anonyomized usernames, which may reduce the feasability of splitting the data up.",
    "Stanford CS 329S Machine Learning Systems Design - is there a good online alternative? Been looking at the slides for [https://stanford-cs329s.github.io/syllabus.html](https://stanford-cs329s.github.io/syllabus.html)\n\nIt seems like a great course, but sadly not all content is available online (no recorded lectures or labs). Iâ€™m wondering if someone knows of a good online alternative with same/similar content? https://huyenchip.com/machine-learning-systems-design/toc.html This one is the latest from FSDL\n\n&#x200B;\n\n[https://fullstackdeeplearning.com/spring2021/](https://fullstackdeeplearning.com/spring2021/) Can you enroll online through Stanford? I think they allow it on a per course basis through their continuing education programme https://stanford-cs329s.github.io/2021/syllabus.html\n\nLecture slides and notes. Recorded lectures are available to enrolled students and SCPD. Nothing beats lectures and exercises, but here's the related book she's writing: https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ apmonitor.com/pds Andrew Ng\n\n[https://www.youtube.com/watch?v=PPLop4L2eGk](https://www.youtube.com/watch?v=PPLop4L2eGk)\n\n&#x200B;\n\nSentdex\n\n[https://www.youtube.com/results?search\\_query=sentdex+machine+learning](https://www.youtube.com/results?search_query=sentdex+machine+learning)\n\n&#x200B;\n\nCoursera. It's not free but useful. one more choice for you: [https://fall2019.fullstackdeeplearning.com/](https://fall2019.fullstackdeeplearning.com/) Thanks! Thank you.",
    "What are some hidden gem subreddits with plenty of stuff to binge read?  r/foundpaper is a favorite of mine. People just post paper they found. Letters, grocery lists, lost pet posters, yard sale signs... any paper you find on on the ground or basically anywhere you can post. r/garfieldminusgarfield is brilliant is Garfield panels without Garfield I love binge-reading r/outoftheloop.  It's always a source to catch up on the weird things on the internet and current events alike and I get lost so fast. /r/ExplainLikeImCalvin is a good one. You ask a question there, and people respond as if they were the dad from Calvin & Hobbes - no true answers, just pure BS. /r/RBI (Reddit Bureau of Investigation). People post about mysteries in their personal lives and the community of sleuths tries to solve them. Fascinating stuff happens there. r/AskAnAmerican is fun, whether you're a foreigner or a resident. You learn a lot, too, and the environment is overall pretty friendly. [R/NewYorksHottestClub](https://www.reddit.com/r/NewYorksHottestClub/) You canâ€™t help but read the posts in Stefonâ€™s voice.  Very soothing.\n\nEditing bc I am old af. r/mrjoenobody is about a person who makes monthly comics about his past in an abusive school.\n\nI'm not sure how to describe the school but it was fucked up. See Elan school on Wikipedia I donâ€™t know if Iâ€™d call it a hidden gem but I personally like r/UnsentLetters. On some days itâ€™s more interesting but I like to write my own and it feels kind of cathartic. I love r/whatisthisthing. Seeing people guess and debate is half the fun for me.",
    "Egg, Ham, Cheese Tortilla Wrap  Please post your recipe comment in reply to me, all other replies will be removed. Posts without recipes will be removed. Don't forget to flair your post!\n\n##**Recipe Comment is under this comment, click to expand**\n\n##**â†“****â†“****â†“**\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GifRecipes) if you have any questions or concerns.* I've been putting my eggs in the wrap after cooking them, like a fucking idiot. Woke up and saw this post in bed.\n\n[Decided to get up and make it myself. ](https://imgur.com/a/bMM7TrC)\n\nFantastic! this looks good as hell. might make this now actually\n\nEdit:\nhttps://imgur.com/a/n6FFn6i\n\nThis is now my preferred way to make a breakfast wrap I saw this on Netflix recently. Nadia ? I like the edge to edge coverage of egg to tortilla Never thought the breakfast burrito/quesadilla would be improved in my lifetime.\n\nGod is great. I love this technique That's genius! I use these exact same ingredients for breakfast all the time, but I never thought to steam the tortilla *on top of* the egg. [deleted]",
    "Easiest way to cook one of these is let it get to room temperature (almost an hour)  salt and pepper then slather garlic butter on it. Put in 500 degree oven on a roasting rack (to catch all the juices) for 5 min per pound (7.24 lb roast should be cooked at 500 degrees for 36.2 minutes) then turn off your oven but DO NOT OPEN it for exactly 2 hours. Then you can take it out, let it rest for a couple minutes, and you get medium rare. EVERY TIME. ",
    "That slow leg sweep  Upvote this comment if you feel this submission is characteristic of our subreddit. Downvote this if you feel that it is not. If this comment's score falls below a certain number, this submission will be automatically removed. Dude moved like the Ents from Lord of the Rings and still managed to beat the other dude. Gaaabe staaawp Gabriel you donâ€™t have to be a bitch to get your ass beat. Those long-armed slaps. That was one methodical ass whoopin Damn his arms are nearly as long as that woman ðŸ¤£ So white shirt and Dora the Ignora was in this man's place disrespecting them? Is this what's going on here? He came back for more, after he got bitch slapped and humiliated, he actually came back, that man is crazy. The gay swag is high with this one, so much style.",
    "TIFU by hooking up with a girl while my friend was in the house. Obligatory this didn't happen today.\n\nSo I (Chris,19M) did something stupid. Because of the Lockdown and shit, I hadn't fucked someone since 3 months, and was low-key feeling desperate and was just looking to smash. Met a girl, let's call her Maria, who was also thinking along the same lines, went on a couple of dates, blah blah blah.\n\nSo now, a little backstory. I live with a Housemate. Let's call him Mike. We both have different rooms, and it's a 2 room apartment. He and I go to nearby colleges, and we're good friends. He knows me well, and I know him well. So he likes pranking, and I like pranking too, It's okay, we get along fine.\n\nSo anyways, after our last date, I told him I'm probably gonna sleep with this girl in a couple of days.\n\nThat's what happens, Maria's in my room, things get hot and steamy, we both haven't had any contact with the other gender since a lot of time, we're making out, clothes come off, and as we start getting down to business, Mike walks in on us in the room.\n\nAnd the cunt-head doesn't simple walk in. He's wearing baby clothes, has an apron on, he's holding a FUCKING ladle, he has this surprised look on his face, his hair looks like a Wasp Nest, he even has this sort of black smearing on his face, he's holding some lube and a sandwich, and you know what the asshole says? He goes 'Damn it Chris, What's wrong with you? Just as I get down to fulfilling your Fucking Ladle Fantasy (Jesus knows what that means), you go Hetero on me? I thought you swore you were gay?'\n\nI learnt that laughing in such a Scenario isn't a good idea. She thought the laughing gave it away that I was pranking her. In my defence, it was hilarious seeing him like that.\n\nWe both are VERY straight, like literally nothing sexual has ever happened before between us, and the MF does this without the slightest HINT of a smile. Well Maria goes ' I KNEW something was off!' and simply leaves the house, even as I try explaining the shit to her. I'm simply standing there, explaining, Naked, that he's lying, but apparently the lube gave it away, and she's sure I'm messing with her, and if I try contacting her again, she'll call the fucking Police.\n\nSo that's how Mike ruined a Hook up, and how a girl thinks I'm a pranking bastard. I swore at him for at least half an hour straight, but that doesn't bring the girl back.\n\nTo add insult to the injury, he got the idea from Reddit, of all places.\n\nTL;DR: My roommate walked in on a girl and me about to have sex, he convinced her that I was gay, and I'm lonely again.\n\nEdit: Lots of people are saying there are many loopholes in my story. I'll address the main ones.\n\n1. I'm 16: I dunno where y'all got this from. I noticed a post saying that I was 16 in r/teenagers.\n\nI don't use that sub, and didn't notice. My flair over there had been set long ago. Sorry for that. I've changed it now.\n\n2) The baby clothes: Mike is an acting major, and we both are in the Boston area. By baby clothes I meant clothes that babies wear duh.\n\n3) Now I'm pretty sure the comments saying I was gay are jokes, but I'll clarify: I'm straight, sorry for disappointing y'all.\n\n4) I'm a girl. I know where this one stems from. It's a meme I made. Do people not understand that a meme is a fucking MEME for gods sake? This account is a meme account, majorly. You can dig up my profile and find out that I'm a 45 year old women who came from Mars and occasionally lives in the UK and Zimbabwe while attending classes in Boston. I'll clear this. I'm a student, in an Ivy League University, about to turn 20. I'm a straight guy. Same description applies to Mike. He's majoring in theatre, and I'm majoring in Engineering. We both are tall. He's better looking. He's an extrovert, I'm in the middle you could say.\n\n5) This is fake: I dunno, hard to believe, for sure, definitely not fake. I'm pretty sure the homies saying this is fake are all middle aged people or 14 year olds, who have forgotten how wild college was, or dunno yet how wild it is.\n\n6) The lube: I think that it implied anal, since you need lots of lube for that. Thought it was pretty clear. I misjudged the average IQ of this sub. Sorry\n\n7) Immature of us: Glad you realised\n\n8) Yes we both are friends, very close ones at that. I'll clarify. We share a lot of stuff with each other.\n\n9) We prank each other all the time, together prank others, it's a fun life.\n\n10) I asked where he got the idea from. He got it from [this](https://www.reddit.com/r/AskReddit/comments/fn67j/i_hear_my_house_mate_masturbating_should_i_walk/c1h5ruf/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3)\n\nTL:DR: I'm not 16, I'm a straight guy, This is real and fuck you if you think it's not. Always fun to hear someone say 'I knew it!' when your roommate calls you gay FUCKING ladle, (*Fuh-king Lay-dull*) *noun:*\n\nA seemingly innocuous kitchen utensil that has been modified for ease of insertion into various bodily cavities.\n\nSee also: Spank spatula, Butt Baster [deleted] This sounds like the opening of a gay porno.\n\n[insert OPâ€™s story here]\n\n...\n\nOP: Now look what you did, now Iâ€™m erect but have no one who can make it go away. \n\nRoommate: Letâ€™s test that theory. *cue porno music* > 3 months no sex\n\n> Super desperate\n\nBro that's not even full Lockdown [removed] Yea... that happened â€œ To add insult to the injury, he got the idea from Reddit, of all places.â€\n\nYeah, weâ€™re going to need a link to that post as well. This sounds very very real. Yeh I would find it super uncomfortable for someone to burst in on me naked with someone I donâ€™t know that well as part of a prank.",
    "Help on problem Given a N by N matrix of non-negative ints with rows and columns numbered 1 to N, perform the following operation:\n\n1. choose a number from 1-N that hasn't been chosen\n2. Add up all the numbers in that row and add this to the answer\n3. Set all numbers in that column to 0 (after step 2)\n\nI want to find the minimum answer I can get after choosing the numbers in whatever order I want. The brute force way would be O(N! \\* N\\^2), but I think there is a O(2\\^N \\* N\\^2) or even faster way. I figured it out. Use bitmask dynamic programming, where the state is the set of column ids you considered, and value is the minimum sum. Maybe this?\n\nCreate an array that holds the sum of the columns along with the column's index, so we can keep track of which is which.\n\nSort it in descending order.\n\n&#x200B;\n\npick the numbers by going down the list and selecting the original index.\n\n&#x200B;\n\nI'm trying to remove the heaviest column first, then the second heaviest, and so on. I'm not sure this is optimal. There is an O(N\\^3) solution.\n\nCompute the row partial sums from the right, then https://en.wikipedia.org/wiki/Hungarian_algorithm.\n\nThe row partial sums encode the cost of the row depending on the order of selection, then you just want to minimize the trace over all permutations. Could you post an example that breaks the O(n^2 ) greedy solution of just taking whatever row is cheapest? Is the Auction algorithm related? Consider the following matrix:\n\n&#x200B;\n\nN = 3\n\n9 0 0\n\n1 9 0\n\n9 9 9\n\n&#x200B;\n\nIf you take the cheapest row, you will erase the columns in the order 1-2-3, which yields  the sum of 27 (9 + 9 + 9). However, if you take the rows in the order 3-2-1, you'll get the sum 46 (the sum of all the elements of the matrix). But isn't 27 the minimum possible? Seems to be what we wanted. whoops, I misread the post; in case of the minimum sum, I think the following case breaks your greedy approach:\n\n&#x200B;\n\nN = 3\n\n1 7 1\n\n0 9 2\n\n0 10 0\n\n&#x200B;\n\nUsing the greedy approach, you get the order 1-3-2, which yields the sum 9 + 10 + 9 = 28, but if you take the order 2-3-1, you get 11 + 0 + 1 = 12.",
    "After two long years, I finally made a dental clinic that uses 100% Linux and Open Source software   * OS: Kubuntu 20.10\n * Software: [Clear.Dental](https://gitlab.com/cleardental) (my own open source project)\n * Hardware: AMD Ryzen 3 3100 + Radeon Rx 550\n * Touch monitor: TD2210 (works with Linux out of the box)\n\nEdit: Sorry for not making it clear: this is a real photo of my actual clinic. Not a 3D render of one.\n\n[A few more photos](https://imgur.com/a/E1Kue9q)\n\n[Multimedia demo](https://www.youtube.com/watch?v=puV2gXaFEEM&feature=youtu.be)\n\n[COVID Screening demo](https://www.youtube.com/watch?v=pDN0jWcvNtA) Holy shit this is the best thing I've ever seen. So you made your own system for client records/database/etc...? \n\nI'm not too familiar with what software medical offices typically use but this is amazing FOSS This is one of the best projects I've seen but not even Linux is going to make me like going to the dentist. `rm -fr /var/run/tooth` I'm retarded, for a moment i thought that you MADE the clinic using blender Just wow, can't upvote more than once, but if I could I would do it.\n\nHuge job you did there. KDEntal. wait, is this image legitimately real? it looks too good to be true...\n\n&#x200B;\n\n**IT LOOKS VERY GOOD MY FRIEND...** congrats! I feel like I'm losing my mind but I absolutely cannot decipher whether this is a photograph or a 3D render. Good way to help kids remember to use their FLOSS",
    "[D] 10 Insightful & Practical AI/ML Books to Read in 2021 If you are still planning a 2021 reading list, here are [10 AI/ML books](https://blog.crossminds.ai/post/10-ai-books-to-read-in-2021-machine-learning-researchers-engineers) to consider. They are published over the past two years and cover a range of topics from fundamental concepts, to algorithms and applications. And here is a collection of [author talks and book reviews](https://crossminds.ai/playlist/60073b29495ecadbf27b3a9e/) that might be helpful to check out before diving deep into the books.\n\n* Artificial Intelligence: A Guide for Thinking Humans (Melanie Mitchell)\n* Rebooting AI (Gary Marcus and Ernest Davis)\n* Human Compatible: Artificial Intelligence and the Problem of Control (Stuart Russel)\n* You Look Like a Thing and I Love You: How Artificial Intelligence Works and Why It's Making the World a Weirder Place (Janelle Shane)\n* The Hundred-Page Machine Learning Book (Andriy Burkov)\n* Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (Christoph Molnar)\n* Machine Learning Yearning (Andrew Ng)\n* Machine Learning Engineering (Andriy Burkov)\n* Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd Edition) (AurÃ©lien GÃ©ron)\n* Approaching (Almost) Any Machine Learning Problem (Abhishek Thakur)\n\nFeel free to comment below and add new book recommendations. Honest opinion: Except Andriy Burkov (not-really-hundred) 100 page ML book & Aurelion Geron Hands on Tensorflow, rest everything reads like popular science. Some are garbage.\n\nThere is very little to gain by reading about cutting edge science in prose. If you want to understand it, you got to learn it by books/tutorials/walk-through of implementations etc and critically think yourself. Just wondering how long does it take for you to read one book? It took me like months to finish a single book thats why i rarely read many books but there are so many good books to read Do people actually read 10 technical books in a year? Just trying to gauge how stupid I am in comparison. I'm a relatively good reader and I can chew through 3 or 4 (without rushing and risking burnout, while working on other stuff in free time + fulltime work). I could speedread more but I feel like the memory retention would suffer. Of course it depends on the size, I consider an average text book ~300 pages. I would recommend reading [Designing data intensive applications](https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/) to anyone that wants to get their model into production. ML is nice and fancy but if you do not understand the technical thread off of the system you are trying to build it will never work. You can be a great data scientist but not knowing how the data can be collected and put into your model will, in my opinion, lead to a lot of frustration in the team \"Deep Learning with Python\" by Francois Chollet is a fantastic read. What is the best book for social scientists who don't themselves program but want to understand what's going on with machine learning? >Machine Learning Engineering (Andriy Burkov)\n\n+1 for this Glad to see my advisor up on that list :) I haven't read it completely yet, but all my colleagues recommended \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio and Aaron Courville Hows the book by Abhishek Thakur?",
    "Best so far: https://github.com/HarisIqbal88/PlotNeuralNet ",
    "I made a course on NumPy. It got good reviews, but sales were weak so I'm releasing the entire thing for free. My course is called Python NumPy For Your Grandma - So easy your grandma could learn it. Here's the course outline.\n\n1. **Introduction**  \n  [1.1 Introduction](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-1-1-introduction)  \n2. **Basic Array Stuff**  \n  [2.1 NumPy Array Motivation](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-1-numpy-array-motivation)  \n  [2.2 NumPy Array Basics](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-2-numpy-array-basics)  \n  [2.3 Creating NumPy Arrays](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-3-creating-numpy-arrays)  \n  [2.4 Indexing 1-D Arrays](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-4-indexing-1d-arrays)  \n  [2.5 Indexing Multidimensional Arrays](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-5-indexing-multidimensional-arrays)  \n  [2.6 Basic Math On Arrays](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-6-basic-math-on-arrays)  \n  [2.7 Challenge: High School Reunion](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-7-challenge-high-school-reunion)  \n  [2.8 Challenge: Gold Miner](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-8-challenge-gold-miner)  \n  [2.9 Challenge: Chic-fil-A](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-2-9-challenge-chic-fil-a)  \n3. **Intermediate Array Stuff**  \n  [3.1 Broadcasting](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-1-broadcasting)  \n  [3.2 newaxis](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-2-newaxis)  \n  [3.3 `reshape()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-3-reshape)  \n  [3.4 Boolean Indexing](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-4-boolean-indexing)  \n  [3.5 nan](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-5-nan)  \n  [3.6 infinity](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-6-infinity)  \n  [3.7 random](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-7-random)  \n  [3.8 Challenge: Love Distance](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-8-challenge-love-distance)  \n  [3.9 Challenge: Professor Prick](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-9-challenge-professor-prick)  \n  [3.10 Challenge: Psycho Parent](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-3-10-challenge-psycho-parent)  \n4. **Common Operations**  \n  [4.1 `where()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-1-where)  \n  [4.2 Math Functions](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-2-math-functions)  \n  [4.3 `all()` and `any()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-3-all-and-any)  \n  [4.4 `concatenate()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-4-concatenate)  \n  [4.5 Stacking](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-5-stacking)  \n  [4.6 Sorting](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-6-sorting)  \n  [4.7 `unique()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-7-unique)  \n  [4.8 Challenge: Movie Ratings](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-8-challenge-movie-ratings)  \n  [4.9 Challenge: Big Fish](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-9-challenge-big-fish)  \n  [4.10 Challenge: Taco Truck](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-4-10-challenge-taco-truck)  \n5. **Advanced Array Stuff**  \n  [5.1 Advanced Array Indexing](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-1-advanced-array-indexing)  \n  [5.2 View vs Copy](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-2-view-vs-copy)  \n  [5.3 Challenge: Population Verification](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-3-challenge-population-verification)  \n  [5.4 Challenge: Prime Locations](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-4-challenge-prime-locations)  \n  [5.5 Challenge: The Game of Doors](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-5-challenge-the-game-of-doors)  \n  [5.6 Challenge: Peanut Butter](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-5-6-challenge-peanut-butter)  \n6. **Final Boss**  \n  [6.1 `as_strided()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-1-as_strided)  \n  [6.2 `einsum()`](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-2-einsum)  \n  [6.3 Challenge: One-Hot-Encoding](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-3-challenge-one-hot-encoding)  \n  [6.4 Challenge: Cumulative Rainfall](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-4-challenge-cumulative-rainfall)  \n  [6.5 Challenge: Table Tennis](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-5-challenge-table-tennis)  \n  [6.6 Challenge: Where's Waldo](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-6-challenge-wheres-waldo)  \n  [6.7 Challenge: Outer Product](https://www.gormanalysis.com/blog/python-numpy-for-your-grandma-6-7-challenge-outer-product)  \n\nIf you find this useful, please consider liking my videos and subscribing to my [YouTube channel](https://www.youtube.com/channel/UCOcsois3fuvgFRZGdozQHeg).\n\nAlso, stay posted for my next course, Python Pandas For Your Grandpa.\n\n**UPDATE** since this post blew up.  \n\n1.  After >1 year of having a YouTube channel, I had 59 subscribers. I posted this 16 hours ago and now I have 325 subscribers and counting. Two people even *purchased* my course. Like, what!?!? Thank you!  \n2.  *Please* stay posted for my next course Python Pandas For Your Grandpa. It's nearly finished after months of work, and the production quality is much better.\n\n**UPDATE 2**  \nMy [course on Pandas](https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa/) has been released!  ([View on YouTube](https://www.youtube.com/playlist?list=PL9oKUrtC4VP7ry0um1QOUUfJBXKnkf-dA)) as_strided looks fun. I can see myself abusing that. Looks good. Usually, there isn't good material on NumPy. Wishing you success and subscribed. That my grandma could learn it doesn't imply that I could. She was very clever. Great offering to the community, thanks, wish you luck and subscribed. EXCITED FOR THE PANDAS COURSE!!! hey I am sorry it didn't sell well. but look at the silver lining - your teaching will create promising innovators of the future - you may not get money out of it (i know that really sucks), but you have done humanity a great service. Thank you. i am familiar with most stuff listed here but i will take a look at them anyway at some point in future. Woah! Iâ€™m buying [your course](https://www.udemy.com/course/python-numpy-for-your-grandma/?referralCode=B75D1F7F498504D88FD3) anyways, because this is too legit to go uncompensated ðŸ‘ Subscribed. I'll share this to my class. I am a TA in the course, Statistical Data Analysis. Thanks Iâ€™m waiting for Matplotlib for my Great Aunt. I had yet to see some good examples on stride tricks. Good catch!",
    "The EnronSent Corpus:\n\nThe Enron Corpus is a database of over 600,000 emails generated by 158 employees[1] of the Enron Corporation in the years leading up to the company's collapse in December 2001. The corpus was generated from Enron email servers by the Federal Energy Regulatory Commission (FERC) during its subsequent investigation.[2] A copy of the email database was subsequently purchased for $10,000 by Andrew McCallum, a computer scientist at the University of Massachusetts Amherst.[3] He released this copy to researchers, providing a trove of data that has been used for studies on social networking and computer-mediated communication.\n\nhttps://en.wikipedia.org/wiki/Enron_Corpus ",
    "The US Department of Ed has a dataset called the CRDC that collects data from all the public schools in the US and has demographic, academic, financial and all sorts of other fun data points. They also have corollary datasets that use the same identifierâ€”an expansion pack if you may. It comes out every 2-3 years I believe. \n\nEdit: Grammar and additional info\n\nLink: https://www2.ed.gov/about/offices/list/ocr/data.html?src=rt ",
    "sqlite database of 400,000+ Jeopardy! clues from j-archive.com  Already missing Alex more than my own family. Very cool, thanks for this. Thx man! Really really hate the format of the j-archive when I looked at scraping it before. What way did you used?",
    "That XOR Trick  xor tricks are cool but the code review will suck Compared to O(N)\n\nGauss's Method:\n\n    Let sum = high * (high + 1) / 2\n\nOne loop:\n\n    for( Int currentNumber : numbers )\n    {\n        sum -= currentNumber;\n    } [Bit Twiddling Hacks](https://graphics.stanford.edu/~seander/bithacks.html) Beware of value swapping using XOR. It works. It works when you make a `swap()` macro or a function that takes args by reference. Then you write a function that works on an array and calls `swap(a[i],a[j])`. It works.  Until `i` happens to be equal to `j`. Boom, surprise :) For some extra dirty pointer tricks sprinkled with XOR we have the [XOR Linked List](https://en.m.wikipedia.org/wiki/XOR_linked_list), or a doubly linked list using just one pointer. Mind you, it is only for those who are extra privileged to work in languages that \"allow\" bitwise pointer manipulation (e.g. C, C++). Imo interview questions requiring tricks like these are garbage. I mean all coding interviews are essentially garbage, but these ones are even worse. It's already hard enough to get any signal out of an interview when you ask a question that a candidate can reason about like a normal human being. Why would you make it harder for yourself by asking a question that might be either trivial or impossible depending on the candidate's familiarity with whatever arcane thing it is you're asking? You might as well decide if they passed by flipping a coin. In Place Swapping with XOR is a horrible thing to do on modern processors because of data dependencies.  You'd need to hope that the processor can detect this specific sequence as a \"swap\" in order to avoid the latency penalties. Of course, these tricks actually have nothing to do with XOR at all, as was hinted in the example that used arithmetic:\n\n    -- finds the unique element that is present in xs but not in ys\n    findMissing :: (Foldable t, Abelian a) => t a -> t a -> a\n    findMissing xs ys = (fold xs) ~~ (fold ys)\n\nYou can define swap etc. similarly; it's the same \"trick\" (though it feels much less tricky in this generalized form). All that is required is some operation which is associative, commutative, and invertible. XOR is only special because it is its own inverse, which makes it look a bit more \"magical\" here. This is actually much easier to conceptualize if you consider XOR as calculating parity.\n\na ^ b is the same as 'parity of a + b'.\n\nSo the xor swap is just 'calculate the parity difference, then subtract it back out again'. Lots of interesting tricks with XOR this was interesting to read. I donâ€™t think Iâ€™ll ever use them though but theyâ€™re a good exercise",
    "ALS Dataset This is an ALS dataset with over 1,000 patients. This is a horrible neurodegenerative disease with no cure. Most patients die within 2-5 years and gradually lose their ability to walk, talk, and breathe. Go to r/ALS for more information. \n\nhttps://dataportal.answerals.org/home Thank you very much for providing the link to this data. [deleted] Consider cross posting in r/datasets.\n\nGood share and good luck! Hi all, im a bioinformatics PHD student working in an ALS lab. If you dont already have much domain knowledge of ALS please feel free to drop me any questions. Also, if you aren't associated with an ALS research department already and want to send your findings to an established ALS lab for review feel free to contact me :) \nAnd thanks for sharing this dataset OP! This is a perfect data set. Thanks for sharing. Iâ€™m gonna try to kick ALSâ€™s ass. My mom just died from als a couple of months  ago and thereâ€™s a 50% chance Iâ€™ll have it, and Iâ€™m going into data science to help with just this. Thanks for posting this. My mom died of ALS 15 years ago so Iâ€™d love to take a look My dad died of ALS in 2014, thank you for this A terrible terrible disease. I applaud this organization for releasing this dataset so that others can understand this terrible disease and perhaps shed new insights. A good thing might be adding a section which displays the useful applications that are built using this dataset?",
    "Handy little guide for you all.  A non profit I run made an interactive expanded version of this concept: www.freelearninglist.org Fonts Matter Goliath guitar was a good place but it was shutdown by some music company because they couldnt handle good music lessons being given for free\n\nGo to the wayback machine, and look up Goliath guitar on there, you'll be able to find those fingerstyle guitar tabs that were uploaded on it. Lmao [erowid.org](https://erowid.org)\n\nGreat website to learn....chemistry.... There is a typo, it's gutenberg.org ELA Teacher here, just to add a few that educators might find  useful:\n\n[CommonLit](http://commonlit.org)\n (text sets, reading comprehension questions in the middle of texts, discussion questions, easily accessed assessment data) \n\n[Newsela](http://newsela.com)\n (up to date news articles written at different lexile levels)\n\n[EdPuzzle](http://edpuzzle.com) \n(make videos interactive)\n \nI believe there's also some things for the independent learner on these sites. libgen? z-library? Bad font, repost, and outdated. For example, ureddit does not work anymore Add phrontistery.info for obscure English words - from colours to musical terms to ecclesiastical terms, it's a brilliant place. I use [Futurelearn.com](https://Futurelearn.com) a lot for free courses as well as the Open University's free short courses if it helps :-)",
    "i made a bot that turns reddit arguments into ace attorney It's still pretty buggy, I threw it together because my holidays are coming to a close.\n\nHere's an example: https://youtu.be/rvFk8hapDZY\n\nHere's the source code: https://github.com/micah5/ace-attorney-reddit-bot Dude, this is wonderful. Love it. Man this is why I started coding. This is a freaking cool ! this is beautiful lmao\n\nthese are the kind of projects which remind me why i got into programming to begin with lol this is beautiful I think someone had an objection, because the bot's account is suspended. I, for one, have no objections, this is exactly the kind of technological overkill for a brief laugh that is funnier than the joke it makes. 10/10 Can someone have a conversation? i really want to see it on a meta conversation [deleted] That's fucking legendary. Funny shit. You sir, are a scholar and a gentleman! Gotem!",
    "[P] Introducing Shapash, a new Python library : makes Machine Learning models transparent and understandable by everyone Hi,\n\nWith my coworkers, we are glad to share Shapash : a Python library that helps making Machine Learning models more transparent and understandable by everyone. #OpenSource #OSSByMaif\n\nKey features:\n\n* Provides easy-to-read visualizations and webApp for Global and Local explainability\n* Displays results with appropriate wording (preprocessing inverse/postprocessing)\n* Summarizes local explanability to answer operational needs\n* Uses explanability from Exploration to Production\n* Is compatible with many Python lib: Explaining (Shap/Lime), ML models, encoding features\n\nHave a look at Shapash: WebApp demo [https://shapash-demo.ossbymaif.fr/](https://shapash-demo.ossbymaif.fr/)\n\nHow to use Shapash? [https://github.com/MAIF/shapash](https://github.com/MAIF/shapash)\n\nI can answer your questions Kind of weird how this is the second day in a row an advertisement for a library has received lots of upvotes in a very short amount of time and many of the comments are from new accounts. There was an ICML 2020 paper basically saying we should stop using Shapley vals for explainability (in most cases): [https://paperswithcode.com/paper/problems-with-shapley-value-based](https://paperswithcode.com/paper/problems-with-shapley-value-based)\n\n&#x200B;\n\nDoes this work account for the problems listed in the paper and check whether shapley is appropriate? So to be clear, this is essentially a wrapper around other explainability tools (with a particular focus on shapley values) that uses them to build a plotly dashboard for visualizing the outputs of those tools, yeah? You are grossly overstating the capabilities of your library. SHAP values etc are super flawed, and give some signal, but are often wrong in strange ways, and depend on hyperparameter choices. E.g. what baseline are you using, and how did you choose it? This sub is going downhill fast ... Does it work with neural nets and random Forrest's or is it only for non-blacknbox models? What does the name Shapash mean? Seems like a lot of work but what would be your use case ? It seems to be aimed at people that do not code much but it seems to require a lot of theoretical knowledge both in terms of code and modelling. Does it work with xgboost? Really bro? Shapash?",
    "Free January 19 Talk with AI Pioneer Sarit Kraus on Agent-Human Collaboration [N] January 19, join Sarit Kraus, 2020-2021 ACM Athena Lecturer **Sarit Kraus** of Bar-Ilan University for the free ACM TechTalk, \"[Agent-Human Collaboration and Learning for Improving Human Satisfaction](https://webinars.on24.com/acm/kraus?partnerref=red).\" ACM Fellow Michael Wooldridge (University of Oxford and the Alan Turing Institute) moderates.\n\nIn this talk, Kraus considers environments where a set of human workers needs to handle a large set of tasks while interacting with human users, and presents automated intelligent agents that will work together with the human operators in order to improve the overall performance of such systems and increase both operatorsâ€™ and usersâ€™ satisfaction. These agents could both support the operators and learn from them to potentially replace them in many of their tasks.\n\n[Register](https://webinars.on24.com/acm/kraus?partnerref=red) to attend the talk live or be notified when the on-demand recording is available. Low on sleep cause of exams and read that as-Talk with AI prisoner...",
    "best-of-python: A ranked list of awesome Python libraries and tools https://i.redd.it/n54xmlw9sbb61.gif\n\nWe've curated a list of the **best Python libraries and tools**!\n\nThe list is fully automated via GitHub Actions, so it will never get outdated. Every week it collects metadata from GitHub and package managers, calculates quality scores to rank projects inside categories, and identifies trending projects.\n\nðŸ”— GitHub: [https://github.com/ml-tooling/best-of-python](https://github.com/ml-tooling/best-of-python)\n\nðŸŽ‰ We also released a few other best-of lists on Reddit today:\n\n* [best-of-ml-python](https://github.com/ml-tooling/best-of-ml-python): Python libraries for machine learning.\n* [best-of-python-dev](https://github.com/ml-tooling/best-of-python-dev): Python developer tools and libraries.\n* [best-of-web-python](https://www.reddit.com/r/flask/comments/kx8mlu/bestofwebpython_a_ranked_list_of_awesome_python/): Python libraries for web development.\n* [best-of-jupyter](https://www.reddit.com/r/IPython/comments/kx8v15/p_bestofjupyter_a_ranked_list_of_awesome_jupyter/): Jupyter Notebook, Hub, and Lab projects.\n\nðŸ“« For updates on trending projects, new additions and detailed comparisons, follow us on [Twitter](https://twitter.com/mltooling) or subscribe to our weekly [newsletter](https://mltooling.substack.com/subscribe). Docopt needs to be replaced with docopt-ng.  Stars aren't everything.  Docopt-ng is docopt, but with testing, bug fixes, and useful error messages.\n\nPyQt and PySide should be on there before quiet a few other libraries on there.  I'd even let wxPython on. If pandas isn't included I'm rioting Wow fantastic lists! Thank you so much for creating and maintaining them.\n\nCan you elaborate on the criteria for what counts as a \"Warning (e.g. missing/risky license)\"? Risky for whom, why are they risky, and under what conditions/assumptions?\n\nFor example, I've heard about how MIT licensed programs could be used by big players like Amazon Web Services for huge profit without any benefit to the original project, but that's not currently listed as a risky license in this list. So just curious what your \"risky\" criteria are.\n\nThanks again! :) Plumbum is still fantastic and under-appreciated. It would fit under:\n\n- process utilities\n- infrastructure & devops\n- file & path utilities\n- cli development Just putting this out here, https://github.com/vinta/awesome-python https://github.com/man-group/dtale should be under both best of ml and jupyter, at least Very good lists! Thank you so much for creating and maintaining them. Capnproto for serialization &#x200B;\n\n![gif](giphy|2mxA3QHH4aHFm) Cool",
    "Bayesian Portfolio Optimisation: Introducing the Black-Litterman Model [removed] amazing, thanks I think BL is good as a starting point for understanding the issue of high estimation error for returns and covariance matrix and how to address it. Aren't there better, newer methods of dealing with these issues? What happened to the post content? This is excellent - H&T gang!\n\n\\-ashu When you come back to a post and it's removed -_- . Why did you remove it OP? Hey I'm new to algotrading and finance but i have computational neuroscience background.\n\nDo you think this is gonna work with ETFs? Or what will be a good model to use for them? !Remindme 2days RemindMe! 1 week RemindMe! 1 day Remind me! 2 days",
    "Bollinger Band Backtester (Python) Hey everyone,\n\nI've seen quite a few posts about here about getting started with programming a backtester and strategies and stuff so I thought I'd help the community by sharing mine!  My code is nothing ground breaking but can hopefully be used as a guide if you want to create your own or you should just be able to adapt it. \n\nI've recently spent some time reading about bollinger bands. I found several helpful videos [here](https://www.youtube.com/watch?v=GN0iK5ws0iE). So I've implemented a basic bollinger bands strategy and backtest it as well as using Monte Carlo Simulation to validate its success. I'm not an expert programmer so I've used relatively basic tools and I'm happy to answer any questions about my code. I'd also really appreciate any feedback on the code, potential improvements to the strategies or any comments in general!\n\n[https://github.com/petemik/BollingerBands](https://github.com/petemik/BollingerBands) Saving this as I want to start some backtesting tonight in Python nice and pretty python code, inspired me to clean mine up plus put in exception handling... What is the strategy that you're backtesting? Looks awesome! Top stuff man! Hit me up if you have any questions, happy to help in anyway I can Yeah I think exception handling is a bit of a must! Managed to avoid it so far as it's only been me running the code but now that I'm sharing it I really should add it in It's a very simple strategy using bollinger bands, when the bands narrow we expect that there is going to be a movement in price so we prepare to buy if we can another indication of move. So if there is a narrowing of the bands, and then the price breaks out of the band high or low, we long or short respectively getting back at you on LinkedIn. You have a super bright future ahead of you! When we do algo trading is it correct to assume that having more indicators along side the Bollinger Bands, for example SMA indicators with different days to confirm the trend indicated by the bands? Thanks for reaching out! And cheers man, means a lot to me! From my understanding, no. Too many indicators for the same thing cause confusion for the model and can lead to overfitting. Generally, you only want one indicator for each 'degree of freedom', so one for momentum, one for trend, one for volume for example. Someone else may correct me on this, but that is my understanding.  Feel free to play around with it though! Add an RSI indicator and see if only buying if it is in line with RSI improves the model. Shouldn't be too difficult to add :)",
    "Why does combining the sigmoid with the binary cross entropy loss work so well? When applying sigmoid activation follow by binary cross entropy loss it is possible to optimize the two operations using the log-sum-exp trick. I was taught this trick in a machine learning course and can follow the math easily enough. However, I can't seem to understand why it helps so much with training. I have tried running experiments which use and don't use this optimization and using the optimization always runs better.\n\nCan anyone offer any sort of intuitive explanation about why this aught to be the case? [deleted] [This seems to be a good explanation](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a?gi=a783c1a9ae53) From the top of my head (and I could be terribly wrong here, so just feel free to correct me):\n\nSigmoid activation function maps to values in [0, 1]. \n\nBinary cross entropy â€œcountsâ€ how many data points divert from their ground truth labels (which are also 0 and 1) in a fancy manner. \n\nSo sigmoid activation function predicts values between 0 and 1 (or more precisely the probability that your data point has label 1) and binary cross entropy takes those outputs directly and give you a good estimate on your modelâ€™s errors. \n\nAgain, I might think too simplistic here and might just be wrong ðŸ˜„ RemindMe! 2 days Commenting for explanation as well. RemindMe! 3 days RemindMe! 3 Days RemindMe! 2 days If I understand correctly the floating point representation numerical issue is due to the number of bits (32 or 64) that your processor has.\n\nWhen doing calculations your float is converted to a binary representation on the CPU using the number of bits, if the number is too small it will underflow, meaning that there are too many bits required to represent the number effectively rounding it off. When it's too big you encounter overflow, as once again it requires too many bits to represent the number and it gets rounded again.\n\nQuick example, representing the number 35 can be represented as 100011 - requiring 6 bits.\n\nIf anyone with more brain cells has any more insights, I'd love to hear them RemindMe! 1 day",
    "[D] Here are 17 ways of making PyTorch training faster â€“ what did I miss? [I've been collecting methods to accelerate training in PyTorch](https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/) â€“ here's what I've found so far. What did I miss? What did I get wrong?\n\nThe methods â€“ roughly sorted from largest to smallest expected speed-up â€“ are:\n\n1. Consider using a different learning rate schedule.\n2. Use multiple workers and pinned memory in DataLoader.\n3. Max out the batch size.\n4. Use Automatic Mixed Precision (AMP).\n5. Consider using a different optimizer.\n6. Turn on cudNN benchmarking.\n7. Beware of frequently transferring data between CPUs and GPUs.\n8. Use gradient/activation checkpointing.\n9. Use gradient accumulation.\n10. Use DistributedDataParallel for multi-GPU training.\n11. Set gradients to None rather than 0.\n12. Use .as\\_tensor rather than .tensor()\n13. Turn off debugging APIs if not needed.\n14. Use gradient clipping.\n15. Turn off bias before BatchNorm.\n16. Turn off gradient computation during validation.\n17. Use input and batch normalization.\n\n## 1. Consider using another learning rate schedule\n\nThe learning rate (schedule) you choose has a large impact on the speed of convergence as well as the generalization performance of your model.\n\nCyclical Learning Rates and the 1Cycle learning rate schedule are both methods introduced by Leslie N. Smith ([here](https://arxiv.org/pdf/1506.01186.pdf) and [here](https://arxiv.org/abs/1708.07120)), and then popularised by fast.ai's Jeremy Howard and Sylvain Gugger ([here](https://www.fast.ai/2018/07/02/adam-weight-decay/) and [here](https://github.com/sgugger/Deep-Learning/blob/master/Cyclical%20LR%20and%20momentums.ipynb)). Essentially, the 1Cycle learning rate schedule looks something like this:\n\n&#x200B;\n\nhttps://preview.redd.it/sc37u5knmxa61.png?width=476&format=png&auto=webp&s=09b309b4dbd67eedb4ab5f86e03e0e83d7b072d1\n\nSylvain writes:\n\n>\\[1cycle consists of\\]  two steps of equal lengths, one going from a lower learning rate to a higher one than go back to the minimum. The maximum should be the value picked with the Learning Rate Finder, and the lower one can be ten times lower. Then, the length of this cycle should be slightly less than the total number of epochs, and, in the last part of training, we should allow the learning rate to decrease more than the minimum, by several orders of magnitude.\n\nIn the best case this schedule achieves a massive speed-up â€“ what Smith calls *Superconvergence* â€“ as compared to conventional learning rate schedules. Using the 1Cycle policy he needs \\~10x fewer training iterations of a ResNet-56 on ImageNet to match the performance of the original paper, for instance). The schedule seems to perform robustly well across common architectures and optimizers.\n\nPyTorch implements both of these methods `torch.optim.lr_scheduler.CyclicLR` and `torch.optim.lr_scheduler.OneCycleLR,` see [the documentation](https://pytorch.org/docs/stable/optim.html).\n\nOne drawback of these schedulers is that they introduce a number of additional hyperparameters. [This post](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) and [this repo](https://github.com/davidtvs/pytorch-lr-finder), offer a nice overview and implementation of how good hyper-parameters can be found including the Learning Rate Finder mentioned above.\n\nWhy does this work? It doesn't seem entirely clear but one[ possible explanation](https://arxiv.org/pdf/1506.01186.pdf) might be that regularly increasing the learning rate helps to traverse [saddle points in the loss landscape ](https://papers.nips.cc/paper/2015/file/430c3626b879b4005d41b8a46172e0c0-Paper.pdf)more quickly.\n\n## 2. Use multiple workers and pinned memory in DataLoader\n\nWhen using [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), set `num_workers > 0`, rather than the default value of 0, and `pin_memory=True`, rather than the default value of False. Details of this are [explained here](https://pytorch.org/docs/stable/data.html).\n\n[Szymon Micacz](https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf) achieves a 2x speed-up for a single training epoch by using four workers and pinned memory.\n\nA rule of thumb that [people are using ](https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/5)to choose the number of workers is to set it to four times the number of available GPUs with both a larger and smaller number of workers leading to a slow down.\n\nNote that increasing num\\_workerswill increase your CPU memory consumption.\n\n## 3. Max out the batch size\n\nThis is a somewhat contentious point. Generally, however, it seems like using the largest batch size your GPU memory permits will accelerate your training (see [NVIDIA's Szymon Migacz](https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf), for instance). Note that you will also have to adjust other hyperparameters, such as the learning rate, if you modify the batch size. A rule of thumb here is to double the learning rate as you double the batch size.\n\n[OpenAI has a nice empirical paper](https://arxiv.org/pdf/1812.06162.pdf) on the number of convergence steps needed for different batch sizes. [Daniel Huynh](https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf) runs some experiments with different batch sizes (also using the 1Cycle policy discussed above) where he achieves a 4x speed-up by going from batch size 64 to 512.\n\n[One of the downsides](https://arxiv.org/pdf/1609.04836.pdf) of using large batch sizes, however, is that they might lead to solutions that generalize worse than those trained with smaller batches.\n\n## 4. Use Automatic Mixed Precision (AMP)\n\nThe release of PyTorch 1.6 included a native implementation of Automatic Mixed Precision training to PyTorch. The main idea here is that certain operations can be run faster and without a loss of accuracy at semi-precision (FP16) rather than in the single-precision (FP32) used elsewhere. AMP, then, automatically decide which operation should be executed in which format. This allows both for faster training and a smaller memory footprint.\n\nIn the best case, the usage of AMP would look something like this:\n\n    import torch\n    # Creates once at the beginning of training\n    scaler = torch.cuda.amp.GradScaler()\n    \n    for data, label in data_iter:\n       optimizer.zero_grad()\n       # Casts operations to mixed precision\n       with torch.cuda.amp.autocast():\n          loss = model(data)\n    \n       # Scales the loss, and calls backward()\n       # to create scaled gradients\n       scaler.scale(loss).backward()\n    \n       # Unscales gradients and calls\n       # or skips optimizer.step()\n       scaler.step(optimizer)\n    \n       # Updates the scale for next iteration\n       scaler.update()\n\nBenchmarking a number of common language and vision models on NVIDIA V100 GPUs, [Huang and colleagues find](https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/) that using AMP over regular FP32 training yields roughly 2x â€“ but upto 5.5x â€“ training speed-ups.\n\nCurrently, only CUDA ops can be autocast in this way. See the [documentation](https://pytorch.org/docs/stable/amp.html#op-eligibility) here for more details on this and other limitations.\n\nu/SVPERBlA points out that you can squeeze out some additional performance (\\~ 20%) from AMP on NVIDIA Tensor Core GPUs if you convert your tensors to the [Channels Last memory format](https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html). Refer to [this section](https://docs.nvidia.com/deeplearning/performance/dl-performance-convolutional/index.html#tensor-layout) in the NVIDIA docs for an explanation of the speedup and more about NCHW versus NHWC tensor formats.\n\n## 5. Consider using another optimizer\n\nAdamW is Adam with weight decay (rather than L2-regularization) which was popularized by fast.ai and is now available natively in PyTorch as `torch.optim.AdamW`. AdamW seems to consistently outperform Adam in terms of both the error achieved and the training time. See [this excellent blog](https://www.fast.ai/2018/07/02/adam-weight-decay/) post on why using weight decay instead of L2-regularization makes a difference for Adam.\n\nBoth Adam and AdamW work well with the 1Cycle policy described above.\n\nThere are also a few not-yet-native optimizers that have received a lot of attention recently, most notably LARS ([pip installable implementation](https://github.com/kakaobrain/torchlars)) and [LAMB](https://github.com/cybertronai/pytorch-lamb).\n\nNVIDA's APEX implements fused versions of a number of common optimizers such as [Adam](https://nvidia.github.io/apex/optimizers.html). This implementation avoid a number of passes to and from GPU memory as compared to the PyTorch implementation of Adam, yielding speed-ups in the range of 5%.\n\n## 6. Turn on cudNN benchmarking\n\nIf your model architecture remains fixed and your input size stays constant, setting `torch.backends.cudnn.benchmark = True` might be beneficial ([docs](https://pytorch.org/docs/stable/backends.html#torch-backends-cudnn)). This enables the cudNN autotuner which will benchmark a number of different ways of computing convolutions in cudNN and then use the fastest method from then on.\n\nFor a rough reference on the type of speed-up you can expect from this, [Szymon Migacz](https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf) achieves a speed-up of 70% on a forward pass for a convolution and a 27% speed-up for a forward + backward pass of the same convolution.\n\nOne caveat here is that this autotuning might become very slow if you max out the batch size as mentioned above.\n\n## 7. Beware of frequently transferring data between CPUs and GPUs\n\nBeware of frequently transferring tensors from a GPU to a CPU using `tensor.cpu()` and vice versa using `tensor.cuda()` as these are relatively expensive. The same applies for `.item()` and `.numpy()` â€“ use `.detach()` instead.\n\nIf you are creating a new tensor, you can also directly assign it to your GPU using the keyword argument `device=torch.device('cuda:0')`.\n\nIf you do need to transfer data, using `.to(non_blocking=True)`, might be useful [as long as you don't have any synchronization points](https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/4) after the transfer.\n\nIf you really have to, you might want to give Santosh Gupta's [SpeedTorch](https://github.com/Santosh-Gupta/SpeedTorch) a try, although it doesn't seem entirely clear when this actually does/doesn't provide speed-ups.\n\n## 8. Use gradient/activation checkpointing\n\nQuoting directly from the [documentation](https://pytorch.org/docs/stable/checkpoint.html):\n\n>Checkpointing works by trading compute for memory. Rather than storing all intermediate activations of the entire computation graph for computing backward, the checkpointed part does **not** save intermediate activations, and instead recomputes them in backward pass. It can be applied on any part of a model.  \n>  \n>Specifically, in the forward pass, function will run in [torch.no\\_grad()](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad) manner, i.e., not storing the intermediate activations. Instead, the forward pass saves the inputs tuple and the functionparameter. In the backwards pass, the saved inputs and function is retrieved, and the forward pass is computed on function again, now tracking the intermediate activations, and then the gradients are calculated using these activation values.\n\nSo while this will might slightly increase your run time for a given batch size, you'll significantly reduce your memory footprint. This in turn will allow you to further increase the batch size you're using allowing for better GPU utilization.\n\nWhile checkpointing is implemented natively as `torch.utils.checkpoint`([docs](https://pytorch.org/docs/stable/checkpoint.html)), it does seem to take some thought and effort to implement properly. Priya Goyal [has a good tutorial ](https://github.com/prigoyal/pytorch_memonger/blob/master/tutorial/Checkpointing_for_PyTorch_models.ipynb)demonstrating some of the key aspects of checkpointing.\n\n## 9. Use gradient accumulation\n\nAnother approach to increasing the batch size is to accumulate gradients across multiple `.backward()` passes before calling optimizer.step().\n\nFollowing [a post](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) by Hugging Face's Thomas Wolf, gradient accumulation can be implemented as follows:\n\n    model.zero_grad()                                   # Reset gradients tensors\n    for i, (inputs, labels) in enumerate(training_set):\n        predictions = model(inputs)                     # Forward pass\n        loss = loss_function(predictions, labels)       # Compute loss function\n        loss = loss / accumulation_steps                # Normalize our loss (if averaged)\n        loss.backward()                                 # Backward pass\n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step()                            # Now we can do an optimizer step\n            model.zero_grad()                           # Reset gradients tensors\n            if (i+1) % evaluation_steps == 0:           # Evaluate the model when we...\n                evaluate_model()                        # ...have no gradients accumulate\n\nThis method was developed mainly to circumvent GPU memory limitations and I'm not entirely clear on the trade-off between having additional `.backward()` loops. [This discussion](https://forums.fast.ai/t/accumulating-gradients/33219/28) on the fastai forum seems to suggest that it can in fact accelerate training, so it's probably worth a try.\n\n## 10. Use Distributed Data Parallel for multi-GPU training\n\nMethods to accelerate distributed training probably warrant their own post but one simple one is to use `torch.nn.DistributedDataParallel` rather than `torch.nn.DataParallel`. By doing so, each GPU will be driven by a dedicated CPU core avoiding the GIL issues of DataParallel.\n\nIn general, I can strongly recommend reading the [documentation on distributed training.](https://pytorch.org/tutorials/beginner/dist_overview.html)\n\n## 11. Set gradients to None rather than 0\n\nUse `.zero_grad(set_to_none=True)` rather than `.zero_grad()`.\n\nDoing so will let the memory allocator handle the gradients rather than actively setting them to 0. This will lead to yield a *modest* speed-up as they say in the [documentation](https://pytorch.org/docs/stable/optim.html), so don't expect any miracles.\n\nWatch out, doing this is not side-effect free! Check the docs for the details on this.\n\n## 12. Use .as_tensor() rather than .tensor()\n\n`torch.tensor()` always copies data. If you have a numpy array that you want to convert, use `torch.as_tensor()` or `torch.from_numpy()` to avoid copying the data.\n\n## 13. Turn on debugging tools only when actually needed\n\nPyTorch offers a number of useful debugging tools like the [autograd.profiler](https://pytorch.org/docs/stable/autograd.html#profiler), [autograd.grad\\_check](https://pytorch.org/docs/stable/autograd.html#numerical-gradient-checking), and [autograd.anomaly\\_detection](https://pytorch.org/docs/stable/autograd.html#anomaly-detection). Make sure to use them to better understand when needed but to also turn them off when you don't need them as they will slow down your training.\n\n## 14. Use gradient clipping\n\nOriginally used to avoid exploding gradients in RNNs, there is both some [empirical evidence as well as some theoretical support](https://openreview.net/forum?id=BJgnXpVYwS) that clipping gradients (roughly speaking: `gradient = min(gradient, threshold)`) accelerates convergence.\n\nHugging Face's [Transformer implementation](https://github.com/huggingface/transformers/blob/7729ef738161a0a182b172fcb7c351f6d2b9c50d/examples/run_squad.py#L156) is a really clean example of how to use gradient clipping as well as some of the other methods such as AMP mentioned in this post.\n\nIn PyTorch this can be done using `torch.nn.utils.clip_grad_norm_`([documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_)).\n\nIt's not entirely clear to me which models benefit how much from gradient clipping but it seems to be robustly useful for RNNs, Transformer-based and ResNets architectures and a range of different optimizers.\n\n## 15. Turn off bias before BatchNorm\n\nThis is a very simple one: turn off the bias of layers before BatchNormalization layers. For a 2-D convolutional layer, this can be done by setting the bias keyword to False: `torch.nn.Conv2d(..., bias=False, ...)`.  (Here's a r[eminder why this makes sense](https://stackoverflow.com/questions/46256747/can-not-use-both-bias-and-batch-normalization-in-convolution-layers).)\n\nYou will save some parameters, I would however expect the speed-up of this to be relatively small as compared to some of the other methods mentioned here.\n\n## 16. Turn off gradient computation during validation\n\nThis one is straightforward: set `torch.no_grad()` during validation.\n\n## 17. Use input and batch normalization\n\nYou're probably already doing this but you might want to double-check:\n\n* Are you [normalizing](https://pytorch.org/docs/stable/torchvision/transforms.html) your input?\n* Are you using [batch-normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)?\n\nAnd [here's](https://stats.stackexchange.com/questions/437840/in-machine-learning-how-does-normalization-help-in-convergence-of-gradient-desc) a reminder of why you probably should.\n\n### Bonus tip from the comments: Use JIT to fuse point-wise operations.\n\nIf you have adjacent point-wise operations you can use [PyTorch JIT](https://pytorch.org/docs/stable/jit.html#creating-torchscript-code) to combine them into one FusionGroup which can then be launched on a single kernel rather than multiple kernels as would have been done per default. You'll also save some memory reads and writes.\n\n[Szymon Migacz shows](https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf) how you can use the `@torch.jit.script` decorator to fuse the operations in a GELU, for instance:\n\n    @torch.jit.script\n    def fused_gelu(x):\n        return x * 0.5 * (1.0 + torch.erf(x / 1.41421))\n\nIn this case, fusing the operations leads to a 5x speed-up for the execution of `fused_gelu`  \nas compared to the unfused version.\n\nSee also [this post](https://pytorch.org/blog/optimizing-cuda-rnn-with-torchscript/) for an example of how Torchscript can be used to accelerate an RNN.\n\nHat tip to u/Patient_Atmosphere45 for the suggestion.\b\n\n## Sources and additional resources\n\nMany of the tips listed above come from Szymon Migacz' [talk](https://www.youtube.com/watch?v=9mS1fIYj1So) and post in the [PyTorch docs](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html).\n\nPyTorch Lightning's William Falcon has [two](https://towardsdatascience.com/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565) [interesting](https://towardsdatascience.com/7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259) posts with tips to speed-up training. [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) does already take care of some of the points above per-default.\n\nThomas Wolf at Hugging Face has a [number](https://medium.com/@Thomwolf) of interesting articles on accelerating deep learning â€“ with a particular focus on language models.\n\nThe same goes for [Sylvain Gugger](https://sgugger.github.io/category/basics.html) and [Jeremy Howard](https://www.youtube.com/watch?v=LqGTFqPEXWs): they have many interesting posts in particular on [learning](https://sgugger.github.io/the-1cycle-policy.html) [rates](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html) and [AdamW](https://www.fast.ai/2018/07/02/adam-weight-decay/).\n\n*Thanks to Ben Hahn, Kevin Klein and Robin Vaaler for their feedback on a draft of this post!*\n\n**I've also put all of the above into this** [**blog post**](https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/)**.** I think you should split this into two categories 1) things that literally make your code run faster such as num_workers, cudNN etc and 2) things that lead to faster convergence such as optimizer, learning rate schedule etc\n\nOtherwise itâ€™s a great list. Thanks for the post! I also found this link useful: [https://pytorch-lightning.readthedocs.io/en/latest/performance.html](https://pytorch-lightning.readthedocs.io/en/latest/performance.html) This is great and thanks for posting it!  One more addition to point 2 :) If you are training the model on the cloud directly from S3 you can achieve \"real-time\" training speed as if the data is local using [Hub](https://github.com/activeloopai/Hub) as seen in [benchmarks](https://docs.activeloop.ai/en/latest/benchmarks.html) by utilizing the network.\n\nFor full disclosure, I am one of the creators of Hub ([https://github.com/activeloopai/Hub](https://github.com/activeloopai/Hub)) which helps to store and manage datasets for deep learning. We have spent quite a while optimizing how the data should be stored to maximize training speeds e.g. on AWS or GCP.\n\nIt also fairly well works on local FS. We would love any feedback on further improving the speed for training your models. One missing method: no mention of hyperparameter tuning across multiple computers on the network, which is possible with Microsoft NNI (this is working brilliantly for me right now). I would add: optimize routines/models using the @torch.jit.script decorator (which will probably require some type hints) Thanks a lot!\n\nThe mixed precision trick was new to me and I had still 240 compute hours of experiments to burn through before the ICML deadline, you just cut that in half for me! \nI see you've posted GitHub links to Jupyter Notebooks! GitHub doesn't \nrender large Jupyter Notebooks, so just in case here are \n[nbviewer](https://nbviewer.jupyter.org/) links to the notebooks:\n\nhttps://nbviewer.jupyter.org/url/github.com/prigoyal/pytorch_memonger/blob/master/tutorial/Checkpointing_for_PyTorch_models.ipynb\n\nhttps://nbviewer.jupyter.org/url/github.com/sgugger/Deep-Learning/blob/master/Cyclical%20LR%20and%20momentums.ipynb\n\nWant to run the code yourself? Here are [binder](https://mybinder.org/) \nlinks to start your own Jupyter server!\n\nhttps://mybinder.org/v2/gh/prigoyal/pytorch_memonger/master?filepath=tutorial%2FCheckpointing_for_PyTorch_models.ipynb\n\nhttps://mybinder.org/v2/gh/sgugger/Deep-Learning/master?filepath=Cyclical%20LR%20and%20momentums.ipynb\n\n\n\n------\n\n^(I am a bot.) \n[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) \n[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) \n[^(Author)](https://johnpaton.net/) >What did I miss? What did I get wrong?\n\nNot much. I've seen and tried almost everything of what you wrote.\n\nThe things that worked the less for me are probably gradient\\_clipping, input normalization for images, and the learning rate schedule (I guess it works with some careful tuning but I spent quite some time on it without great results).\n\nThe things that shouldn't even be noted beause they should be obvious now are fp16 training, choosing a better optimizer, maxing out batch size, and having multiple workers.\n\nThe thing that wasn't so obvious for me was going from DataParallel to DistributedDataParallel for multigpu training and even if it's not as easy to do (pytorch should definitely improve that (maybe they did I didn't check latest versions)) I totally recommend it.\n\nThere's a lot of other recommendations but which are not specific to Pytorch You may want to consider adding following to the list. I did it in a professional setting and results were.\n\n1. Consider using fewer data, appropriate sampling/filters. Many times, we end up using more data than needed, and it only adds to the noise.\n\n2. Take a break, do some offline thinking. Just chasing short term model training speed and accuracy metrics may not be the optimal path to the end objective. And you might even end up overfitting, by subconsciously snooping on the data. In DeepML terms, use real-world 'drop-out'. It may not seem to help in the short term speed of training, but it can lead to a more elegant/robust solutions. I think\n1. data transforms (for data augmentation) can be another source of speed improvement. Some transforms using only simple Python statements as well as some native PyTorch implementation can be accelerated by using numba package. [Ref](https://sanje2v.wordpress.com/2021/01/11/accelerating-data-transforms/)\n\n2. preprocessing datasets into single file, rather reading different files from disk, to something like TFRecords in Tensorflow could also be beneficial for speed.",
    "Meal Swipe Data In case anyone is just curious, like I am, you can look at all of your Meal Swipe, Dining Dollar, and Boiler Express usage for the semester on the Purdue eAccounts page.  I made my swipes into a neat pie chart.\n\nhttps://preview.redd.it/uj4cfo5r3h961.png?width=2326&format=png&auto=webp&s=afc440e219c5cc104c5c9adb5bbca29d9042ea2b I did this but I had trouble getting excel to recognize the data for whatever reason. I was tryouts bf a histogram though. I just used the table() function in r. I should try this again with the whole years worth of data. \n\nHow did you get the data into a spreadsheet? The next page button didnâ€™t work for me so I sat there refreshing the page and putting new dates there so I could get new data. Then I copy pasted. All in all I spent over an hour copy pasting meal swipe data. iâ€™m glad to see chick fil a is a favorite I just filtered by each location to get a count.  Then manual enter those numbers in excel",
    "go to covid.vit.co to take your send home covid test!!! covidtest.vaulthealth.com might tell you donâ€™t have a test registered with them. in that case covid.vlt.co will actually work\n\nsource: i just did this after calling pphc and vault when covidtest.vaulthealth.com wouldnâ€™t let me test.\n\nEDIT: you need to already be logged into vault iâ€™m pretty sure for this link to work\n\nEDIT again: itâ€™s VLT not vit sorry for the confusion! itâ€™s covid.VLT.co fyi! why is this nsfw lmao YES THIS ONE SORRY for the more confusion yall!!! i donâ€™t think i did that but iâ€™m also terrible at reddit so i couldâ€™ve hit something that turned it on figured it out lol",
    "Through the roof, i tells ya  Hey /u/beerbellybeg, thanks for contributing to /r/PoliticalHumor. Unfortunately, your post was removed as it violates our rules:\n\n**Rule 5** - Avoid reposts, flooding, and spam.\n\n Use Karmadecay and check /new and the front page before you post. Unfortunately, due to recent Reddit changes, karmadecay is not as effective, so we have a pretty light hand with repost violations and are not likely to ban you if you make a mistake.\n\n Do not post more than 4 posts in a 24 hour period. \n\nPlease read the [sidebar](http://www.reddit.com/r/PoliticalHumor/about/sidebar) and [rules](http://www.reddit.com/r/PoliticalHumor/about/rules) before posting again. If you have questions or concerns, please [message the moderators through modmail](https://www.reddit.com/message/compose?to=/r/PoliticalHumor&subject=&message=). Thank you! I live in Tennessee and variations of this picture are dotted across the landscape. Itâ€™s depressing as hell. [deleted] Im a ups driver in canton GA and this is every other house... smh The last person who said that I asked what symbols he had shares in. You all know what the reply was. Don't hate.  That's a rental property... Having grown up in West Virginiaâ˜ðŸ»this is accurate. Some folkâ€™ll never eat a skunk... The gentleman from Kentucky asks to be recognized... I retired at 56, 7 years ago. This has been a very profitable year I've made more money than any year I worked. I'd much rather have less to not have this hatred in our county.",
    "Until now, I never realized how important intelligence and a quick wit was to me in a partner. [removed] [deleted] Thereâ€™s nothing better than an intelligent conversation with someone who can hold their own.  Even a debate and differing views can be stimulating! There is nothing sexier than intelligence and a gooooood sense of humour. The more people know, the more things they can make jokes about. Im trying to understand the wit in her response.\n\nI've showed this to my girlfriend as I feel I'm missing the joke.\n\nCan someone explain it to me? News at 11: local man begins to see women as people, is rewarded once again for his crushing mediocrity Why was her asking that question back so intelligent or quick-witted? What was so witty and intelligent about her response to the horoscope question lol? â€”How old are you?\n\nâ€”How old do i look?\n\nNot trying to be mean but does that sound quick wit to you? Intelligence is important for a lot of folks, myself included.  Some old romantic comedies would feature a lot of fast, witty banter.  You might like some of those.  I recommend \"His Girl Friday.\" It's very attractive when a guy can make intelligent or clever references to things",
    "[R] A List of Best Papers from Top AI Conferences in 2020 Sharing a list of award-winning papers from this year's top conferences for anyone interested in catching up on the latest machine learning research before the end of the year :)\n\n**AAAI 2020**\n\n* Best Paper: WinoGrande: An Adversarial Winograd Schema Challenge at Scale \\[[Paper](https://arxiv.org/abs/1907.10641)\\]\n* Honorable Mention: A Unifying View on Individual Bounds and Heuristic Inaccuracies in Bidirectional Search \\[[Paper](https://ojs.aaai.org//index.php/AAAI/article/view/5611)\\]\n\n**CVPR 2020** \n\n* Best Paper: Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild \\[[Paper](https://arxiv.org/pdf/1911.11130.pdf)\\] \\[[Presentation](https://crossminds.ai/video/5ee96b86b1267e24b0ec2354/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**ACL 2020**\n\n* Best Paper: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList \\[[Paper](https://www.aclweb.org/anthology/2020.acl-main.442.pdf)\\] \\[[Video](https://crossminds.ai/video/5f454437e1acdc4d12c4186e/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**ICML 2020**\n\n* Best Paper: On Learning Sets of Symmetric Elements \\[[Paper](https://arxiv.org/abs/2002.08599)\\]  \\[[Presentation](https://icml.cc/virtual/2020/poster/6022)\\] \n* Best Paper: Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems \\[[Paper](https://arxiv.org/abs/2012.05703)\\]  \\[[Presentation](https://icml.cc/virtual/2020/poster/6447)\\] \n* Honorable Mention: Efficiently sampling functions from Gaussian process posteriors  \\[[Paper](https://arxiv.org/abs/2002.09309)\\]  \\[[Presentation](https://crossminds.ai/video/5f189c96c01f1dd70811ebef/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Honorable Mention: Generative Pretraining From Pixels \\[[Paper](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)\\]  \\[[Presentation](https://crossminds.ai/video/5f0e0b67d8b7c2e383e1077b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**ECCV 2020**\n\n* Best Paper: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow \\[[Paper](https://arxiv.org/abs/2003.12039)\\] \\[[Video](https://crossminds.ai/video/5f5acf7f7fa4bb2ca9d64e4d/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Honorable Mention: Towards Streaming Perception \\[[Paper](https://arxiv.org/abs/2005.10420)\\] \\[[Presentation](https://crossminds.ai/video/5f44390ae1acdc4d12c417e3/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Honorable Mention: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis \\[[Paper](https://arxiv.org/abs/2003.08934)\\] \\[[Presentation](https://crossminds.ai/video/5f3b294f96cfcc9d075e35b6/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**ICRA 2020**\n\n* Best Paper: Preference-Based Learning for Exoskeleton Gait Optimization \\[[Paper](https://arxiv.org/abs/1909.12316)\\] \\[[Presentation](https://crossminds.ai/video/5f65488303c0894581947a6b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Best Paper in Robot Vision: Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection \\[[Paper](https://arxiv.org/abs/1909.08605)\\] \\[[Presentation](https://crossminds.ai/video/5f63f6c403c089458194705f/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**CoRL 2020**\n\n* Best Paper: Learning Latent Representations to Influence Multi-Agent Interaction \\[[Paper](https://arxiv.org/abs/2011.06619)\\] \\[[Presentation](https://crossminds.ai/video/5fd9782a08be4fa7f41eabfe/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Best Paper Presentation: Accelerating Reinforcement Learning with Learned Skill Priors \\[[Paper](https://arxiv.org/abs/2010.11944)\\] \\[[Presentation](https://crossminds.ai/video/5fd9794308be4fa7f41eac54/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Best System Paper: SMARTS: An Open-Source Scalable Multi-Agent RL Training School for Autonomous Driving \\[[Paper](https://arxiv.org/abs/2010.09776)\\] \\[[Presentation](https://crossminds.ai/video/5fd9791f08be4fa7f41eac48/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**RecSys 2020**\n\n* Best Long Paper: Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations \\[[Paper](https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/blob/master/0_New_Papers_in_2020/2020%20%28Tencent%29%20%28Recsys%29%20%5BPLE%5D%20Progressive%20Layered%20Extraction%20%28PLE%29%20-%20A%20Novel%20Multi-Task%20Learning%20%28MTL%29%20Model%20for%20Personalized%20Recommendations.pdf)\\] \\[[Presentation](https://crossminds.ai/video/5f7fc247d81cf36f1a8e379c/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Best Short Paper: ADER: Adaptively Distilled Exemplar Replay Towards Continual Learning for Session-based Recommendation \\[[Paper](https://arxiv.org/abs/2007.12000)\\] \\[[Presentation](https://crossminds.ai/video/5f7fc27ad81cf36f1a8e37b6/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n\n**NeurIPS 2020**\n\n* Best Paper: Language Models are Few-Shot Learners \\[[Paper](https://arxiv.org/abs/2005.14165)\\] \\[[Video](https://crossminds.ai/video/5f3179536d7639fd8a7fc06a/?playlist_id=5fe2e2ea56dab51eaff52eaf)\\] \n* Best Paper: No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium \\[[Paper](https://arxiv.org/abs/2004.00603)\\] \n* Best Paper: Improved Guarantees and a Multiple-Descent Curve for Column Subset Selection and the NystrÃ¶m Method \\[[Paper](https://arxiv.org/abs/2002.09073)\\]\n\nHere is a comprehensive collection of [research talks from all major AI conferences](https://crossminds.ai/c/conference/) this year if you'd like to explore further. Mods, can we have a post for these every year, and a pinned thread linking each end of year post? Nice work. \n\nThanks! Thank you soooo much for this!. I was thinking of compiling this and you made my life so much easier :) They're obviously not bad papers, and I think NeRF was interesting, but aside from *Language Models are Few-Shot Learners* most are application papers and not true ML papers. I don't feel that any of them represents true progress on general ML, even though some represent limited progress, like the NeurIPS papers.\n\nI hope that people will have better taste than this and will hold up papers the results of which they will actually use instead of what impresses them. Man this is great. I was itching to do a little weekend reading. Thank you, this is very helpful! I appreciate your work, as I am sure many others do! Uhmmm... no ICLR? https://aibestpape.rs/?sub=AI,ML,CV,NLP Do I need a PhD or would a Masters in Data science be sufficient to understand these papers? What would everyone say were the best papers dealing with the underlying challenge of energy consumption in ML?",
    "That was a close one  Whatever people want to do in the privacy of the side of a public road in plain sight is fine by me... From the couples perspective: r/yesyesyesno Is this Florida or Russia r/Unexpected Lots of redditors saving this video in the comments. [deleted] Legitimately thought it was two people in a horse costume...  I need to put my glasses on I will award this once I get one da fuq they doin over der Seems like a scene from Reno 911",
    "For those of you taking Diff EQs next semester, hereâ€™s a flow chart to determine which technique to use on a given Differential Equation.  In an effort to curb the amount of memes posted to the sub, image and link submissions have been restricted outside of meme approved days. (Saturday, Sunday, and Monday)  \n\nIf this was a homework post, please be sure to follow the [homework submission guidelines](https://www.reddit.com/r/EngineeringStudents/wiki/homeworkhelp?utm_source=reddit&utm_medium=usertext&utm_name=EngineeringStudents&utm_content=t5_2sh0b) and  try submitting again a text self post with a link to your problem inside. \n\nIf you have a relevant link post and it was removed in error, please contact the moderation team. We thank you for your understanding.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/EngineeringStudents) if you have any questions or concerns.* As someone who passed DE with an A exactly one year ago, I have no idea what any of this means anymore I just use Euler's Method every time and keep it simple Also, if there are any inaccuracies, let me know. I ran it by the tutors a couple times and it seemed okay.\n\nThe chapter numbers are referencing â€œA First Course in Differential Equations With Modeling Applicationsâ€ by Dennis G. Zill This gave me flashbacks. Wish I had this when I was doing diffeq Then they make you do convolution before they teach you Laplace. Torture lol i have an easier one\n\n&#x200B;\n\nsee the question -> give up I just stumbled across one for thermo, and now I find this. Very good. Will print. 10/10. Good man.\n\nEdit: it's posted Just use laplace transform for all of them. If you are EE, get use to that shit now. Youll hate it at first but you will understand how useful and easy it is later I wish I had this for diffEQ and know I will next semester yay",
    "I made an Infographic to summarise K-means clustering in simple english. Let me know what you think!  Well done, simple enough to have a basic understanding This is really good and simple. Would love to see more of these for algorithms like SVC, PCA. More more more!!! I like that you are aiming for beginners, this will help them a lot.\n\nA minor suggestion: the most common fundamental confusion for a beginner to Kmeans is to distinguish that centroids are not real points in your dataset, but you initialize them using real points. I think that if you clarify that it can help even firther. Something like \"create the initial centroids copying k random points from your dataset\" What tools did you use? Photoshop and what? Five thumbs way up! The rare infographic on this sub that is actually quality rather than misleading, oversimplified tripe. Looking forward to more cool stuff like this from you in the future. Well done, this summarises the basics in the simplest way needed for K-means Will it be better to randomly spawn the data points around the average of all the points in the beginning?\n\nMe a complete noob that find this infographics amazing. This is terrific. Would love to see more concepts explained this way. That yellow is horrific, can barely see the points.",
    "[P] NumPy Illustrated. The Visual Guide to NumPy Hi, r/MachineLearning,\n\nI've built a (more or less) complete guide to numpy by taking \"Visual Intro to NumPy\" by Jay Alammar as a starting point and significantly expanding the coverage.\n\nHere's the [link](https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d?source=friends_link&sk=57b908a77aa44075a49293fa1631dd9b). This is fantastic. gonna share this with my students, thanks! Perhaps you could add [tensordot](https://numpy.org/doc/stable/reference/generated/numpy.tensordot.html) to your visual explanations?\n\nIt's a little known, yet extremely powerful function that I regularly struggle with, because it's hard to understand how the axis arguments work. I usually fiddle around until it finally works, but it's mostly guessing :( Keep up the great work!! Very comprehensive, nice work! This is amazing--thanks for doing this. If you haven't already, you should share it in Hacker news, i think they'll like it Thanks for sharing! X-Mas gift :) This is really solid, thanks. This is really awesome! But suddenly I feel like a primitive caveman!",
    "A tutorial for absolute beginners to understand the compilation process and get started in C++ I created a tutorial on the very basics of C++ compilation process.\n\nAs I C++ learner myself, I found most tutorials for newbies focuses more on the language itself like syntax rules. Few have covered on **compilation process**. I had questions in mind like: \n\n1. What does gcc/g++/clang++ command do for me?\n2. Why there are two types of files: header files and source files?\n3. What the hack are makefiles?\n\nThis motivated me to create this tutorial mini-series:\n\n[C++ Development Tutorial 1: Compile a Simple Program](https://domiyanyue.medium.com/c-development-tutorial-1-compile-a-simple-program-d0d04c680af3?sk=f0300c2f340ecb19db481aefcf585d30)\n\n[C++ Development Tutorial 2: Compile Multiple Files (1) â€” Compiling Process Basics](https://domiyanyue.medium.com/c-development-tutorial-2-compile-multiple-files-1-compiling-process-basics-41fba37eed6c?sk=18b13fd64754c0e5605b5ce5e80f0dfd)\n\n[C++ Development Tutorial 3: Compile Multiple Files (2) â€” Header Files](https://domiyanyue.medium.com/c-development-tutorial-3-compile-multiple-files-2-header-files-413e664b55f1?sk=f58786a5cab967982c819e79ef144cf0)\n\n[C++ Development Tutorial 4: Static and Dynamic Libraries](https://domiyanyue.medium.com/c-development-tutorial-4-static-and-dynamic-libraries-7b537656163e?sk=4592f7f94ab2ab1ec048976b91777df4)\n\n[C++ Development Tutorial 5: Orchestrate Build Process with Make](https://domiyanyue.medium.com/c-development-tutorial-5-orchestrate-build-process-with-make-6b379a3676c1?sk=b66f845b49e2a7fbb3d47f4dc670d1e6)\n\n&#x200B;\n\nFeedback is welcome! After a quick peek into chapter 5, I see CMake and Ninja right next to each other in a list. I think that is not entirely correct, especially since CMake is a tool that coordinates the others in the list.\n\nI know CMake is a big topic of its own, but that should be pointed out appropriately and maybe a different source should be linked or the promise of upcoming posts covering CMake. If you go with the latter and keep us posted, I'll make sure to read it thoroughly and give proper feedback as it is important that more people know how to actually use CMake instead of copy pasting snippets together hoping that works but never actually taking the time to read the docs and learn the tool that effectively solves a lot of problems when it comes to building projects.  \nMaybe this ended up a little rant-y, but so be it, however it's not targeted at you, OP!\n\nEdit: for chapter 4 it might be worth pointing out that symbol visibility is not uniform across platforms. This is something a build tool like CMake has a solution for, although that is not necessary to mention here.\n\nEdit 2: In chapter 1 `print â€œallâ€ warnings` should be `enable â€œallâ€ warnings` instead. Also in the array code please replace `sizeof(array)/sizeof(array[0])` with [`std::size(array)`](https://en.cppreference.com/w/cpp/iterator/size). Looks very straightforward to me. Thanks for making this. Build process, project structure and deployment are some of the things I struggle a lot with C++ as a newb. This surely helps a bit. [deleted] I am not a beginner but I do struggle with these kind of things, so I thank you for taking the time to give us these tutorials! :) >In todayâ€™s most modern Linux operating systems, GCC is adopted as the standard compiler.\n\nNot just modern ones, GCC was always the system compiler for Linux, right from the start.\n\nAlso, `-Wall` does not enable **all** warnings, only the ones with low rates of false positives, or which have an easy workaround to avoid the warning. There are more warnings documented in the manual. Some of them are enabled by `-Wextra` but there are others that must be enabled explicitly. `-Wall` enables all the most important and useful ones. part 4: static libs have one advantage over dynamic one - only used parts of library is compile and linked to exec :) Well done my man, I'm currently study C and C++ is set as my next goal, I saved there tutorial for later referance! Thanks Get rid of make, and convert it to cmake. Please :) On my IDE (Eclipse) i never had to learn how to manually compile. I just click â€œbuild projectâ€ What books covers this?",
    "Convolutional Neural Networks Explained (What Is Computer Vision)  This is cool, like the 3B1B video but more in-depth! Thank you very much! I really liked the video and will be digging into more of your content. This was very cool and very interesting! The animations in this video are extraordinary. Saving for later Thanks for watching and the huge compliment! Iâ€™m a huge fan of Grant and all the work he does! \nThanks! My computer hated me for them lol, took forever to render!",
    "It arrives when?  You expected `undefined`, but it was me, `false`! The Boolean ones are the funniest to find. They effectively render reality unreal. \"Help\" most welcome Never bitch A computer's way of saying \"when hell freezes over\". Why boolean? :( When the driver realizes your neighorhood is sketchy as fuck... Why does a variable thatâ€™s supposed to represent a time accept a boolean? That sounds about right for DoorDash. # Help",
    "My college books are fucking trash  Man,really arch wiki is one of the best things in Linux. Even with Debian love or hate arch and its users \n\narch wiki is absolutely fantastic and a lot of the stuff on there is applicable to all other distros due to it just being epic College books? Is that a package on the AUR? Ah, the Arch wiki. Really useful especially when you are on Arch or and Arch based distro, like me. (EndeavourOS) Yes, except for the fact that I don't understand anything there lol. Using Linux + Studying in med school! Yeah, that ArchWiki is a hell of a resource Sounds like you shouldnâ€™t study and need to keep reading what interests you ! I fuckin agree with ya. V had linux subject last semester and Im pretty sure that my university will fail even Linus trolvald in that subject I concur.",
    "A Math search engine I have found this search engine: [https://approach0.xyz/search/](https://approach0.xyz/search/) and I thought I'd share it, it might become hard sometimes to look up some Math stuff in google (latex, etc...) this search engine supports latex and currently searches through Mathematics StackExchange and ArtOfProblemSolving. I am in no way related to this project and don't know the owner. What a beautifully clean web page design.  I think the folks at hackernews will love it, and exposure there may lead to more substantial financial support for the author.  If someone has an account there, I would recommed making a post.\n\nEdit: The killer feature, of course, would be to index arxiv.  Arxiv's own search functionality is... well... It's epic, I found it after someone on mathstackexchange recommend it There's also https://www.searchonmath.com/ ðŸ˜„ Think itâ€™s down? Just found out it's [open source](https://github.com/approach0/search-engine) too! You may like the math section on https://www.wolframalpha.com/ as well. Does it support variable substitution? Because this would be the killer feature. Some people might ask the question: *\"How to solve xe^x = y?\"* while another person may ask: *\"How to solve ze^z = w?\"*\n\nThey are asking exactly the same question, but because they use different variable letters; traditional search engines are not able to find all relevant results. I love the UI. I'm sure this will be useful to me at some point, thanks Now we need one that searches through  google scholar Neat. Thank you!",
    "I made a video on the Lottery Ticket Hypothesis, and why it's important. I figured y'all would find it valuable/interesting!  An easily-intelligible presentation of an accessible idea to try, seeing there's a keras impl. Six thumbs up!\n\nhttps://pypi.org/project/lottery-ticket-pruner/ Ok but the idea behind regularization is that you don't want a particular weight to have too much impact in the trained model. That's why if you do drop-out, for example, you turn off some weights each iteration then turn others off, so that the network doesn't have high variance/ high complexity. \n\nThis idea seems the opposite of that and yet one explanation is that it becomes better at generalization. \n\nI feel like something doesn't add up ( in my understanding at least ) Thank you, and I did :) Tensorflow 2 implementation:\nhttps://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2 Very cool thanks How much does it depend on the distribution of important features in the training data? I guess one needs to make sure that in the reduced set of training data still all important aspects are present, since otherwise it would prune out too much/parameters that might be needed? Wow, that is incredible. What technique(s) did you use in your own implementation to identify which parameters to prune? PCA? I hadn't seen that yet, I'm excited to give that implementation a try! explain more, does the lottery ticket method truly holds up with generalization and efficiency. I believe this is just a better way of figuring out the sub network architecture from a larger one.  Those sub networks might still have independent features that respond well to drop out.",
    "A competition: build an insurance pricing model with real data, compete in a market, prize pool of $12,000 USD [removed] That sounds awesome! But I wonder how they model things like public perception and marketing when that's such a huge driver in the current industry. \n\nI see so many ads on \"save 15%\" and that might make sense for the premiums but not the payouts. The marketing must be attracting customers if they can afford to run so many ads. I also have friends who have gotten sucked in to MLM insurance schemes (I had to block a number because it got so bad) and that marketing must work to some degree? \n\nMeanwhile, I've never seen ads for my insurance company (Chubb) they cover my home and vehicle, the premiums are tiny, and they've covered things like chipped windshield and a stolen bicycle in full! Do this get paid almost nothing company saves or makes millions on millions on millions for $12k worth of work and what you create becomes proprietary to them and you lose all the analysis and code you wrote. Sounds like a deal to me! Has the competition already started? Looks like you can form a team. If you want to collaborate PM me, let's talk.\n\nObligatory [GitHub](https://github.com/skellet0r) reference, I use Python. Let me know which firm will be using the model, will buy LEAPS. Does anybody have an idea on the start/end dates for this? The ads are just that, pure marketing and ads, and donâ€™t actually reflect the economics of the business.  If you listen closely they donâ€™t say â€œsave 15%â€ they say â€œsave *up to* 15%â€ by switching.  So technically you might not save anything on their quote (and typically donâ€™t).\n\nThe way they typically get new customers to think theyâ€™ve saved them 15% is by reducing their coverage in certain categories enough to bring the premiums down by 15%.  So at that point it is an apples to oranges comparison to the customerâ€™s old policy.  If they were to offer them the exact same coverage then the actual savings will usually be in the range of 5% or less. Itâ€™s must be the half Chubb policy. The full Chubb comes with added benefits. >public perception and marketing when that's such a huge driver in the current industry\n\nBut is it? I would think people nowadays get multiple quotes and pick the cheapest one. Ads just makes sure the consumer at least get a quote from you.\n\nIt is stated in the competition that the cheapest price wins so imo, that takes care of public perception (because price is only driver of choice) and marketing (because it assumes consumer sees all prices). If you aren't selling online direct to consumers or have your own captive agent force  you advertise to independent agents, and marketing dollars are spent convincing independent agents to sell your stuff.",
    "Visualizing the Complex function tan(z)  These visualisations are a way of plotting complex functions, in this case tan(z). These graphics are sometimes known as modular surfaces or 3D phase portraits. \n\nThe input is a complex number, as shown on the base plane. The output is also a complex number. The absolute value of the output is shown as height. The argument (angle) is shown as colour. Where red it the positive real axis, and cyan is the negative real axis. Where the image touches the base there is a zero. You can clearly see the poles where the function heads towards infinity.\n\nIn the imaginary direction, this function approaches plus or minus i. In fact, the values on the imaginary axis are the hyperbolic function tanh(z).\n\nIâ€™ve made a video of all 6 complex trigonometric functions (sin, cos, tan, sec, cosec, cot). It is rendered in 4k 60fps: https://youtu.be/3qEJeP6qQGA There shall be a day when I'll be able to understand this I need to see this visualisation for zeta - it would be so cool. nice visualization! what software did you use for rendering it? Looks like modern art. Imagine a museum filled with these I thought tan(z) goes to +/- infinity on the real axis! I am only see +infinity. More plz Didn't even get to see the top of it :(      \n\n/s That's pretty interesting.\n\nI kind of like visualisations where +âˆž  and -âˆž are at the same place, so that it doesn't look like a huge jump when there is an odd pole. (It's hard for me to tell which colour I'm looking at... but it looks like red is ðœƒ=0, and blue is ðœƒ=ðœ‹; maybe.)\n\nAt first I assume that the flat part was |z|=0... but it does make sense for it to be 1. I'd just not really thought about it until it was revealed. So the underside thing was a nice surprise feature. :) I want to 3D print that."
  ]
}